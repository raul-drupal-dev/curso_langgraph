# üõ†Ô∏è Tema 7: Tools ‚Äì Integraci√≥n de Herramientas Externas en el Grafo  

## üöÄ ¬øQu√© son las Tools en LangGraph?  

Las **tools (herramientas)** son funciones externas que el grafo puede invocar para realizar tareas espec√≠ficas, como consultas a bases de datos, c√°lculos matem√°ticos o llamadas a APIs externas.  
Las tools permiten que el grafo **extienda sus capacidades m√°s all√° de los nodos internos**, integrando l√≥gica personalizada o servicios de terceros.  

---

### üß† ¬øPor qu√© son Importantes las Tools?  

- **Extensibilidad:** Permiten que el grafo interact√∫e con APIs externas y sistemas avanzados.  
- **Modularidad:** Las tools se definen de forma independiente y se integran f√°cilmente en el flujo del grafo.  
- **Eficiencia:** Delegan tareas espec√≠ficas a funciones externas, reduciendo la complejidad dentro de los nodos.  

üëâ **Piensa en las tools como plugins** que a√±aden nuevas capacidades al grafo sin necesidad de modificar su estructura central.  

---

## ‚öôÔ∏è ¬øC√≥mo Funcionan las Tools?  

1. **Definici√≥n de Tools:** Creamos funciones externas que pueden recibir par√°metros y devolver resultados.  
2. **Vinculaci√≥n al Modelo de Lenguaje (LLM):** Asociamos estas tools al LLM para que pueda invocarlas durante el flujo de trabajo.  
3. **Ejecuci√≥n Condicional:** Si el LLM detecta que es necesario usar una tool, el grafo redirige el flujo para ejecutarla y procesar el resultado.  

üí° Es fundamental entender que **es el LLM quien decide qu√© tool invocar** en funci√≥n del mensaje o prompt proporcionado. El grafo facilita la integraci√≥n de herramientas, pero la decisi√≥n de cu√°l utilizar se basa en la interpretaci√≥n que hace el modelo del contexto y las instrucciones.  


---

## üìã Ejemplo Pr√°ctico: Chatbot con Tools para Soporte y Ventas  

Vamos a construir un grafo que act√∫a como un asistente virtual, redirigiendo solicitudes de los usuarios a diferentes herramientas seg√∫n sus necesidades.  
El chatbot podr√°:  
1. **Consultar precios de productos.**  
2. **Verificar el estado de pedidos.**  
3. **Abrir tickets de soporte.**  

```python
from langchain_openai import ChatOpenAI

# Definimos las tools externas con docstrings
def check_price(product: str) -> str:
    """Consulta el precio de un producto.

    Args:
        product: Nombre del producto a consultar.
    
    Returns:
        El precio del producto en formato texto.
    """
    # Simulamos una consulta a nuestra base de datos.
    return f"El precio de {product} es de 100‚Ç¨."

def order_status(order_id: int) -> str:
    """Consulta el estado de un pedido.

    Args:
        order_id: ID del pedido.
    
    Returns:
        El estado actual del pedido.
    """
    # Simulamos una consulta a nuestro ORM.
    return f"El pedido con ID {order_id} est√° en camino."

def open_ticket(issue: str) -> str:
    """Abre un ticket de soporte.

    Args:
        issue: Descripci√≥n del problema o incidencia.
    
    Returns:
        Confirmaci√≥n de apertura del ticket.
    """
    # Simulamos una creacion de un ticket en nuestro sistema de soporte.
    return f"Se ha abierto un ticket de soporte para el problema: {issue}."


tools = [check_price, order_status, open_ticket]

# Vinculamos las tools al modelo de lenguaje
llm = ChatOpenAI(model="gpt-4o-mini")
llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)
```

- **Tools (`check_price`, `order_status`, `open_ticket`):** Simulan herramientas externas que realizan distintas tareas para ventas y soporte.  

:material-alert-octagram-outline: **Nota Importante:**  

Cuando llamamos a `bind_tools`, **no se modifica el modelo original (`llm`)**, sino que se genera **una nueva instancia** con las herramientas vinculadas.  
Por esta raz√≥n, es necesario **asignarlo a una nueva variable** (`llm_with_tools`).  

Esto garantiza que el modelo original **permanezca sin cambios** y podamos reutilizarlo o aplicar diferentes herramientas en otros contextos.  

Ejemplo:  
```python
llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)
```
üëâ llm sigue siendo el modelo base, mientras que llm_with_tools es la versi√≥n extendida con las tools activas.
---

## üèóÔ∏è Construcci√≥n del Grafo  

Creamos los nodos y edges necesarios para integrar las tools al flujo del grafo.  
 
```python
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langgraph.prebuilt import ToolNode

sys_msg = SystemMessage(content="Eres un asistente de ventas y soporte. Responde usando las herramientas disponibles.")

def assistant(state: MessagesState):
    return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

builder = StateGraph(MessagesState)

# A√±adimos nodos
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Definimos los edges y el flujo del grafo
builder.add_edge(START, "assistant")
builder.add_conditional_edges("assistant", tools_condition)
builder.add_edge("tools", "assistant")

graph_with_tools = builder.compile()

from IPython.display import Image, display
display(Image(graph_with_tools.get_graph(xray=True).draw_mermaid_png()))
```

- **Assistant Node:** El nodo principal procesa el mensaje del usuario y decide si debe invocar alguna tool.  
- **Router Condicional:** El flujo se redirige al nodo de tools si se detecta una llamada a alguna de ellas.  

---

## üöÄ Invocando el Grafo  

Probamos el grafo enviando un mensaje del usuario para ver c√≥mo se invocan las tools en el flujo.  

```python
from IPython.display import Image, display
display(Image(graph_with_tools.get_graph(xray=True).draw_mermaid_png()))

messages = [HumanMessage(content="Quiero saber el precio del producto X y abrir un ticket de soporte.")]
response = graph_with_tools.invoke({"messages": messages})

for msg in response["messages"]:
    print(msg.content)
```

```python
El precio de producto X es de 100‚Ç¨.
Se ha abierto un ticket de soporte para el problema: Precio de producto X.
```

El chatbot analiza la solicitud, invoca las tools adecuadas y devuelve una respuesta consolidada al usuario.  

---

## üßë‚Äçüè´ ¬øQu√© Hemos Aprendido?  

- **Tools:** Permiten extender el grafo con funciones externas que realizan tareas espec√≠ficas.  
- **Integraci√≥n con LLM:** Las tools se vinculan directamente al modelo de lenguaje, permitiendo respuestas m√°s avanzadas.  
- **Flujo Din√°mico:** El grafo puede invocar tools de forma condicional, adapt√°ndose a las necesidades del usuario.  

---

## üåê ¬øQu√© es lo Siguiente?  

En el pr√≥ximo tema, profundizaremos en **subgrafos (subgraphs)**, permitiendo que el grafo ejecute flujos complejos de manera modular y jer√°rquica.  
