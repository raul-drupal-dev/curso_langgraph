# 🧩 Tema 3: State Schema y Memoria  

## 🚀 ¿Qué es el State Schema y la Memoria en LangGraph?  

El **State Schema** es el corazón de LangGraph, ya que define y gestiona el estado del grafo durante su ejecución.  
El **estado** es la información que **se transfiere, modifica y actualiza** a medida que el flujo avanza por diferentes nodos.  

Piensa en el estado como una mochila 🧳 que lleva datos entre los nodos. En cada nodo, puedes:  
- **Añadir** nuevos datos.  
- **Modificar** valores existentes.  
- **Eliminar** información que ya no necesitas.  

### 🧠 ¿Y la Memoria?  
La memoria es la capacidad que tiene el grafo para **recordar información** a lo largo de múltiples invocaciones. Es especialmente útil cuando creamos chatbots o flujos conversacionales donde el contexto es crucial.  

- **Sin memoria:** Cada vez que invocamos el grafo, comienza desde cero.  
- **Con memoria:** El grafo guarda un historial de mensajes o datos, permitiendo respuestas basadas en todo el contexto anterior.  

**¿Por qué es importante?**  
- **Persistencia de datos.**  
- **Toma de decisiones basadas en el contexto actual.**  
- **Mayor precisión en interacciones prolongadas.**  

---

## ⚙️ ¿Cómo Funciona el State?  

Para entender cómo se define el estado en LangGraph, crearemos un `State` personalizado.  
Este enfoque facilita la comprensión antes de utilizar estructuras predefinidas como `MessagesState`.  

### 📋 Creación de un State Propio  
```python hl_lines="3 4"
from typing_extensions import TypedDict

class CustomState(MessagesState):
    messages: list[AIMessage | HumanMessage | SystemMessage] = []
```

- **Explicación:**  
  - `TypedDict` nos permite definir un diccionario con tipos estrictos, lo que asegura que el estado tenga una estructura clara y esperada.  
  - El `graph_state` es un campo donde almacenaremos mensajes o datos que pasarán de un nodo a otro.  

Si prefieres simplificar, puedes utilizar el estado predefinido `MessagesState` de LangGraph, diseñado específicamente para flujos conversacionales.  
👉 [Documentación de MessagesState](https://python.langchain.com/docs/modules/langgraph#messagesstate)  

---

## 🧩 Nodos que Utilizan el Estado  

A continuación, crearemos dos nodos que utilizan el estado:  
1. **Nodo de entrada del usuario:** Agrega el mensaje del usuario al estado.  
2. **Nodo de respuesta de IA:** El modelo de OpenAI (`gpt-4o-mini`) genera una respuesta basada en el historial.  

```python  
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

llm = ChatOpenAI(model="gpt-4o-mini")

def user_input_node(state: CustomState):
    print("--- Usuario dice ---")
    return {"messages": state['messages']}

def ai_response_node(state: CustomState):
    print("--- IA responde ---")
    response = llm.invoke(state['messages'])
    return {"messages": state['messages'] + [AIMessage(content=response.content)]}
```

- **`user_input_node:`** Toma el mensaje del usuario y lo guarda en el estado.  
- **`ai_response_node:`** Usa el estado actual (historial) para generar una respuesta de IA.  

---

## 🧠 Memoria: ¿Cómo Funciona?  

LangGraph ofrece varios tipos de memoria:  

1. **Memoria de Estado (State Memory):**  
    - El estado se transfiere de nodo a nodo, reteniendo información solo durante una invocación.  
   
2. **Memoria de Corto Alcance (MemorySaver):**  
    - Guarda datos durante múltiples invocaciones, pero **no persiste después de cerrar el programa.**  
    - Almacena la información en memoria volátil (RAM).  
    - Ideal para flujos temporales que necesitan recordar el contexto durante la sesión actual.  
   👉 [Documentación de MemorySaver](https://python.langchain.com/docs/modules/langgraph#memorysaver)  

3. **Memoria Persistente (Postgres u otros):**  
    - Permite almacenar el historial en bases de datos externas (ej: PostgreSQL).  
    - **Se verá en temas más avanzados.**  

4. **Memoria Transversal (Cross-Session Memory):**  
    - Conserva datos a lo largo de múltiples sesiones y usuarios.  
    - **Se estudiará en profundidad en futuros módulos.**  

---

## 🏗️ Añadiendo Memoria al Grafo  

Ahora implementaremos el `MemorySaver` para agregar memoria de corto alcance a nuestro grafo.  

### 📋 Grafo sin Memoria  

En el siguiente ejemplo, vamos a ver un grafo básico, como ya hemos visto hasta ahora, solamente para poder ver la diferencia para cuando le apliquemos nuestra memoria.

```python  
from langgraph.graph import StateGraph, START, END

builder = StateGraph(State)
builder.add_node("user_input", user_input_node)
builder.add_node("ai_response", ai_response_node)

builder.add_edge(START, "user_input")
builder.add_edge("user_input", "ai_response")
builder.add_edge("ai_response", END)

graph_no_memory = builder.compile()
```

### 📋 Grafo con Memoria  

Ahora, agregaremos una memoria temporal

```python   hl_lines="4 14"
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

builder_mem = StateGraph(State)
builder_mem.add_node("user_input", user_input_node)
builder_mem.add_node("ai_response", ai_response_node)

builder_mem.add_edge(START, "user_input")
builder_mem.add_edge("user_input", "ai_response")
builder_mem.add_edge("ai_response", END)

graph_memory = builder_mem.compile(checkpointer=memory)
```

---

## 📈 Visualización del Grafo  

Para observar cómo se estructura nuestro grafo, generamos una visualización:  
```python  
from IPython.display import Image, display
display(Image(graph_no_memory.get_graph().draw_mermaid_png()))
display(Image(graph_memory.get_graph().draw_mermaid_png()))
```  

---

## 🚀 Invocando el Grafo y Comparando Resultados  

### 📋 Sin Memoria  
```python  
graph_no_memory.invoke({"messages": [HumanMessage(content="Hola, me llamo Raul.")]})
graph_no_memory.invoke({"messages": [HumanMessage(content="¿Cómo me llamo?")]})

```

```python 
--- Usuario dice ---
Hola, me llamo Raul.
--- IA responde ---
Hola Raul, ¿en qué puedo ayudarte?
--- Usuario dice ---
¿Cómo me llamo?
--- IA responde ---
No tengo esa información.
```

---

### 📋 Con Memoria  
```python  
graph_memory.invoke({"messages": [HumanMessage(content="Hola, me llamo Raul.")]})
graph_memory.invoke({"messages": [HumanMessage(content="¿Cómo me llamo?")]})
```

```python  
--- Usuario dice ---
Hola, me llamo Raul.
--- IA responde ---
Hola Raul, ¿en qué puedo ayudarte?
--- Usuario dice ---
¿Cómo me llamo?
--- IA responde ---
Te llamas Raul.
```

---

## 🧑‍🏫 ¿Qué Hemos Aprendido?  

- **State Schema:** Es la estructura que define qué datos se transportan y modifican durante el flujo del grafo.  
- **Memoria de Estado (State):** Solo persiste durante la ejecución de una invocación.  
- **MemorySaver:** Proporciona memoria de corto alcance para retener datos durante múltiples invocaciones.  
- **Diferencias Clave:** Sin memoria, cada invocación es independiente. Con memoria, el grafo recuerda datos anteriores.  

---

## 🌐 ¿Qué es lo Siguiente?  

En el siguiente tema exploraremos **Chains y Flujos de Trabajo**, donde aprenderemos a encadenar nodos y construir pipelines complejos.  
También abordaremos el tema de **Tools (Herramientas)**, pero lo veremos **después de Chains**, ya que comprender primero el flujo de trabajo hará que la integración de herramientas sea más sencilla y práctica.  
