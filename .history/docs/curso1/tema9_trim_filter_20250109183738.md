# âœ‚ï¸ Tema 8: Trim y Filter Messages â€“ OptimizaciÃ³n del Historial de Mensajes  

## ğŸš€ Â¿QuÃ© es el Trimming y Filtering de Mensajes?  

A medida que un grafo interactÃºa con los usuarios, el historial de mensajes puede **crecer considerablemente**, lo que puede:  
- **Aumentar el costo de procesamiento** para los modelos LLM.  
- **Reducir la eficiencia** del grafo en conversaciones largas.  
- **Diluir el contexto**, incluyendo mensajes irrelevantes.  

Para solucionar esto, LangGraph ofrece herramientas que permiten **gestionar y optimizar el historial de mensajes**:  

1. **`RemoveMessages`** â€“ Elimina mensajes especÃ­ficos.  
2. **`trim_messages`** â€“ Recorta el historial manteniendo solo los mensajes mÃ¡s recientes.  
3. **`summarize_conversation`** â€“ Resume la conversaciÃ³n para reducir la longitud del historial, manteniendo el contexto.  

:material-alert-octagram-outline: **Nota Importante:**  

Al eliminar mensajes del historial, es crucial asegurarse de que la estructura de los mensajes **siga siendo vÃ¡lida** para el modelo LLM.  
Algunos modelos, como los chatbots basados en LLM, requieren que el primer mensaje sea de un **Humano** (`HumanMessage`).  

ğŸ‘‰ Antes de procesar el historial, verifica que la estructura cumpla con los requisitos del modelo para evitar errores en su funcionamiento.  

---

## ğŸ§  Â¿Por quÃ© es Importante?  

- **OptimizaciÃ³n del Rendimiento:** Reduce la cantidad de datos enviados al LLM.  
- **Mejora de la PrecisiÃ³n:** Mantiene el contexto relevante, eliminando informaciÃ³n redundante.  
- **Ahorro de Costos:** Menos tokens procesados significa **menos consumo de recursos.**  

---

## âš™ï¸ Â¿CÃ³mo Funciona el Trimming y Filtering?  

LangGraph ofrece diferentes enfoques segÃºn el escenario:  
- **Eliminar mensajes irrelevantes o antiguos.**  
- **Recortar automÃ¡ticamente despuÃ©s de alcanzar un lÃ­mite.**  
- **Resumir el historial para mantener el contexto clave.**  

---

## ğŸ“‹ Ejemplo PrÃ¡ctico: Chatbot con GestiÃ³n del Historial de Mensajes  

Vamos a crear un chatbot que interactÃºa con el usuario, pero **gestiona el historial** para mantener solo los mensajes relevantes y no saturar el flujo del grafo.  

---

### ğŸ› ï¸ OpciÃ³n 1: Eliminar Mensajes EspecÃ­ficos con `RemoveMessages`  

Permite eliminar ciertos mensajes del historial, ideal para **eliminar mensajes duplicados o irrelevantes.**  
  
```python hl_lines="1 9 10"
from langchain_core.messages import HumanMessage, AIMessage, RemoveMessage
from IPython.display import Image, display
from langgraph.graph import MessagesState
from langgraph.graph import StateGraph, START, END

# Nodes
def filter_messages(state: MessagesState):
    # Eliminamos todo el historial menos los 2 mas recientes
    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
    return {"messages": delete_messages}

def chat_model_node(state: MessagesState):  
    # Simulamos una respuesta de un LLM.  
    return {"messages": [
        AIMessage(
          content="El producto B cuesta 150â‚¬ y estÃ¡ disponible en color rojo y azul. Â¿Te interesa alguna de estas opciones?",
          id="accce84f-3e31-4cf2-b16d-5aed5a4b890a"
          )
        ]}

# Build graph
builder = StateGraph(MessagesState)
builder.add_node("filter", filter_messages)
builder.add_node("chat_model", chat_model_node)
builder.add_edge(START, "filter")
builder.add_edge("filter", "chat_model")
builder.add_edge("chat_model", END)
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
```

![RemoveMessages](../assets/img/curso1/tema9/image.png)

```python
messages = [
    HumanMessage(content='Hola, necesito informaciÃ³n sobre varios productos.', additional_kwargs={}, response_metadata={}, id='66a48850-bcf9-4500-9a0b-6a18ecad0d4a'), 
    AIMessage(content='Claro, puedo ayudarte con eso.', additional_kwargs={}, response_metadata={}, id='46bc8fa9-452b-4f16-b5d9-65f527812b8e'), 
    HumanMessage(content='Perfecto. Empecemos con el producto A.', additional_kwargs={}, response_metadata={}, id='ef3742dd-87ac-443a-bbff-72282fb4c1ca'), 
    AIMessage(content='El producto A cuesta 100â‚¬ y estÃ¡ disponible.', additional_kwargs={}, response_metadata={}, id='038bff18-4498-4ca5-afa8-448c9118b1bc'), 
    HumanMessage(content='Â¿Y quÃ© pasa con el producto B?', additional_kwargs={}, response_metadata={}, id='1d315b43-906e-48f0-a801-b2807e8abf0a')
    ]

response = graph.invoke({'messages': messages})

for m in response['messages']:
    m.pretty_print()
```

```python title="Resuldato"
 ================================== Ai Message ==================================

El producto A cuesta 100â‚¬ y estÃ¡ disponible.
================================ Human Message =================================

Â¿Y quÃ© pasa con el producto B?
================================== Ai Message ==================================

El producto B cuesta 150â‚¬ y estÃ¡ disponible en color rojo y azul. Â¿Te interesa alguna de estas opciones?
```

---

### ğŸ› ï¸ OpciÃ³n 2: Recorte de Mensajes con `trim_messages`  

Recorta el historial de mensajes **manteniendo solo los Ãºltimos N mensajes.**  
Esto es Ãºtil para **evitar que el historial crezca sin control.**  
 
```python
from langchain_core.messages import trim_messages
from langchain_core.messages import HumanMessage, AIMessage

# Estado con muchos mensajes
state = {
    "messages": [
      HumanMessage(content='Hola, necesito informaciÃ³n sobre varios productos.', additional_kwargs={}, response_metadata={}, id='66a48850-bcf9-4500-9a0b-6a18ecad0d4a'), 
      AIMessage(content='Claro, puedo ayudarte con eso.', additional_kwargs={}, response_metadata={}, id='46bc8fa9-452b-4f16-b5d9-65f527812b8e'), 
      HumanMessage(content='Perfecto. Empecemos con el producto A.', additional_kwargs={}, response_metadata={}, id='ef3742dd-87ac-443a-bbff-72282fb4c1ca'), 
      AIMessage(content='El producto A cuesta 100â‚¬ y estÃ¡ disponible.', additional_kwargs={}, response_metadata={}, id='038bff18-4498-4ca5-afa8-448c9118b1bc'), 
      HumanMessage(content='Â¿Y quÃ© pasa con el producto B?', additional_kwargs={}, response_metadata={}, id='1d315b43-906e-48f0-a801-b2807e8abf0a')
    ]
}

# Limitamos a los ultimos 3 mensajes para no sobrecargar la llamada.
state = trim_messages(
            state['messages'],
            token_counter=len,  # Contamos mensajes (simple, no tokens)
            max_tokens=3,       # LÃ­mite de 3 mensajes
            strategy="last",
            #start_on="system",   # Empieza en un mensaje humano o sistema-humano
            include_system=True,
            allow_partial=False
        )

for m in state:
    m.pretty_print()
```

```python

---

### ğŸ› ï¸ OpciÃ³n 3: Resumir ConversaciÃ³n con `summarize_conversation`  

En lugar de eliminar mensajes, **genera un resumen de la conversaciÃ³n** manteniendo el contexto en menos palabras.  
Perfecto para **mantener el contexto en conversaciones extensas.**  
 
```python
from langgraph.graph.message import summarize_conversation

# Estado con mensajes acumulados
state = {
    "messages": [
        HumanMessage(content="Hola, necesito informaciÃ³n sobre varios productos."),
        AIMessage(content="Claro, puedo ayudarte con eso."),
        HumanMessage(content="Perfecto. Empecemos con el producto A."),
        AIMessage(content="El producto A cuesta 100â‚¬ y estÃ¡ disponible."),
        HumanMessage(content="Â¿Y quÃ© pasa con el producto B?")
    ]
}

# Resumir la conversaciÃ³n
state = summarize_conversation(state)

print(state)
```

---

## ğŸ—ï¸ ConstrucciÃ³n del Grafo con Trim y Filter Messages  

Integramos estas herramientas en el flujo de trabajo del chatbot para optimizar el historial de mensajes en diferentes etapas.  

```python
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import RemoveMessages, trim_messages

def assistant(state: MessagesState):
    # Simula la respuesta de un asistente
    state["messages"].append(AIMessage(content="Tu pedido ha sido procesado."))
    return state

def filter_messages(state: MessagesState):
    # Elimina mensajes irrelevantes
    state = RemoveMessages([0]).invoke(state)
    state = trim_messages(state, n=5)
    return state

# ConstrucciÃ³n del grafo
builder = StateGraph(MessagesState)
builder.add_node("assistant", assistant)
builder.add_node("filter", filter_messages)

builder.add_edge(START, "assistant")
builder.add_edge("assistant", "filter")
builder.add_edge("filter", END)

graph = builder.compile()
```

---

## ğŸš€ Invocando el Grafo y Resultados  

Probamos el grafo con mensajes largos y observamos cÃ³mo se filtran, recortan o resumen automÃ¡ticamente.  
  
```python
result = graph.invoke({"messages": [HumanMessage(content="Hola, tengo una duda.")]} )
print(result)
```

```python
{'messages': [
    AIMessage(content="Tu pedido ha sido procesado.")
]}
```

---

## ğŸ§‘â€ğŸ« Â¿QuÃ© Hemos Aprendido?  

- **RemoveMessages:** Elimina mensajes especÃ­ficos del historial.  
- **trim_messages:** Recorta el historial a los Ãºltimos mensajes.  
- **summarize_conversation:** Genera resÃºmenes que conservan el contexto sin saturar el historial.  

---

## ğŸŒ Â¿QuÃ© es lo Siguiente?  

Con esto finalizamos el **Curso 1: Fundamentos de LangGraph.**  
En el siguiente curso, exploraremos temas mÃ¡s avanzados como **Memoria a Largo Plazo, SubgrafÃ­as y Despliegues.**  
