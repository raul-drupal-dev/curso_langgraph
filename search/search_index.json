{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\ud83e\uddd1\u200d\ud83d\udcbb Curso Completo de LangGraph 0.3.xx Construcci\u00f3n de Flujos Avanzados con LLMs \ud83d\ude80 \u00a1Bienvenido al Curso de LangGraph 0.3.xx! Este curso est\u00e1 dise\u00f1ado para ense\u00f1arte desde los conceptos m\u00e1s b\u00e1sicos hasta la creaci\u00f3n de un asistente virtual avanzado usando LangGraph 0.3.xx . Si buscas dominar el desarrollo de flujos de trabajo con modelos de lenguaje grande (LLMs) y optimizar tus proyectos de IA, est\u00e1s en el lugar adecuado . LangGraph es una herramienta poderosa para la creaci\u00f3n de pipelines modulares, paralelos y escalables , con capacidades que te permitir\u00e1n llevar tus aplicaciones de IA al siguiente nivel. \ud83d\udccb \u00bfQu\u00e9 Aprender\u00e1s en Este Curso? A lo largo de este curso, adquirir\u00e1s habilidades pr\u00e1cticas y te\u00f3ricas para: \u2705 Construir flujos de trabajo avanzados con LangGraph. \u2705 Crear pipelines din\u00e1micos y modulares que interact\u00faan con LLMs. \u2705 Implementar memoria a corto y largo plazo en tus aplicaciones. \u2705 Desplegar y escalar tus proyectos de IA en entornos reales. \u2705 Desarrollar un asistente virtual completo con memoria y capacidad de respuesta avanzada. \ud83c\udfaf Objetivos del Curso Al finalizar, podr\u00e1s: - Construir pipelines completos con LangGraph que manejan consultas, flujos paralelos y enrutamiento condicional. - Crear asistentes virtuales con memoria persistente. - Optimizar y monitorizar flujos con herramientas como LangSmith y LangGraph Studio. - Desplegar tus aplicaciones de LangGraph en producci\u00f3n utilizando LangGraph Local Server o CLI. \ud83d\udcc2 Estructura del Curso El curso se divide en tres m\u00f3dulos principales , con teor\u00eda, ejemplos de c\u00f3digo y ejercicios pr\u00e1cticos: M\u00f3dulo 1: Fundamentos y Componentes B\u00e1sicos de LangGraph \u00bfQu\u00e9 es LangGraph y para qu\u00e9 sirve? Creaci\u00f3n de nodos (Nodes) y conexiones (Edges). Control del estado y memoria (State Schema y Postgres). Construcci\u00f3n de flujos con chains y routers. M\u00f3dulo 2: Aplicaciones Avanzadas y Flujos Complejos Construcci\u00f3n de chatbots resumidores (Summarizing). Implementaci\u00f3n de puntos de interrupci\u00f3n y streaming. Ejecuci\u00f3n paralela de tareas y subgraf\u00edas. Sistemas de RAG (Retrieval-Augmented Generation). Uso de LangGraph Studio para visualizar flujos. M\u00f3dulo 3: Despliegue y Proyecto Final Despliegue de LangGraph en producci\u00f3n. Memoria a largo plazo con LangGraph Store. Creaci\u00f3n de APIs REST para LangGraph. Proyecto final: Asistente virtual completo. \ud83d\udee0\ufe0f Requisitos Previos Conocimientos b\u00e1sicos de Python. Familiaridad con modelos de lenguaje grande (LLMs) . Experiencia en LangChain (opcional). \ud83d\udccc \u00bfPara Qui\u00e9n Est\u00e1 Dirigido Este Curso? Este curso es ideal para: - \ud83e\uddd1\u200d\ud83d\udcbb Desarrolladores de IA que quieren construir pipelines avanzados. - \ud83d\udcca Ingenieros de datos que buscan optimizar flujos de procesamiento de lenguaje natural. - \ud83d\udcda Investigadores y entusiastas que desean integrar LLMs en proyectos reales. \ud83c\udfc6 Resultado Final del Curso Al completar el curso, habr\u00e1s desarrollado un asistente virtual funcional que: - Gestiona m\u00faltiples consultas con LLMs. - Mantiene memoria y contexto de conversaciones previas. - Ejecuci\u00f3n de tareas paralelas y flujos complejos. - Es capaz de desplegarse y escalarse en entornos de producci\u00f3n. \ud83d\udee0\ufe0f Tecnolog\u00edas Utilizadas LangGraph 0.3.xx LangChain (opcional) LangSmith (trazado y depuraci\u00f3n) OpenAI (u otros LLMs) Postgres (para memoria de corto plazo) \ud83d\udcdc Certificaci\u00f3n Final Completar este curso te permitir\u00e1 obtener un certificado que acredita tus conocimientos en LangGraph 0.3.xx y la construcci\u00f3n de flujos avanzados con modelos de lenguaje. \ud83c\udf1f \u00a1Empieza tu viaje ahora y lleva tus habilidades de IA al siguiente nivel!","title":"\ud83d\ude4b\u200d\u2642\ufe0f Bienvenida"},{"location":"#curso-completo-de-langgraph-03xx","text":"","title":"\ud83e\uddd1\u200d\ud83d\udcbb Curso Completo de LangGraph 0.3.xx"},{"location":"#construccion-de-flujos-avanzados-con-llms","text":"","title":"Construcci\u00f3n de Flujos Avanzados con LLMs"},{"location":"#bienvenido-al-curso-de-langgraph-03xx","text":"Este curso est\u00e1 dise\u00f1ado para ense\u00f1arte desde los conceptos m\u00e1s b\u00e1sicos hasta la creaci\u00f3n de un asistente virtual avanzado usando LangGraph 0.3.xx . Si buscas dominar el desarrollo de flujos de trabajo con modelos de lenguaje grande (LLMs) y optimizar tus proyectos de IA, est\u00e1s en el lugar adecuado . LangGraph es una herramienta poderosa para la creaci\u00f3n de pipelines modulares, paralelos y escalables , con capacidades que te permitir\u00e1n llevar tus aplicaciones de IA al siguiente nivel.","title":"\ud83d\ude80 \u00a1Bienvenido al Curso de LangGraph 0.3.xx!"},{"location":"#que-aprenderas-en-este-curso","text":"A lo largo de este curso, adquirir\u00e1s habilidades pr\u00e1cticas y te\u00f3ricas para: \u2705 Construir flujos de trabajo avanzados con LangGraph. \u2705 Crear pipelines din\u00e1micos y modulares que interact\u00faan con LLMs. \u2705 Implementar memoria a corto y largo plazo en tus aplicaciones. \u2705 Desplegar y escalar tus proyectos de IA en entornos reales. \u2705 Desarrollar un asistente virtual completo con memoria y capacidad de respuesta avanzada.","title":"\ud83d\udccb \u00bfQu\u00e9 Aprender\u00e1s en Este Curso?"},{"location":"#objetivos-del-curso","text":"Al finalizar, podr\u00e1s: - Construir pipelines completos con LangGraph que manejan consultas, flujos paralelos y enrutamiento condicional. - Crear asistentes virtuales con memoria persistente. - Optimizar y monitorizar flujos con herramientas como LangSmith y LangGraph Studio. - Desplegar tus aplicaciones de LangGraph en producci\u00f3n utilizando LangGraph Local Server o CLI.","title":"\ud83c\udfaf Objetivos del Curso"},{"location":"#estructura-del-curso","text":"El curso se divide en tres m\u00f3dulos principales , con teor\u00eda, ejemplos de c\u00f3digo y ejercicios pr\u00e1cticos:","title":"\ud83d\udcc2 Estructura del Curso"},{"location":"#modulo-1-fundamentos-y-componentes-basicos-de-langgraph","text":"\u00bfQu\u00e9 es LangGraph y para qu\u00e9 sirve? Creaci\u00f3n de nodos (Nodes) y conexiones (Edges). Control del estado y memoria (State Schema y Postgres). Construcci\u00f3n de flujos con chains y routers.","title":"M\u00f3dulo 1: Fundamentos y Componentes B\u00e1sicos de LangGraph"},{"location":"#modulo-2-aplicaciones-avanzadas-y-flujos-complejos","text":"Construcci\u00f3n de chatbots resumidores (Summarizing). Implementaci\u00f3n de puntos de interrupci\u00f3n y streaming. Ejecuci\u00f3n paralela de tareas y subgraf\u00edas. Sistemas de RAG (Retrieval-Augmented Generation). Uso de LangGraph Studio para visualizar flujos.","title":"M\u00f3dulo 2: Aplicaciones Avanzadas y Flujos Complejos"},{"location":"#modulo-3-despliegue-y-proyecto-final","text":"Despliegue de LangGraph en producci\u00f3n. Memoria a largo plazo con LangGraph Store. Creaci\u00f3n de APIs REST para LangGraph. Proyecto final: Asistente virtual completo.","title":"M\u00f3dulo 3: Despliegue y Proyecto Final"},{"location":"#requisitos-previos","text":"Conocimientos b\u00e1sicos de Python. Familiaridad con modelos de lenguaje grande (LLMs) . Experiencia en LangChain (opcional).","title":"\ud83d\udee0\ufe0f Requisitos Previos"},{"location":"#para-quien-esta-dirigido-este-curso","text":"Este curso es ideal para: - \ud83e\uddd1\u200d\ud83d\udcbb Desarrolladores de IA que quieren construir pipelines avanzados. - \ud83d\udcca Ingenieros de datos que buscan optimizar flujos de procesamiento de lenguaje natural. - \ud83d\udcda Investigadores y entusiastas que desean integrar LLMs en proyectos reales.","title":"\ud83d\udccc \u00bfPara Qui\u00e9n Est\u00e1 Dirigido Este Curso?"},{"location":"#resultado-final-del-curso","text":"Al completar el curso, habr\u00e1s desarrollado un asistente virtual funcional que: - Gestiona m\u00faltiples consultas con LLMs. - Mantiene memoria y contexto de conversaciones previas. - Ejecuci\u00f3n de tareas paralelas y flujos complejos. - Es capaz de desplegarse y escalarse en entornos de producci\u00f3n.","title":"\ud83c\udfc6 Resultado Final del Curso"},{"location":"#tecnologias-utilizadas","text":"LangGraph 0.3.xx LangChain (opcional) LangSmith (trazado y depuraci\u00f3n) OpenAI (u otros LLMs) Postgres (para memoria de corto plazo)","title":"\ud83d\udee0\ufe0f Tecnolog\u00edas Utilizadas"},{"location":"#certificacion-final","text":"Completar este curso te permitir\u00e1 obtener un certificado que acredita tus conocimientos en LangGraph 0.3.xx y la construcci\u00f3n de flujos avanzados con modelos de lenguaje. \ud83c\udf1f \u00a1Empieza tu viaje ahora y lleva tus habilidades de IA al siguiente nivel!","title":"\ud83d\udcdc Certificaci\u00f3n Final"},{"location":"curso1/","text":"\ud83d\udcda Curso 1: Fundamentos de LangGraph \ud83d\udc4b Bienvenida al Curso 1 \u00a1Bienvenidos al primer curso de Fundamentos de LangGraph! \ud83d\ude80 En este curso, nos sumergiremos en los conceptos esenciales para dominar LangGraph, una poderosa herramienta para construir flujos de trabajo complejos con modelos de lenguaje. Desde nodos y conexiones hasta la gesti\u00f3n de memoria y reducci\u00f3n de resultados, cubriremos todos los pilares clave que necesitas para crear aplicaciones con LLMs. \ud83c\udfaf \u00bfQu\u00e9 Aprenderemos? Comprender la estructura b\u00e1sica de LangGraph y sus ventajas. Crear y conectar nodos para formar flujos de trabajo. Implementar routers para enrutar din\u00e1micamente los datos. Utilizar reducers para consolidar y filtrar informaci\u00f3n. Manejar la memoria de estado (state schema) para flujos persistentes. Optimizar y filtrar mensajes con t\u00e9cnicas avanzadas de trim y filter . \ud83c\udfc6 Objetivo del Curso Al finalizar este curso, ser\u00e1s capaz de construir flujos de trabajo de LLM desde cero, comprender c\u00f3mo funciona LangGraph a nivel fundamental y aplicar este conocimiento para construir soluciones reales y escalables. \ud83d\udccb Temario Tema 1: Nodos Tema 2: Edges (Conexiones) Tema 3: State Schema Tema 3: Memoria Tema 5: Chains y Flujos de Trabajo Tema 6: Routers Tema 7: Reducers Tema 8: tools Tema 9: Trim y Filtrado de Mensajes \ud83c\udfc1 Resultado Final del Curso Habr\u00e1s construido flujos b\u00e1sicos de LLM usando LangGraph. Tendr\u00e1s una base s\u00f3lida para afrontar proyectos avanzados en los siguientes cursos. Entender\u00e1s los conceptos b\u00e1sicos de memoria, rutas y nodos aplicados en pipelines de procesamiento. \u2699\ufe0f Tecnolog\u00edas Utilizadas LangGraph 0.3.x Python 3.10+ FastAPI PostgreSQL para manejo de memoria Google Colab (opcional para pruebas)","title":"\ud83d\udcda Curso 1: Fundamentos de LangGraph"},{"location":"curso1/#curso-1-fundamentos-de-langgraph","text":"","title":"\ud83d\udcda Curso 1: Fundamentos de LangGraph"},{"location":"curso1/#bienvenida-al-curso-1","text":"\u00a1Bienvenidos al primer curso de Fundamentos de LangGraph! \ud83d\ude80 En este curso, nos sumergiremos en los conceptos esenciales para dominar LangGraph, una poderosa herramienta para construir flujos de trabajo complejos con modelos de lenguaje. Desde nodos y conexiones hasta la gesti\u00f3n de memoria y reducci\u00f3n de resultados, cubriremos todos los pilares clave que necesitas para crear aplicaciones con LLMs.","title":"\ud83d\udc4b Bienvenida al Curso 1"},{"location":"curso1/#que-aprenderemos","text":"Comprender la estructura b\u00e1sica de LangGraph y sus ventajas. Crear y conectar nodos para formar flujos de trabajo. Implementar routers para enrutar din\u00e1micamente los datos. Utilizar reducers para consolidar y filtrar informaci\u00f3n. Manejar la memoria de estado (state schema) para flujos persistentes. Optimizar y filtrar mensajes con t\u00e9cnicas avanzadas de trim y filter .","title":"\ud83c\udfaf \u00bfQu\u00e9 Aprenderemos?"},{"location":"curso1/#objetivo-del-curso","text":"Al finalizar este curso, ser\u00e1s capaz de construir flujos de trabajo de LLM desde cero, comprender c\u00f3mo funciona LangGraph a nivel fundamental y aplicar este conocimiento para construir soluciones reales y escalables.","title":"\ud83c\udfc6 Objetivo del Curso"},{"location":"curso1/#temario","text":"Tema 1: Nodos Tema 2: Edges (Conexiones) Tema 3: State Schema Tema 3: Memoria Tema 5: Chains y Flujos de Trabajo Tema 6: Routers Tema 7: Reducers Tema 8: tools Tema 9: Trim y Filtrado de Mensajes","title":"\ud83d\udccb Temario"},{"location":"curso1/#resultado-final-del-curso","text":"Habr\u00e1s construido flujos b\u00e1sicos de LLM usando LangGraph. Tendr\u00e1s una base s\u00f3lida para afrontar proyectos avanzados en los siguientes cursos. Entender\u00e1s los conceptos b\u00e1sicos de memoria, rutas y nodos aplicados en pipelines de procesamiento.","title":"\ud83c\udfc1 Resultado Final del Curso"},{"location":"curso1/#tecnologias-utilizadas","text":"LangGraph 0.3.x Python 3.10+ FastAPI PostgreSQL para manejo de memoria Google Colab (opcional para pruebas)","title":"\u2699\ufe0f Tecnolog\u00edas Utilizadas"},{"location":"curso1/tema1_nodos/","text":"\ud83e\udde9 Tema 1: Nodos en LangGraph \ud83e\udde9 \u00bfQu\u00e9 es un Nodo? En LangGraph, los nodos representan las operaciones fundamentales que se realizan en un flujo de trabajo. Cada nodo se encarga de procesar datos o estados, y a partir de esto, devolver un nuevo estado o resultado. Piensa en los nodos como piezas individuales de una m\u00e1quina que trabajan juntas para completar una tarea compleja. Los nodos est\u00e1n conectados mediante aristas (edges) que permiten el flujo de informaci\u00f3n entre ellos, formando un grafo que ejecuta operaciones de manera secuencial o condicional. \ud83d\udee0\ufe0f \u00bfC\u00f3mo Funciona un Nodo? Un nodo es una funci\u00f3n que toma un estado de entrada y devuelve un nuevo estado. Los nodos pueden representar tareas simples (como sumar n\u00fameros) o procesos m\u00e1s complejos (como ejecutar un modelo de IA). Cada nodo tiene una conexi\u00f3n hacia otros nodos, permitiendo que el flujo contin\u00fae seg\u00fan la l\u00f3gica definida. \ud83d\ude80 Ejemplo: Construyendo un Grafo con Nodos Para entender mejor c\u00f3mo funcionan los nodos, vamos a construir un grafo simple utilizando LangGraph . El objetivo ser\u00e1 simular un grafo que cambia de estado y elige diferentes caminos en funci\u00f3n de decisiones aleatorias. 1. Instalaci\u00f3n de LangGraph Primero, asegur\u00e9monos de tener instalada la librer\u00eda LangGraph. % pip install -- quiet - U langgraph 2. Definiendo el Estado del Grafo El estado del grafo es una estructura que guarda informaci\u00f3n sobre el progreso y los datos en cada paso. Aqu\u00ed definimos una clase State que representa el estado del grafo con una variable graph_state de tipo texto. from typing_extensions import TypedDict class State ( TypedDict ): graph_state : str 3. Creando los Nodos Ahora crearemos tres nodos simples: 1. Nodo 1 : Modifica el estado inicial agregando \"Me gusta. 2. Nodo 2 : A\u00f1ade \"programar!\" al estado. 3. Nodo 3 : A\u00f1ade \"salir en bici!\" al estado. Cada nodo es una funci\u00f3n que recibe el estado actual ( state ) y devuelve un nuevo estado modificado. def node_1 ( state ): print ( \"---Node 1---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" Me gusta\" } def node_2 ( state ): print ( \"---Node 2---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" programar!\" } def node_3 ( state ): print ( \"---Node 3---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" salir en bici!\" } 4. Agregando L\u00f3gica de Decisi\u00f3n Aqu\u00ed agregamos una funci\u00f3n decide_hooby que decide aleatoriamente si el flujo contin\u00faa hacia el Nodo 2 (programar) o el Nodo 3 (salir en bici) . Esto simula una bifurcaci\u00f3n en el camino que depender\u00e1 del resultado de una probabilidad del 50%. import random from typing import Literal def decide_hooby ( state ) -> Literal [ \"node_2\" , \"node_3\" ]: if random . random () < 0.5 : return \"node_2\" return \"node_3\" 5. Construcci\u00f3n del Grafo En este paso, construimos el grafo utilizando StateGraph . from IPython.display import Image , display from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"node_1\" , node_1 ) builder . add_node ( \"node_2\" , node_2 ) builder . add_node ( \"node_3\" , node_3 ) builder . add_edge ( START , \"node_1\" ) builder . add_conditional_edges ( \"node_1\" , decide_hooby ) builder . add_edge ( \"node_2\" , END ) builder . add_edge ( \"node_3\" , END ) graph = builder . compile () Vamos a explicar l\u00ednea por l\u00ednea: StateGraph(State) : Creamos una instancia de StateGraph y le pasamos el estado que definimos antes ( State ). \u00bfPor qu\u00e9 lo hacemos? : LangGraph necesita saber qu\u00e9 tipo de estado manejar\u00e1 el grafo. builder.add_node(\"node_1\", node_1) : A\u00f1adimos el Nodo 1 al grafo. El primer par\u00e1metro \"node_1\" es el identificador del nodo, y el segundo ( node_1 ) es la funci\u00f3n que ejecutar\u00e1. builder.add_node(\"node_2\", node_2) : Agregamos el Nodo 2 . Funciona de la misma forma que el Nodo 1. builder.add_node(\"node_3\", node_3) : Agregamos el Nodo 3 al grafo. builder.add_edge(START, \"node_1\") : Conectamos el punto de inicio ( START ) con el Nodo 1 . Esto significa que cuando el grafo comience, lo har\u00e1 en el Nodo 1. builder.add_conditional_edges(\"node_1\", decide_hooby) : Desde el Nodo 1 , agregamos una bifurcaci\u00f3n condicional que ejecutar\u00e1 la funci\u00f3n decide_hooby . Dependiendo del resultado, el flujo se dirigir\u00e1 hacia el Nodo 2 o 3 . builder.add_edge(\"node_2\", END) : Si el flujo llega al Nodo 2, este finalizar\u00e1 ( END ). builder.add_edge(\"node_3\", END) : De igual forma, si pasa por el Nodo 3, tambi\u00e9n finalizar\u00e1. Finalmente, compilamos el grafo : graph = builder.compile() : Ensambla el grafo con todos los nodos y conexiones. 6. Visualizaci\u00f3n del Grafo Para visualizar el grafo, usamos la funci\u00f3n draw_mermaid_png() que genera un diagrama del grafo. Esto nos permite ver gr\u00e1ficamente c\u00f3mo est\u00e1n conectados los nodos. display ( Image ( graph . get_graph () . draw_mermaid_png ())) 7. Invocamos el Grafo Para invocar el grafo, simplemente usamos el siguiente c\u00f3digo: graph . invoke ({ \"graph_state\" : \"Hola, me llamo Raul.\" }) Resultado 1 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta programar!' } Resultado 2 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta salir en bici!' } Como vemos, nuestro grafo ha creado dos cadenas diferentes basado en la aleatoriedad. Con esto podemos tener una idea b\u00e1sica de como funcionan los nodos y cual es su principal funci\u00f3n. \ud83d\udd0e Recursos: Definici\u00f3n: Nodos \ud83e\udde9 \u00bfQu\u00e9 Hemos Aprendido? Nodos : Son funciones que procesan datos y modifican el estado de un grafo. Decisiones Condicionales : Podemos agregar l\u00f3gica de bifurcaci\u00f3n para que el flujo tome diferentes caminos. StateGraph : Es la base sobre la que construimos el grafo, a\u00f1adiendo nodos y conexiones. Visualizaci\u00f3n : LangGraph permite visualizar gr\u00e1ficamente el flujo de trabajo. \ud83c\udf10 Siguientes Pasos En el siguiente tema aprenderemos sobre Edges (Conexiones) , que permiten conectar nodos y controlar el flujo de informaci\u00f3n entre ellos.","title":"Tema 1: Nodos"},{"location":"curso1/tema1_nodos/#tema-1-nodos-en-langgraph","text":"","title":"\ud83e\udde9 Tema 1: Nodos en LangGraph"},{"location":"curso1/tema1_nodos/#que-es-un-nodo","text":"En LangGraph, los nodos representan las operaciones fundamentales que se realizan en un flujo de trabajo. Cada nodo se encarga de procesar datos o estados, y a partir de esto, devolver un nuevo estado o resultado. Piensa en los nodos como piezas individuales de una m\u00e1quina que trabajan juntas para completar una tarea compleja. Los nodos est\u00e1n conectados mediante aristas (edges) que permiten el flujo de informaci\u00f3n entre ellos, formando un grafo que ejecuta operaciones de manera secuencial o condicional.","title":"\ud83e\udde9 \u00bfQu\u00e9 es un Nodo?"},{"location":"curso1/tema1_nodos/#como-funciona-un-nodo","text":"Un nodo es una funci\u00f3n que toma un estado de entrada y devuelve un nuevo estado. Los nodos pueden representar tareas simples (como sumar n\u00fameros) o procesos m\u00e1s complejos (como ejecutar un modelo de IA). Cada nodo tiene una conexi\u00f3n hacia otros nodos, permitiendo que el flujo contin\u00fae seg\u00fan la l\u00f3gica definida.","title":"\ud83d\udee0\ufe0f \u00bfC\u00f3mo Funciona un Nodo?"},{"location":"curso1/tema1_nodos/#ejemplo-construyendo-un-grafo-con-nodos","text":"Para entender mejor c\u00f3mo funcionan los nodos, vamos a construir un grafo simple utilizando LangGraph . El objetivo ser\u00e1 simular un grafo que cambia de estado y elige diferentes caminos en funci\u00f3n de decisiones aleatorias.","title":"\ud83d\ude80 Ejemplo: Construyendo un Grafo con Nodos"},{"location":"curso1/tema1_nodos/#1-instalacion-de-langgraph","text":"Primero, asegur\u00e9monos de tener instalada la librer\u00eda LangGraph. % pip install -- quiet - U langgraph","title":"1. Instalaci\u00f3n de LangGraph"},{"location":"curso1/tema1_nodos/#2-definiendo-el-estado-del-grafo","text":"El estado del grafo es una estructura que guarda informaci\u00f3n sobre el progreso y los datos en cada paso. Aqu\u00ed definimos una clase State que representa el estado del grafo con una variable graph_state de tipo texto. from typing_extensions import TypedDict class State ( TypedDict ): graph_state : str","title":"2. Definiendo el Estado del Grafo"},{"location":"curso1/tema1_nodos/#3-creando-los-nodos","text":"Ahora crearemos tres nodos simples: 1. Nodo 1 : Modifica el estado inicial agregando \"Me gusta. 2. Nodo 2 : A\u00f1ade \"programar!\" al estado. 3. Nodo 3 : A\u00f1ade \"salir en bici!\" al estado. Cada nodo es una funci\u00f3n que recibe el estado actual ( state ) y devuelve un nuevo estado modificado. def node_1 ( state ): print ( \"---Node 1---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" Me gusta\" } def node_2 ( state ): print ( \"---Node 2---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" programar!\" } def node_3 ( state ): print ( \"---Node 3---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" salir en bici!\" }","title":"3. Creando los Nodos"},{"location":"curso1/tema1_nodos/#4-agregando-logica-de-decision","text":"Aqu\u00ed agregamos una funci\u00f3n decide_hooby que decide aleatoriamente si el flujo contin\u00faa hacia el Nodo 2 (programar) o el Nodo 3 (salir en bici) . Esto simula una bifurcaci\u00f3n en el camino que depender\u00e1 del resultado de una probabilidad del 50%. import random from typing import Literal def decide_hooby ( state ) -> Literal [ \"node_2\" , \"node_3\" ]: if random . random () < 0.5 : return \"node_2\" return \"node_3\"","title":"4. Agregando L\u00f3gica de Decisi\u00f3n"},{"location":"curso1/tema1_nodos/#5-construccion-del-grafo","text":"En este paso, construimos el grafo utilizando StateGraph . from IPython.display import Image , display from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"node_1\" , node_1 ) builder . add_node ( \"node_2\" , node_2 ) builder . add_node ( \"node_3\" , node_3 ) builder . add_edge ( START , \"node_1\" ) builder . add_conditional_edges ( \"node_1\" , decide_hooby ) builder . add_edge ( \"node_2\" , END ) builder . add_edge ( \"node_3\" , END ) graph = builder . compile () Vamos a explicar l\u00ednea por l\u00ednea: StateGraph(State) : Creamos una instancia de StateGraph y le pasamos el estado que definimos antes ( State ). \u00bfPor qu\u00e9 lo hacemos? : LangGraph necesita saber qu\u00e9 tipo de estado manejar\u00e1 el grafo. builder.add_node(\"node_1\", node_1) : A\u00f1adimos el Nodo 1 al grafo. El primer par\u00e1metro \"node_1\" es el identificador del nodo, y el segundo ( node_1 ) es la funci\u00f3n que ejecutar\u00e1. builder.add_node(\"node_2\", node_2) : Agregamos el Nodo 2 . Funciona de la misma forma que el Nodo 1. builder.add_node(\"node_3\", node_3) : Agregamos el Nodo 3 al grafo. builder.add_edge(START, \"node_1\") : Conectamos el punto de inicio ( START ) con el Nodo 1 . Esto significa que cuando el grafo comience, lo har\u00e1 en el Nodo 1. builder.add_conditional_edges(\"node_1\", decide_hooby) : Desde el Nodo 1 , agregamos una bifurcaci\u00f3n condicional que ejecutar\u00e1 la funci\u00f3n decide_hooby . Dependiendo del resultado, el flujo se dirigir\u00e1 hacia el Nodo 2 o 3 . builder.add_edge(\"node_2\", END) : Si el flujo llega al Nodo 2, este finalizar\u00e1 ( END ). builder.add_edge(\"node_3\", END) : De igual forma, si pasa por el Nodo 3, tambi\u00e9n finalizar\u00e1. Finalmente, compilamos el grafo : graph = builder.compile() : Ensambla el grafo con todos los nodos y conexiones.","title":"5. Construcci\u00f3n del Grafo"},{"location":"curso1/tema1_nodos/#6-visualizacion-del-grafo","text":"Para visualizar el grafo, usamos la funci\u00f3n draw_mermaid_png() que genera un diagrama del grafo. Esto nos permite ver gr\u00e1ficamente c\u00f3mo est\u00e1n conectados los nodos. display ( Image ( graph . get_graph () . draw_mermaid_png ()))","title":"6. Visualizaci\u00f3n del Grafo"},{"location":"curso1/tema1_nodos/#7-invocamos-el-grafo","text":"Para invocar el grafo, simplemente usamos el siguiente c\u00f3digo: graph . invoke ({ \"graph_state\" : \"Hola, me llamo Raul.\" }) Resultado 1 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta programar!' } Resultado 2 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta salir en bici!' } Como vemos, nuestro grafo ha creado dos cadenas diferentes basado en la aleatoriedad. Con esto podemos tener una idea b\u00e1sica de como funcionan los nodos y cual es su principal funci\u00f3n.","title":"7. Invocamos el Grafo"},{"location":"curso1/tema1_nodos/#recursos","text":"Definici\u00f3n: Nodos","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema1_nodos/#que-hemos-aprendido","text":"Nodos : Son funciones que procesan datos y modifican el estado de un grafo. Decisiones Condicionales : Podemos agregar l\u00f3gica de bifurcaci\u00f3n para que el flujo tome diferentes caminos. StateGraph : Es la base sobre la que construimos el grafo, a\u00f1adiendo nodos y conexiones. Visualizaci\u00f3n : LangGraph permite visualizar gr\u00e1ficamente el flujo de trabajo.","title":"\ud83e\udde9 \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema1_nodos/#siguientes-pasos","text":"En el siguiente tema aprenderemos sobre Edges (Conexiones) , que permiten conectar nodos y controlar el flujo de informaci\u00f3n entre ellos.","title":"\ud83c\udf10 Siguientes Pasos"},{"location":"curso1/tema2_edges/","text":"\ud83c\udfaf Tema 2: Edges (Conexiones) \ud83e\udde9 \u00bfQu\u00e9 son los Edges? Los edges son las conexiones entre nodos que dirigen el flujo de datos de un nodo a otro. Estas conexiones pueden ser: Directas: Conectan un nodo con el siguiente sin condiciones. Condicionales: Deciden din\u00e1micamente qu\u00e9 nodo visitar a continuaci\u00f3n bas\u00e1ndose en una funci\u00f3n l\u00f3gica. En este ejemplo, utilizaremos un flujo de decisi\u00f3n aleatorio para mostrar c\u00f3mo se pueden agregar edges y bifurcaciones. \ud83d\udee0\ufe0f Ejemplo Pr\u00e1ctico: Construyendo un Grafo con Edges Usando el c\u00f3digo usado anteriormente con los nodos, mostramos el c\u00f3digo de ejemplo que ilustra c\u00f3mo agregar edges entre nodos: def node_1 ( state ): print ( \"---Node 1---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" Me gusta\" } def node_2 ( state ): print ( \"---Node 2---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" programar!\" } def node_3 ( state ): print ( \"---Node 3---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" salir en bici!\" } \ud83d\udd0d Explicaci\u00f3n Paso a Paso \ud83d\udccc Definici\u00f3n de Nodos from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"node_1\" , node_1 ) builder . add_node ( \"node_2\" , node_2 ) builder . add_node ( \"node_3\" , node_3 ) node_1 : A\u00f1ade al estado \"Me gusta\" . node_2 : A\u00f1ade al estado \"programar!\" . node_3 : A\u00f1ade al estado \"salir en bici!\" . En este caso, node_1 act\u00faa como punto de partida para las decisiones que se tomar\u00e1n posteriormente. \ud83d\udd04 Decisi\u00f3n con Condiciones import random from typing import Literal def decide_hooby ( state ) -> Literal [ \"node_2\" , \"node_3\" ]: if random . random () < 0.5 : return \"node_2\" return \"node_3\" La funci\u00f3n decide_hooby decide, de forma aleatoria, si el flujo debe continuar hacia node_2 o node_3 . 50% de probabilidad de ir a node_2 (programar). 50% de probabilidad de ir a node_3 (salir en bici). Este edge condicional permite que el grafo tenga m\u00faltiples rutas de ejecuci\u00f3n. \ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo builder . add_edge ( START , \"node_1\" ) builder . add_conditional_edges ( \"node_1\" , decide_hooby ) builder . add_edge ( \"node_2\" , END ) builder . add_edge ( \"node_3\" , END ) graph = builder . compile () add_edge : Conecta directamente START con node_1 . add_conditional_edges : Desde node_1 , el flujo se bifurca condicionalmente hacia node_2 o node_3 . add_edge (Final) : Ambos nodos ( node_2 y node_3 ) terminan en el nodo final END . \ud83d\udcc8 Visualizando el Grafo Una vez construido, podemos visualizar el grafo: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) \u2699\ufe0f Invocando el Grafo Para ejecutar el grafo y ver su comportamiento, utilizamos: graph . invoke ({ \"graph_state\" : \"Hola, me llamo Raul.\" }) Resultado 1 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta programar!' } Resultado 2 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta salir en bici!' } \ud83d\udd0e Recursos: Gu\u00eda: Edges \ud83e\udde9 \u00bfQu\u00e9 Hemos Aprendido? Edges (Conexiones): Son las rutas que conectan nodos en el grafo, permitiendo el flujo de informaci\u00f3n de un nodo a otro. Edges Condicionales: Permiten bifurcaciones en el flujo, tomando decisiones din\u00e1micas que afectan el camino que sigue el grafo. Flujo de Trabajo Din\u00e1mico: Al conectar nodos de forma condicional, podemos crear grafos m\u00e1s complejos y adaptativos, generando diferentes resultados seg\u00fan la l\u00f3gica aplicada. Construcci\u00f3n de Grafos: Hemos aprendido a agregar nodos, edges y compilar el grafo usando StateGraph y add_edge . \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el siguiente tema, profundizaremos en State Schema y Memoria . Aprenderemos: - C\u00f3mo almacenar y mantener el estado a lo largo del flujo del grafo. - Estrategias para preservar memoria en LangGraph. - Esquemas de estado personalizados para que el grafo retenga y modifique informaci\u00f3n de manera continua. \u00a1Nos vemos en el pr\u00f3ximo tema! \ud83d\ude80","title":"Tema 2: Edges (Conexiones)"},{"location":"curso1/tema2_edges/#tema-2-edges-conexiones","text":"","title":"\ud83c\udfaf Tema 2: Edges (Conexiones)"},{"location":"curso1/tema2_edges/#que-son-los-edges","text":"Los edges son las conexiones entre nodos que dirigen el flujo de datos de un nodo a otro. Estas conexiones pueden ser: Directas: Conectan un nodo con el siguiente sin condiciones. Condicionales: Deciden din\u00e1micamente qu\u00e9 nodo visitar a continuaci\u00f3n bas\u00e1ndose en una funci\u00f3n l\u00f3gica. En este ejemplo, utilizaremos un flujo de decisi\u00f3n aleatorio para mostrar c\u00f3mo se pueden agregar edges y bifurcaciones.","title":"\ud83e\udde9 \u00bfQu\u00e9 son los Edges?"},{"location":"curso1/tema2_edges/#ejemplo-practico-construyendo-un-grafo-con-edges","text":"Usando el c\u00f3digo usado anteriormente con los nodos, mostramos el c\u00f3digo de ejemplo que ilustra c\u00f3mo agregar edges entre nodos: def node_1 ( state ): print ( \"---Node 1---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" Me gusta\" } def node_2 ( state ): print ( \"---Node 2---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" programar!\" } def node_3 ( state ): print ( \"---Node 3---\" ) return { \"graph_state\" : state [ 'graph_state' ] + \" salir en bici!\" }","title":"\ud83d\udee0\ufe0f Ejemplo Pr\u00e1ctico: Construyendo un Grafo con Edges"},{"location":"curso1/tema2_edges/#explicacion-paso-a-paso","text":"","title":"\ud83d\udd0d Explicaci\u00f3n Paso a Paso"},{"location":"curso1/tema2_edges/#definicion-de-nodos","text":"from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"node_1\" , node_1 ) builder . add_node ( \"node_2\" , node_2 ) builder . add_node ( \"node_3\" , node_3 ) node_1 : A\u00f1ade al estado \"Me gusta\" . node_2 : A\u00f1ade al estado \"programar!\" . node_3 : A\u00f1ade al estado \"salir en bici!\" . En este caso, node_1 act\u00faa como punto de partida para las decisiones que se tomar\u00e1n posteriormente.","title":"\ud83d\udccc Definici\u00f3n de Nodos"},{"location":"curso1/tema2_edges/#decision-con-condiciones","text":"import random from typing import Literal def decide_hooby ( state ) -> Literal [ \"node_2\" , \"node_3\" ]: if random . random () < 0.5 : return \"node_2\" return \"node_3\" La funci\u00f3n decide_hooby decide, de forma aleatoria, si el flujo debe continuar hacia node_2 o node_3 . 50% de probabilidad de ir a node_2 (programar). 50% de probabilidad de ir a node_3 (salir en bici). Este edge condicional permite que el grafo tenga m\u00faltiples rutas de ejecuci\u00f3n.","title":"\ud83d\udd04 Decisi\u00f3n con Condiciones"},{"location":"curso1/tema2_edges/#construccion-del-grafo","text":"builder . add_edge ( START , \"node_1\" ) builder . add_conditional_edges ( \"node_1\" , decide_hooby ) builder . add_edge ( \"node_2\" , END ) builder . add_edge ( \"node_3\" , END ) graph = builder . compile () add_edge : Conecta directamente START con node_1 . add_conditional_edges : Desde node_1 , el flujo se bifurca condicionalmente hacia node_2 o node_3 . add_edge (Final) : Ambos nodos ( node_2 y node_3 ) terminan en el nodo final END .","title":"\ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo"},{"location":"curso1/tema2_edges/#visualizando-el-grafo","text":"Una vez construido, podemos visualizar el grafo: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ()))","title":"\ud83d\udcc8 Visualizando el Grafo"},{"location":"curso1/tema2_edges/#invocando-el-grafo","text":"Para ejecutar el grafo y ver su comportamiento, utilizamos: graph . invoke ({ \"graph_state\" : \"Hola, me llamo Raul.\" }) Resultado 1 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta programar!' } Resultado 2 --- Node 1 --- --- Node 3 --- { 'graph_state' : 'Hola, me llamo Raul. Me gusta salir en bici!' }","title":"\u2699\ufe0f Invocando el Grafo"},{"location":"curso1/tema2_edges/#recursos","text":"Gu\u00eda: Edges","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema2_edges/#que-hemos-aprendido","text":"Edges (Conexiones): Son las rutas que conectan nodos en el grafo, permitiendo el flujo de informaci\u00f3n de un nodo a otro. Edges Condicionales: Permiten bifurcaciones en el flujo, tomando decisiones din\u00e1micas que afectan el camino que sigue el grafo. Flujo de Trabajo Din\u00e1mico: Al conectar nodos de forma condicional, podemos crear grafos m\u00e1s complejos y adaptativos, generando diferentes resultados seg\u00fan la l\u00f3gica aplicada. Construcci\u00f3n de Grafos: Hemos aprendido a agregar nodos, edges y compilar el grafo usando StateGraph y add_edge .","title":"\ud83e\udde9 \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema2_edges/#que-es-lo-siguiente","text":"En el siguiente tema, profundizaremos en State Schema y Memoria . Aprenderemos: - C\u00f3mo almacenar y mantener el estado a lo largo del flujo del grafo. - Estrategias para preservar memoria en LangGraph. - Esquemas de estado personalizados para que el grafo retenga y modifique informaci\u00f3n de manera continua. \u00a1Nos vemos en el pr\u00f3ximo tema! \ud83d\ude80","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema3_state_schema/","text":"\ud83e\udde9 Tema 3: State Schema \ud83d\ude80 \u00bfQu\u00e9 es el State Schema? El State Schema en LangGraph define la estructura de datos que viaja a trav\u00e9s de un grafo durante su ejecuci\u00f3n. Es como el \u201cADN\u201d del flujo, que transporta y actualiza informaci\u00f3n a medida que se avanza por diferentes nodos, piensa en el estado como una mochila \ud83e\uddf3 que lleva datos entre los nodos, la cual vamos llenando o vaciando a medida que vamos necesitando. \ud83e\udde0 \u00bfPor qu\u00e9 es importante? El State Schema permite: - Controlar y validar los datos que circulan por el grafo. - Definir tipos de datos espec\u00edficos (texto, listas, enteros, etc.) para evitar errores. - Modificar y actualizar atributos a lo largo del flujo. Imagina que est\u00e1s construyendo un asistente virtual: - El State podr\u00eda contener atributos como el nombre del usuario, historial de mensajes y preferencias. - A medida que la conversaci\u00f3n avanza, los nodos modifican o consultan estos atributos. \u2699\ufe0f \u00bfC\u00f3mo se Define el State Schema? Para definir un State personalizado, utilizamos TypedDict . Esto nos permite crear una plantilla de estado con atributos espec\u00edficos y sus respectivos tipos. \ud83d\udccb Ejemplo: Creaci\u00f3n de un State con Varios Atributos from typing_extensions import TypedDict from typing import Literal class State ( TypedDict ): name : str age : int preferences : Literal [ \"Videojuegos\" , \"Programaci\u00f3n\" ] \ud83e\udde9 Explicaci\u00f3n: TypedDict crea una plantilla para el estado. name y age son atributos que definen el nombre y edad de un usuario. preferences es una lista que guarda intereses o preferencias. Usando Literal forzamos a que la aplicaci\u00f3n solamente guarde esos terminos en concreto. Con esto, aseguramos que el estado tenga una estructura clara y solo acepte los tipos de datos definidos. \ud83d\udd04 \u00bfC\u00f3mo Funciona el State en un Grafo? El State fluye de un nodo a otro, llevando consigo informaci\u00f3n que puede ser modificada, eliminada o ampliada . Cada nodo puede: - Leer atributos del estado. - Modificar datos existentes. - Agregar nuevos atributos si es necesario. Esto nos permite construir flujos din\u00e1micos y adaptativos, donde el grafo evoluciona seg\u00fan las interacciones del usuario o los c\u00e1lculos realizados. \ud83d\udee0\ufe0f Ejemplo Completo con Nodos Vamos a construir un grafo que: 1. Reciba el nombre y edad del usuario. 2. Modifique el estado agregando una preferencia de acuerdo con la edad. \ud83d\udccb Definiendo Nodos para Modificar el Estado def user_input_node ( state : State ): print ( \"--- Nodo 1: Recibir Usuario ---\" ) state [ \"name\" ] = \"Raul\" state [ \"preferences\" ] = [] return state def recommendation_node ( state : State ): print ( \"--- Nodo 2: Recomendaci\u00f3n ---\" ) if state [ \"age\" ] < 18 : state [ \"preferences\" ] . append ( \"Videojuegos\" ) else : state [ \"preferences\" ] . append ( \"Programaci\u00f3n\" ) return state Nodo user_input_node : Toma el nombre, inicializa las preferencias y los a\u00f1ade al estado. Nodo recommendation_node : Agrega recomendaciones basadas en la edad del usuario. \ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input_node ) builder . add_node ( \"recommendation\" , recommendation_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"recommendation\" ) builder . add_edge ( \"recommendation\" , END ) graph = builder . compile () Explicaci\u00f3n de cada paso: 1. Creamos el grafo con StateGraph . 2. A\u00f1adimos los nodos. 3. Definimos el flujo: - El grafo comienza en START y pasa por user_input_node . - Luego se dirige a recommendation_node antes de finalizar ( END ). \ud83d\udcc8 Visualizaci\u00f3n del Grafo Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) \ud83d\ude80 Invocando el Grafo y Resultados Ejecuci\u00f3n del Grafo graph . invoke ({ \"name\" : \"\" , \"age\" : 40 }) Resultado --- Nodo 1 : Recibir Usuario --- --- Nodo 2 : Recomendaci\u00f3n --- { 'name' : 'Raul' , 'age' : 40 , 'preferences' : [ 'Programaci\u00f3n' ]} Si el usuario tiene menos de 18 a\u00f1os, el grafo recomienda videojuegos. Si tiene 18 o m\u00e1s, se recomienda programaci\u00f3n. \ud83d\udd0e Recursos: Ver notebook en Google Colab Ver M\u00e1s ejemplos en Google Colab Gu\u00eda: State \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? State Schema: Define la estructura de datos que viaja por el grafo. TypedDict: Permite definir el esquema con tipos espec\u00edficos, asegurando que el estado tenga una estructura clara y validada. Nodos y Estado: Los nodos pueden modificar y ampliar el estado, creando flujos din\u00e1micos. Literal : Podemos filtar la informaci\u00f3n que vamos a manejar. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el pr\u00f3ximo tema, profundizaremos en el uso de Memoria en LangGraph . Aprenderemos c\u00f3mo usar MemorySaver para almacenar datos a lo largo de m\u00faltiples invocaciones, creando flujos de trabajo que recuerdan informaci\u00f3n pasada.","title":"Tema 3: State Schema"},{"location":"curso1/tema3_state_schema/#tema-3-state-schema","text":"","title":"\ud83e\udde9 Tema 3: State Schema"},{"location":"curso1/tema3_state_schema/#que-es-el-state-schema","text":"El State Schema en LangGraph define la estructura de datos que viaja a trav\u00e9s de un grafo durante su ejecuci\u00f3n. Es como el \u201cADN\u201d del flujo, que transporta y actualiza informaci\u00f3n a medida que se avanza por diferentes nodos, piensa en el estado como una mochila \ud83e\uddf3 que lleva datos entre los nodos, la cual vamos llenando o vaciando a medida que vamos necesitando.","title":"\ud83d\ude80 \u00bfQu\u00e9 es el State Schema?"},{"location":"curso1/tema3_state_schema/#por-que-es-importante","text":"El State Schema permite: - Controlar y validar los datos que circulan por el grafo. - Definir tipos de datos espec\u00edficos (texto, listas, enteros, etc.) para evitar errores. - Modificar y actualizar atributos a lo largo del flujo. Imagina que est\u00e1s construyendo un asistente virtual: - El State podr\u00eda contener atributos como el nombre del usuario, historial de mensajes y preferencias. - A medida que la conversaci\u00f3n avanza, los nodos modifican o consultan estos atributos.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 es importante?"},{"location":"curso1/tema3_state_schema/#como-se-define-el-state-schema","text":"Para definir un State personalizado, utilizamos TypedDict . Esto nos permite crear una plantilla de estado con atributos espec\u00edficos y sus respectivos tipos.","title":"\u2699\ufe0f \u00bfC\u00f3mo se Define el State Schema?"},{"location":"curso1/tema3_state_schema/#ejemplo-creacion-de-un-state-con-varios-atributos","text":"from typing_extensions import TypedDict from typing import Literal class State ( TypedDict ): name : str age : int preferences : Literal [ \"Videojuegos\" , \"Programaci\u00f3n\" ]","title":"\ud83d\udccb Ejemplo: Creaci\u00f3n de un State con Varios Atributos"},{"location":"curso1/tema3_state_schema/#explicacion","text":"TypedDict crea una plantilla para el estado. name y age son atributos que definen el nombre y edad de un usuario. preferences es una lista que guarda intereses o preferencias. Usando Literal forzamos a que la aplicaci\u00f3n solamente guarde esos terminos en concreto. Con esto, aseguramos que el estado tenga una estructura clara y solo acepte los tipos de datos definidos.","title":"\ud83e\udde9 Explicaci\u00f3n:"},{"location":"curso1/tema3_state_schema/#como-funciona-el-state-en-un-grafo","text":"El State fluye de un nodo a otro, llevando consigo informaci\u00f3n que puede ser modificada, eliminada o ampliada . Cada nodo puede: - Leer atributos del estado. - Modificar datos existentes. - Agregar nuevos atributos si es necesario. Esto nos permite construir flujos din\u00e1micos y adaptativos, donde el grafo evoluciona seg\u00fan las interacciones del usuario o los c\u00e1lculos realizados.","title":"\ud83d\udd04 \u00bfC\u00f3mo Funciona el State en un Grafo?"},{"location":"curso1/tema3_state_schema/#ejemplo-completo-con-nodos","text":"Vamos a construir un grafo que: 1. Reciba el nombre y edad del usuario. 2. Modifique el estado agregando una preferencia de acuerdo con la edad.","title":"\ud83d\udee0\ufe0f Ejemplo Completo con Nodos"},{"location":"curso1/tema3_state_schema/#definiendo-nodos-para-modificar-el-estado","text":"def user_input_node ( state : State ): print ( \"--- Nodo 1: Recibir Usuario ---\" ) state [ \"name\" ] = \"Raul\" state [ \"preferences\" ] = [] return state def recommendation_node ( state : State ): print ( \"--- Nodo 2: Recomendaci\u00f3n ---\" ) if state [ \"age\" ] < 18 : state [ \"preferences\" ] . append ( \"Videojuegos\" ) else : state [ \"preferences\" ] . append ( \"Programaci\u00f3n\" ) return state Nodo user_input_node : Toma el nombre, inicializa las preferencias y los a\u00f1ade al estado. Nodo recommendation_node : Agrega recomendaciones basadas en la edad del usuario.","title":"\ud83d\udccb Definiendo Nodos para Modificar el Estado"},{"location":"curso1/tema3_state_schema/#construccion-del-grafo","text":"from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input_node ) builder . add_node ( \"recommendation\" , recommendation_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"recommendation\" ) builder . add_edge ( \"recommendation\" , END ) graph = builder . compile () Explicaci\u00f3n de cada paso: 1. Creamos el grafo con StateGraph . 2. A\u00f1adimos los nodos. 3. Definimos el flujo: - El grafo comienza en START y pasa por user_input_node . - Luego se dirige a recommendation_node antes de finalizar ( END ).","title":"\ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo"},{"location":"curso1/tema3_state_schema/#visualizacion-del-grafo","text":"Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ()))","title":"\ud83d\udcc8 Visualizaci\u00f3n del Grafo"},{"location":"curso1/tema3_state_schema/#invocando-el-grafo-y-resultados","text":"","title":"\ud83d\ude80 Invocando el Grafo y Resultados"},{"location":"curso1/tema3_state_schema/#ejecucion-del-grafo","text":"graph . invoke ({ \"name\" : \"\" , \"age\" : 40 }) Resultado --- Nodo 1 : Recibir Usuario --- --- Nodo 2 : Recomendaci\u00f3n --- { 'name' : 'Raul' , 'age' : 40 , 'preferences' : [ 'Programaci\u00f3n' ]} Si el usuario tiene menos de 18 a\u00f1os, el grafo recomienda videojuegos. Si tiene 18 o m\u00e1s, se recomienda programaci\u00f3n.","title":"Ejecuci\u00f3n del Grafo"},{"location":"curso1/tema3_state_schema/#recursos","text":"Ver notebook en Google Colab Ver M\u00e1s ejemplos en Google Colab Gu\u00eda: State","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema3_state_schema/#que-hemos-aprendido","text":"State Schema: Define la estructura de datos que viaja por el grafo. TypedDict: Permite definir el esquema con tipos espec\u00edficos, asegurando que el estado tenga una estructura clara y validada. Nodos y Estado: Los nodos pueden modificar y ampliar el estado, creando flujos din\u00e1micos. Literal : Podemos filtar la informaci\u00f3n que vamos a manejar.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema3_state_schema/#que-es-lo-siguiente","text":"En el pr\u00f3ximo tema, profundizaremos en el uso de Memoria en LangGraph . Aprenderemos c\u00f3mo usar MemorySaver para almacenar datos a lo largo de m\u00faltiples invocaciones, creando flujos de trabajo que recuerdan informaci\u00f3n pasada.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema4_memory/","text":"\ud83e\udde0 Tema 4: Memoria \ud83d\udd75 \u00bfQu\u00e9 es el la Memoria? La memoria es la capacidad que tiene el grafo para recordar informaci\u00f3n a lo largo de m\u00faltiples invocaciones. Es especialmente \u00fatil cuando creamos chatbots o flujos conversacionales donde el contexto es crucial. Sin memoria: Cada vez que invocamos el grafo, comienza desde cero. Con memoria: El grafo guarda un historial de mensajes o datos, permitiendo respuestas basadas en todo el contexto anterior. \u00bfPor qu\u00e9 es importante? - Persistencia de datos. - Toma de decisiones basadas en el contexto actual. - Mayor precisi\u00f3n en interacciones prolongadas. \ud83d\udee0\ufe0f \u00bfC\u00f3mo Funciona? LangGraph ofrece varios tipos de memoria: Memoria de Estado (State Memory): El estado se transfiere de nodo a nodo, reteniendo informaci\u00f3n solo durante una invocaci\u00f3n. Memoria de Corto Alcance (MemorySaver): Guarda datos durante m\u00faltiples invocaciones, pero no persiste despu\u00e9s de cerrar el programa. Almacena la informaci\u00f3n en memoria vol\u00e1til (RAM). Ideal para flujos temporales que necesitan recordar el contexto durante la sesi\u00f3n actual. \ud83d\udc49 Documentaci\u00f3n de MemorySaver Memoria Persistente (Postgres u otros): Permite almacenar el historial en bases de datos externas (ej: PostgreSQL). Se ver\u00e1 en temas m\u00e1s avanzados. Memoria Transversal (Cross-Session Memory): Conserva datos a lo largo de m\u00faltiples sesiones y usuarios. Se estudiar\u00e1 en profundidad en futuros m\u00f3dulos. \ud83e\udde9 Implementaci\u00f3n de MemorySaver Usando el ejemplo que vimos anteriormente en art\u00edculos pasados, vamos a definir un grafo sencillo para poder ver como actula el MemorySaver : CustomState: Definimos un custom state para almacenar los mensajes. Nodo de entrada del usuario: Agrega el mensaje del usuario al estado. Nodo de respuesta de IA: El modelo de OpenAI ( gpt-4o-mini ) genera una respuesta basada en el historial. from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage , AIMessage , SystemMessage llm = ChatOpenAI ( model = \"gpt-4o-mini\" ) class CustomState ( MessagesState ): messages : list [ AIMessage | HumanMessage | SystemMessage ] = [] # Nodo de entrada del usuario def user_input_node ( state : CustomState ): print ( \"--- Usuario dice ---\" ) print ( state [ 'messages' ][ - 1 ] . content ) return { \"messages\" : state [ 'messages' ]} # Nodo de IA (respuesta) def ai_response_node ( state : CustomState ): print ( \"--- IA responde ---\" ) response = llm . invoke ( state [ 'messages' ]) print ( response . content ) return { \"messages\" : state [ 'messages' ] + [ AIMessage ( content = response . content )]} user_input_node: Toma el mensaje del usuario y lo guarda en el estado. ai_response_node: Usa el estado actual (historial) para generar una respuesta de IA. \ud83c\udfd7\ufe0f A\u00f1adiendo Memoria al Grafo Ahora implementaremos el MemorySaver para agregar memoria de corto alcance a nuestro grafo. \ud83d\udccb Grafo sin Memoria En el siguiente ejemplo, vamos a ver un grafo b\u00e1sico, como ya hemos visto hasta ahora, solamente para poder ver la diferencia para cuando le apliquemos nuestra memoria. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input_node ) builder . add_node ( \"ai_response\" , ai_response_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"ai_response\" ) builder . add_edge ( \"ai_response\" , END ) graph_no_memory = builder . compile () \ud83d\udccb Grafo con Memoria Ahora, agregaremos una memoria temporal y comprobaremos si nuestro grafo es capaz de retener informaci\u00f3n para poderla usar mas adelante. from langgraph.graph import StateGraph , START , END from langgraph.checkpoint.memory import MemorySaver memory = MemorySaver () builder_mem = StateGraph ( State ) builder_mem . add_node ( \"user_input\" , user_input_node ) builder_mem . add_node ( \"ai_response\" , ai_response_node ) builder_mem . add_edge ( START , \"user_input\" ) builder_mem . add_edge ( \"user_input\" , \"ai_response\" ) builder_mem . add_edge ( \"ai_response\" , END ) graph_memory = builder_mem . compile ( checkpointer = memory ) \ud83d\udcc8 Visualizaci\u00f3n del Grafo Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph_no_memory . get_graph () . draw_mermaid_png ())) display ( Image ( graph_memory . get_graph () . draw_mermaid_png ())) \ud83d\ude80 Invocando el Grafo y Comparando Resultados \ud83d\udccb Sin Memoria graph_no_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"Hola, me llamo Raul.\" )]}) graph_no_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )]}) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- No tengo acceso a informaci\u00f3n personal sobre los usuarios , as\u00ed que no s\u00e9 c\u00f3mo te llamas . Pero si quieres , puedes decirme tu nombre . \u00a1 Estoy aqu\u00ed para ayudarte ! Como vemos el grafo no guarda el hist\u00f3rico del chat, haciendo que el LLM no pueda tener acceso a informaci\u00f3n previa, por eso no es capaz de recordar mi nombre. \ud83d\udccb Con Memoria config = { \"configurable\" : { \"thread_id\" : \"1\" }} # Agregamos el config a nuestros invokes graph_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"Hola, me llamo Raul.\" )]}, config ) graph_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )]}, config ) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- Te llamas Ra\u00fal . \u00bf Hay algo m\u00e1s en lo que te pueda ayudar ? El par\u00e1metro config es fundamental para habilitar el seguimiento de sesiones individuales cuando utilizamos memoria con MemorySaver . - thread_id act\u00faa como un identificador \u00fanico para cada sesi\u00f3n o conversaci\u00f3n. - Esto permite que LangGraph recuerde informaci\u00f3n espec\u00edfica de una sesi\u00f3n y la distinga de otras conversaciones paralelas. \ud83e\udde9 \u00bfQu\u00e9 sucede sin thread_id ? Si no agregamos thread_id : - Cada invocaci\u00f3n del grafo se trata como una nueva sesi\u00f3n , incluso si estamos usando MemorySaver . - El grafo no podr\u00e1 recordar mensajes previos porque no tendr\u00e1 forma de asociarlos a una misma sesi\u00f3n. \ud83d\ude80 \u00bfCu\u00e1ndo usar thread_id ? Chats personalizados : Cuando manejamos m\u00faltiples usuarios o conversaciones. Bots conversacionales : Para mantener el contexto de usuarios durante largas interacciones. Flujos multi-sesi\u00f3n : Si queremos permitir que un usuario retome una conversaci\u00f3n anterior. \ud83e\udde9 Alternativa a MemorySaver La forma m\u00e1s efectiva de aplicar memoria de corto alcance en LangGraph es utilizando MemorySaver . Sin embargo, existen otras alternativas que pueden resultar \u00fatiles en ciertos casos. Una de las opciones m\u00e1s simples es almacenar el historial de la conversaci\u00f3n en una variable y pasarla continuamente durante cada invocaci\u00f3n. De esta manera, el modelo de lenguaje (LLM) mantiene el contexto de la conversaci\u00f3n sin depender de sistemas de memoria externos. A continuaci\u00f3n, veremos un ejemplo sencillo para entender c\u00f3mo implementar esta t\u00e9cnica: # Almacenamos las preguntas y respuestas en una variable. messages = [ HumanMessage ( content = \"Hola, me llamo Raul.\" )] response = graph_no_memory . invoke ({ \"messages\" : messages }) messages . append ( response . get ( 'messages' )[ - 1 ]) messages . append ( HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )) response = graph_no_memory . invoke ({ \"messages\" : messages }) messages . append ( response . get ( 'messages' )[ - 1 ]) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- Te llamas Ra\u00fal . \u00bf Hay algo m\u00e1s con lo que te pueda ayudar ? Guardamos los mensajes en una lista ( messages ) que act\u00faa como historial de conversaci\u00f3n. Tras cada invocaci\u00f3n al grafo, agregamos la respuesta generada por la IA al historial. Cuando el usuario realiza una nueva pregunta, enviamos el historial completo al grafo para que el modelo mantenga el contexto . \ud83e\uddd1\u200d\ud83c\udfeb Observaciones Importantes Esta t\u00e9cnica proporciona memoria temporal , pero requiere gesti\u00f3n manual del historial de mensajes. El historial puede almacenarse: En una variable. En una base de datos. En un archivo externo. Aunque m\u00e1s adelante exploraremos m\u00e9todos m\u00e1s avanzados y optimizados (como memoria persistente con bases de datos), esta soluci\u00f3n puede ser una forma sencilla y efectiva para proyectos que no requieren una arquitectura compleja. \ud83d\udd0e Recursos: Ver notebook en Google Colab How-to-guide: MemorySaver \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? Memoria de Estado (State): Solo persiste durante la ejecuci\u00f3n de una invocaci\u00f3n. MemorySaver: Proporciona memoria de corto alcance para retener datos durante m\u00faltiples invocaciones. Diferencias Clave: Sin memoria, cada invocaci\u00f3n es independiente. Con memoria, el grafo recuerda datos anteriores. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el siguiente tema exploraremos Chains y Flujos de Trabajo , donde aprenderemos a encadenar nodos y construir pipelines complejos. Tambi\u00e9n abordaremos el tema de Tools (Herramientas) , pero lo veremos despu\u00e9s de Chains , ya que comprender primero el flujo de trabajo har\u00e1 que la integraci\u00f3n de herramientas sea m\u00e1s sencilla y pr\u00e1ctica.","title":"Tema 4: Memoria"},{"location":"curso1/tema4_memory/#tema-4-memoria","text":"","title":"\ud83e\udde0 Tema 4: Memoria"},{"location":"curso1/tema4_memory/#que-es-el-la-memoria","text":"La memoria es la capacidad que tiene el grafo para recordar informaci\u00f3n a lo largo de m\u00faltiples invocaciones. Es especialmente \u00fatil cuando creamos chatbots o flujos conversacionales donde el contexto es crucial. Sin memoria: Cada vez que invocamos el grafo, comienza desde cero. Con memoria: El grafo guarda un historial de mensajes o datos, permitiendo respuestas basadas en todo el contexto anterior. \u00bfPor qu\u00e9 es importante? - Persistencia de datos. - Toma de decisiones basadas en el contexto actual. - Mayor precisi\u00f3n en interacciones prolongadas.","title":"\ud83d\udd75 \u00bfQu\u00e9 es el la Memoria?"},{"location":"curso1/tema4_memory/#como-funciona","text":"LangGraph ofrece varios tipos de memoria: Memoria de Estado (State Memory): El estado se transfiere de nodo a nodo, reteniendo informaci\u00f3n solo durante una invocaci\u00f3n. Memoria de Corto Alcance (MemorySaver): Guarda datos durante m\u00faltiples invocaciones, pero no persiste despu\u00e9s de cerrar el programa. Almacena la informaci\u00f3n en memoria vol\u00e1til (RAM). Ideal para flujos temporales que necesitan recordar el contexto durante la sesi\u00f3n actual. \ud83d\udc49 Documentaci\u00f3n de MemorySaver Memoria Persistente (Postgres u otros): Permite almacenar el historial en bases de datos externas (ej: PostgreSQL). Se ver\u00e1 en temas m\u00e1s avanzados. Memoria Transversal (Cross-Session Memory): Conserva datos a lo largo de m\u00faltiples sesiones y usuarios. Se estudiar\u00e1 en profundidad en futuros m\u00f3dulos.","title":"\ud83d\udee0\ufe0f \u00bfC\u00f3mo Funciona?"},{"location":"curso1/tema4_memory/#implementacion-de-memorysaver","text":"Usando el ejemplo que vimos anteriormente en art\u00edculos pasados, vamos a definir un grafo sencillo para poder ver como actula el MemorySaver : CustomState: Definimos un custom state para almacenar los mensajes. Nodo de entrada del usuario: Agrega el mensaje del usuario al estado. Nodo de respuesta de IA: El modelo de OpenAI ( gpt-4o-mini ) genera una respuesta basada en el historial. from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage , AIMessage , SystemMessage llm = ChatOpenAI ( model = \"gpt-4o-mini\" ) class CustomState ( MessagesState ): messages : list [ AIMessage | HumanMessage | SystemMessage ] = [] # Nodo de entrada del usuario def user_input_node ( state : CustomState ): print ( \"--- Usuario dice ---\" ) print ( state [ 'messages' ][ - 1 ] . content ) return { \"messages\" : state [ 'messages' ]} # Nodo de IA (respuesta) def ai_response_node ( state : CustomState ): print ( \"--- IA responde ---\" ) response = llm . invoke ( state [ 'messages' ]) print ( response . content ) return { \"messages\" : state [ 'messages' ] + [ AIMessage ( content = response . content )]} user_input_node: Toma el mensaje del usuario y lo guarda en el estado. ai_response_node: Usa el estado actual (historial) para generar una respuesta de IA.","title":"\ud83e\udde9 Implementaci\u00f3n de MemorySaver"},{"location":"curso1/tema4_memory/#anadiendo-memoria-al-grafo","text":"Ahora implementaremos el MemorySaver para agregar memoria de corto alcance a nuestro grafo.","title":"\ud83c\udfd7\ufe0f A\u00f1adiendo Memoria al Grafo"},{"location":"curso1/tema4_memory/#grafo-sin-memoria","text":"En el siguiente ejemplo, vamos a ver un grafo b\u00e1sico, como ya hemos visto hasta ahora, solamente para poder ver la diferencia para cuando le apliquemos nuestra memoria. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input_node ) builder . add_node ( \"ai_response\" , ai_response_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"ai_response\" ) builder . add_edge ( \"ai_response\" , END ) graph_no_memory = builder . compile ()","title":"\ud83d\udccb Grafo sin Memoria"},{"location":"curso1/tema4_memory/#grafo-con-memoria","text":"Ahora, agregaremos una memoria temporal y comprobaremos si nuestro grafo es capaz de retener informaci\u00f3n para poderla usar mas adelante. from langgraph.graph import StateGraph , START , END from langgraph.checkpoint.memory import MemorySaver memory = MemorySaver () builder_mem = StateGraph ( State ) builder_mem . add_node ( \"user_input\" , user_input_node ) builder_mem . add_node ( \"ai_response\" , ai_response_node ) builder_mem . add_edge ( START , \"user_input\" ) builder_mem . add_edge ( \"user_input\" , \"ai_response\" ) builder_mem . add_edge ( \"ai_response\" , END ) graph_memory = builder_mem . compile ( checkpointer = memory )","title":"\ud83d\udccb Grafo con Memoria"},{"location":"curso1/tema4_memory/#visualizacion-del-grafo","text":"Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph_no_memory . get_graph () . draw_mermaid_png ())) display ( Image ( graph_memory . get_graph () . draw_mermaid_png ()))","title":"\ud83d\udcc8 Visualizaci\u00f3n del Grafo"},{"location":"curso1/tema4_memory/#invocando-el-grafo-y-comparando-resultados","text":"","title":"\ud83d\ude80 Invocando el Grafo y Comparando Resultados"},{"location":"curso1/tema4_memory/#sin-memoria","text":"graph_no_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"Hola, me llamo Raul.\" )]}) graph_no_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )]}) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- No tengo acceso a informaci\u00f3n personal sobre los usuarios , as\u00ed que no s\u00e9 c\u00f3mo te llamas . Pero si quieres , puedes decirme tu nombre . \u00a1 Estoy aqu\u00ed para ayudarte ! Como vemos el grafo no guarda el hist\u00f3rico del chat, haciendo que el LLM no pueda tener acceso a informaci\u00f3n previa, por eso no es capaz de recordar mi nombre.","title":"\ud83d\udccb Sin Memoria"},{"location":"curso1/tema4_memory/#con-memoria","text":"config = { \"configurable\" : { \"thread_id\" : \"1\" }} # Agregamos el config a nuestros invokes graph_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"Hola, me llamo Raul.\" )]}, config ) graph_memory . invoke ({ \"messages\" : [ HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )]}, config ) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- Te llamas Ra\u00fal . \u00bf Hay algo m\u00e1s en lo que te pueda ayudar ? El par\u00e1metro config es fundamental para habilitar el seguimiento de sesiones individuales cuando utilizamos memoria con MemorySaver . - thread_id act\u00faa como un identificador \u00fanico para cada sesi\u00f3n o conversaci\u00f3n. - Esto permite que LangGraph recuerde informaci\u00f3n espec\u00edfica de una sesi\u00f3n y la distinga de otras conversaciones paralelas.","title":"\ud83d\udccb Con Memoria"},{"location":"curso1/tema4_memory/#que-sucede-sin-thread_id","text":"Si no agregamos thread_id : - Cada invocaci\u00f3n del grafo se trata como una nueva sesi\u00f3n , incluso si estamos usando MemorySaver . - El grafo no podr\u00e1 recordar mensajes previos porque no tendr\u00e1 forma de asociarlos a una misma sesi\u00f3n.","title":"\ud83e\udde9 \u00bfQu\u00e9 sucede sin thread_id?"},{"location":"curso1/tema4_memory/#cuando-usar-thread_id","text":"Chats personalizados : Cuando manejamos m\u00faltiples usuarios o conversaciones. Bots conversacionales : Para mantener el contexto de usuarios durante largas interacciones. Flujos multi-sesi\u00f3n : Si queremos permitir que un usuario retome una conversaci\u00f3n anterior.","title":"\ud83d\ude80 \u00bfCu\u00e1ndo usar thread_id?"},{"location":"curso1/tema4_memory/#alternativa-a-memorysaver","text":"La forma m\u00e1s efectiva de aplicar memoria de corto alcance en LangGraph es utilizando MemorySaver . Sin embargo, existen otras alternativas que pueden resultar \u00fatiles en ciertos casos. Una de las opciones m\u00e1s simples es almacenar el historial de la conversaci\u00f3n en una variable y pasarla continuamente durante cada invocaci\u00f3n. De esta manera, el modelo de lenguaje (LLM) mantiene el contexto de la conversaci\u00f3n sin depender de sistemas de memoria externos. A continuaci\u00f3n, veremos un ejemplo sencillo para entender c\u00f3mo implementar esta t\u00e9cnica: # Almacenamos las preguntas y respuestas en una variable. messages = [ HumanMessage ( content = \"Hola, me llamo Raul.\" )] response = graph_no_memory . invoke ({ \"messages\" : messages }) messages . append ( response . get ( 'messages' )[ - 1 ]) messages . append ( HumanMessage ( content = \"\u00bfC\u00f3mo me llamo?\" )) response = graph_no_memory . invoke ({ \"messages\" : messages }) messages . append ( response . get ( 'messages' )[ - 1 ]) Respuesta --- Usuario dice --- Hola , me llamo Raul . --- IA responde --- \u00a1 Hola , Ra\u00fal ! \u00bf C\u00f3mo est\u00e1s ? \u00bf En qu\u00e9 puedo ayudarte hoy ? --- Usuario dice --- \u00bf C\u00f3mo me llamo ? --- IA responde --- Te llamas Ra\u00fal . \u00bf Hay algo m\u00e1s con lo que te pueda ayudar ? Guardamos los mensajes en una lista ( messages ) que act\u00faa como historial de conversaci\u00f3n. Tras cada invocaci\u00f3n al grafo, agregamos la respuesta generada por la IA al historial. Cuando el usuario realiza una nueva pregunta, enviamos el historial completo al grafo para que el modelo mantenga el contexto .","title":"\ud83e\udde9 Alternativa a MemorySaver"},{"location":"curso1/tema4_memory/#observaciones-importantes","text":"Esta t\u00e9cnica proporciona memoria temporal , pero requiere gesti\u00f3n manual del historial de mensajes. El historial puede almacenarse: En una variable. En una base de datos. En un archivo externo. Aunque m\u00e1s adelante exploraremos m\u00e9todos m\u00e1s avanzados y optimizados (como memoria persistente con bases de datos), esta soluci\u00f3n puede ser una forma sencilla y efectiva para proyectos que no requieren una arquitectura compleja.","title":"\ud83e\uddd1\u200d\ud83c\udfeb Observaciones Importantes"},{"location":"curso1/tema4_memory/#recursos","text":"Ver notebook en Google Colab How-to-guide: MemorySaver","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema4_memory/#que-hemos-aprendido","text":"Memoria de Estado (State): Solo persiste durante la ejecuci\u00f3n de una invocaci\u00f3n. MemorySaver: Proporciona memoria de corto alcance para retener datos durante m\u00faltiples invocaciones. Diferencias Clave: Sin memoria, cada invocaci\u00f3n es independiente. Con memoria, el grafo recuerda datos anteriores.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema4_memory/#que-es-lo-siguiente","text":"En el siguiente tema exploraremos Chains y Flujos de Trabajo , donde aprenderemos a encadenar nodos y construir pipelines complejos. Tambi\u00e9n abordaremos el tema de Tools (Herramientas) , pero lo veremos despu\u00e9s de Chains , ya que comprender primero el flujo de trabajo har\u00e1 que la integraci\u00f3n de herramientas sea m\u00e1s sencilla y pr\u00e1ctica.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema5_chains/","text":"\ud83d\udd17 Tema 5: Chains \u2013 Construcci\u00f3n de Flujos de Trabajo \ud83d\ude80 \u00bfQu\u00e9 son las Chains en LangGraph? Las Chains (cadenas) son uno de los componentes m\u00e1s esenciales dentro de LangGraph. Permiten encadenar m\u00faltiples nodos y funciones para crear flujos de trabajo complejos y estructurados. Piensa en las chains como una l\u00ednea de montaje , donde cada nodo realiza una tarea espec\u00edfica y pasa el resultado al siguiente. Esto permite dividir procesos en pasos m\u00e1s manejables y reutilizables . Sin embargo, no todos los flujos siguen un camino lineal. A veces, es necesario bifurcar el flujo en funci\u00f3n de ciertas condiciones. \ud83e\udde0 \u00bfPor qu\u00e9 usar Chains? Modularidad: Dividir grandes procesos en nodos peque\u00f1os facilita el mantenimiento y la depuraci\u00f3n. Reutilizaci\u00f3n: Las chains pueden componerse de nodos reutilizables en diferentes flujos. Escalabilidad: Permiten construir flujos extensibles que pueden crecer f\u00e1cilmente a\u00f1adiendo m\u00e1s nodos. \u2699\ufe0f \u00bfC\u00f3mo se Define una Chain? Crear una chain en LangGraph implica: 1. Definir nodos individuales. 2. Encadenar esos nodos en una secuencia l\u00f3gica. 3. Permitir bifurcaciones condicionales si es necesario. Adem\u00e1s de encadenar nodos de forma secuencial, podemos agregar bifurcaciones condicionales para que el grafo tome diferentes rutas seg\u00fan el estado actual. \ud83d\udccb Ejemplo Pr\u00e1ctico: Creaci\u00f3n de una Chain Vamos a construir un flujo simple que: 1. Reciba el nombre del usuario. 2. Salude al usuario. 3. Sugiera una actividad diferente seg\u00fan la hora del d\u00eda (ma\u00f1ana o tarde). from typing_extensions import TypedDict from datetime import datetime class State ( TypedDict ): name : str message : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) state [ \"name\" ] = \"Raul\" return state def greet_user ( state : State ): print ( \"--- Nodo 2: Saludo ---\" ) state [ \"message\" ] = f \"Hola { state [ 'name' ] } , \u00a1bienvenido de nuevo!\" return state def suggest_morning ( state : State ): print ( \"--- Nodo 3: Ma\u00f1ana ---\" ) state [ \"message\" ] += \" Te recomiendo empezar el d\u00eda con un caf\u00e9 \u2615\ufe0f\" return state def suggest_afternoon ( state : State ): print ( \"--- Nodo 4: Tarde ---\" ) state [ \"message\" ] += \" \u00bfQu\u00e9 tal salir a dar un paseo por la tarde? \ud83d\udeb6\u200d\u2642\ufe0f\" return state def decide_path ( state : State ) -> bool : hour = datetime . now () . hour return True if hour < 12 else False Nodo 1 (user_input): Recoge el nombre del usuario. Nodo 2 (greet_user): Genera un saludo personalizado. Nodo 3 y Nodo 4 (suggest_morning/suggest_afternoon): Si es por la ma\u00f1ana, el flujo sugiere tomar un caf\u00e9. Si es por la tarde, se recomienda dar un paseo. Funci\u00f3n decide_path : Eval\u00faa la hora actual para bifurcar el flujo hacia el nodo adecuado. \ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo con Chains Encadenamos los nodos en secuencia para formar la chain completa. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"greet_user\" , greet_user ) builder . add_node ( \"suggest_morning\" , suggest_morning ) builder . add_node ( \"suggest_afternoon\" , suggest_afternoon ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"greet_user\" ) builder . add_conditional_edges ( \"greet_user\" , decide_path , { True : \"suggest_morning\" , False : \"suggest_afternoon\" }) builder . add_edge ( \"suggest_morning\" , END ) builder . add_edge ( \"suggest_afternoon\" , END ) graph = builder . compile () \ud83d\udcc8 Visualizaci\u00f3n del Grafo Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) \ud83d\ude80 Invocando el Grafo Ahora ejecutamos el grafo con una entrada simple. graph . invoke ({ \"name\" : \"\" , \"message\" : \"\" }) Resultado 1 --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Saludo --- --- Nodo 3 : Ma\u00f1ana --- { 'name' : 'Raul' , 'message' : 'Hola Raul, \u00a1bienvenido de nuevo! Te recomiendo empezar el d\u00eda con un caf\u00e9 \u2615\ufe0f' } Resultado 2 --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Saludo --- --- Nodo 4 : Tarde --- { 'name' : 'Raul' , 'message' : 'Hola Raul, \u00a1bienvenido de nuevo! \u00bfQu\u00e9 tal salir a dar un paseo por la tarde? \ud83d\udeb6\u200d\u2642\ufe0f' } El grafo procesa cada nodo secuencialmente, generando una respuesta estructurada para el usuario. \ud83d\udd0e Recursos: Ver notebook en Google Colab Definici\u00f3n Condition Edge Clase Condition Edge \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? Chains: Permiten conectar nodos en secuencia, formando flujos de trabajo escalables y reutilizables. Modularidad: Los nodos pueden realizar tareas peque\u00f1as que, al combinarse, crean flujos m\u00e1s complejos. Chains Condicionales: Permiten bifurcar el flujo en funci\u00f3n de valores din\u00e1micos (como la hora o entradas del usuario). Encadenamiento Secuencial y Din\u00e1mico: Los flujos no siempre son lineales, y LangGraph permite construir grafos que se adaptan a diferentes situaciones. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el siguiente tema, exploraremos el uso de Routers , donde aprenderemos c\u00f3mo crear bifurcaciones y poder redirigir el flujo para que tome diferentes caminos.","title":"Tema 5: Chains y Flujos de Trabajo"},{"location":"curso1/tema5_chains/#tema-5-chains-construccion-de-flujos-de-trabajo","text":"","title":"\ud83d\udd17 Tema 5: Chains \u2013 Construcci\u00f3n de Flujos de Trabajo"},{"location":"curso1/tema5_chains/#que-son-las-chains-en-langgraph","text":"Las Chains (cadenas) son uno de los componentes m\u00e1s esenciales dentro de LangGraph. Permiten encadenar m\u00faltiples nodos y funciones para crear flujos de trabajo complejos y estructurados. Piensa en las chains como una l\u00ednea de montaje , donde cada nodo realiza una tarea espec\u00edfica y pasa el resultado al siguiente. Esto permite dividir procesos en pasos m\u00e1s manejables y reutilizables . Sin embargo, no todos los flujos siguen un camino lineal. A veces, es necesario bifurcar el flujo en funci\u00f3n de ciertas condiciones.","title":"\ud83d\ude80 \u00bfQu\u00e9 son las Chains en LangGraph?"},{"location":"curso1/tema5_chains/#por-que-usar-chains","text":"Modularidad: Dividir grandes procesos en nodos peque\u00f1os facilita el mantenimiento y la depuraci\u00f3n. Reutilizaci\u00f3n: Las chains pueden componerse de nodos reutilizables en diferentes flujos. Escalabilidad: Permiten construir flujos extensibles que pueden crecer f\u00e1cilmente a\u00f1adiendo m\u00e1s nodos.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 usar Chains?"},{"location":"curso1/tema5_chains/#como-se-define-una-chain","text":"Crear una chain en LangGraph implica: 1. Definir nodos individuales. 2. Encadenar esos nodos en una secuencia l\u00f3gica. 3. Permitir bifurcaciones condicionales si es necesario. Adem\u00e1s de encadenar nodos de forma secuencial, podemos agregar bifurcaciones condicionales para que el grafo tome diferentes rutas seg\u00fan el estado actual.","title":"\u2699\ufe0f \u00bfC\u00f3mo se Define una Chain?"},{"location":"curso1/tema5_chains/#ejemplo-practico-creacion-de-una-chain","text":"Vamos a construir un flujo simple que: 1. Reciba el nombre del usuario. 2. Salude al usuario. 3. Sugiera una actividad diferente seg\u00fan la hora del d\u00eda (ma\u00f1ana o tarde). from typing_extensions import TypedDict from datetime import datetime class State ( TypedDict ): name : str message : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) state [ \"name\" ] = \"Raul\" return state def greet_user ( state : State ): print ( \"--- Nodo 2: Saludo ---\" ) state [ \"message\" ] = f \"Hola { state [ 'name' ] } , \u00a1bienvenido de nuevo!\" return state def suggest_morning ( state : State ): print ( \"--- Nodo 3: Ma\u00f1ana ---\" ) state [ \"message\" ] += \" Te recomiendo empezar el d\u00eda con un caf\u00e9 \u2615\ufe0f\" return state def suggest_afternoon ( state : State ): print ( \"--- Nodo 4: Tarde ---\" ) state [ \"message\" ] += \" \u00bfQu\u00e9 tal salir a dar un paseo por la tarde? \ud83d\udeb6\u200d\u2642\ufe0f\" return state def decide_path ( state : State ) -> bool : hour = datetime . now () . hour return True if hour < 12 else False Nodo 1 (user_input): Recoge el nombre del usuario. Nodo 2 (greet_user): Genera un saludo personalizado. Nodo 3 y Nodo 4 (suggest_morning/suggest_afternoon): Si es por la ma\u00f1ana, el flujo sugiere tomar un caf\u00e9. Si es por la tarde, se recomienda dar un paseo. Funci\u00f3n decide_path : Eval\u00faa la hora actual para bifurcar el flujo hacia el nodo adecuado.","title":"\ud83d\udccb Ejemplo Pr\u00e1ctico: Creaci\u00f3n de una Chain"},{"location":"curso1/tema5_chains/#construccion-del-grafo-con-chains","text":"Encadenamos los nodos en secuencia para formar la chain completa. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"greet_user\" , greet_user ) builder . add_node ( \"suggest_morning\" , suggest_morning ) builder . add_node ( \"suggest_afternoon\" , suggest_afternoon ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"greet_user\" ) builder . add_conditional_edges ( \"greet_user\" , decide_path , { True : \"suggest_morning\" , False : \"suggest_afternoon\" }) builder . add_edge ( \"suggest_morning\" , END ) builder . add_edge ( \"suggest_afternoon\" , END ) graph = builder . compile ()","title":"\ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo con Chains"},{"location":"curso1/tema5_chains/#visualizacion-del-grafo","text":"Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ()))","title":"\ud83d\udcc8 Visualizaci\u00f3n del Grafo"},{"location":"curso1/tema5_chains/#invocando-el-grafo","text":"Ahora ejecutamos el grafo con una entrada simple. graph . invoke ({ \"name\" : \"\" , \"message\" : \"\" }) Resultado 1 --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Saludo --- --- Nodo 3 : Ma\u00f1ana --- { 'name' : 'Raul' , 'message' : 'Hola Raul, \u00a1bienvenido de nuevo! Te recomiendo empezar el d\u00eda con un caf\u00e9 \u2615\ufe0f' } Resultado 2 --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Saludo --- --- Nodo 4 : Tarde --- { 'name' : 'Raul' , 'message' : 'Hola Raul, \u00a1bienvenido de nuevo! \u00bfQu\u00e9 tal salir a dar un paseo por la tarde? \ud83d\udeb6\u200d\u2642\ufe0f' } El grafo procesa cada nodo secuencialmente, generando una respuesta estructurada para el usuario.","title":"\ud83d\ude80 Invocando el Grafo"},{"location":"curso1/tema5_chains/#recursos","text":"Ver notebook en Google Colab Definici\u00f3n Condition Edge Clase Condition Edge","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema5_chains/#que-hemos-aprendido","text":"Chains: Permiten conectar nodos en secuencia, formando flujos de trabajo escalables y reutilizables. Modularidad: Los nodos pueden realizar tareas peque\u00f1as que, al combinarse, crean flujos m\u00e1s complejos. Chains Condicionales: Permiten bifurcar el flujo en funci\u00f3n de valores din\u00e1micos (como la hora o entradas del usuario). Encadenamiento Secuencial y Din\u00e1mico: Los flujos no siempre son lineales, y LangGraph permite construir grafos que se adaptan a diferentes situaciones.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema5_chains/#que-es-lo-siguiente","text":"En el siguiente tema, exploraremos el uso de Routers , donde aprenderemos c\u00f3mo crear bifurcaciones y poder redirigir el flujo para que tome diferentes caminos.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema6_routers/","text":"\ud83d\udea6 Tema 6: Routers \u2013 Dirigiendo el Flujo del Grafo \ud83d\ude80 \u00bfQu\u00e9 es un Router en LangGraph? Los routers en LangGraph son nodos especiales que permiten redirigir el flujo hacia diferentes caminos en funci\u00f3n de condiciones din\u00e1micas. A diferencia de los edges condicionales , los routers centralizan y gestionan m\u00faltiples bifurcaciones desde un solo punto, haciendo que los grafos sean m\u00e1s modulares, limpios y escalables. \ud83e\udde0 \u00bfPor qu\u00e9 usar Routers en lugar de Condicionales? Centralizaci\u00f3n: Un solo nodo puede gestionar m\u00faltiples caminos, evitando bifurcaciones dispersas. Escalabilidad: A medida que crecen los caminos posibles, los routers permiten expandir el grafo sin a\u00f1adir complejidad. Reutilizaci\u00f3n: Un mismo router puede ser usado en diferentes partes del grafo. Legibilidad: Mantiene el grafo organizado y f\u00e1cil de seguir. \ud83d\udc49 Piensa en el router como un sem\u00e1foro \ud83d\udea6 que dirige el tr\u00e1fico hacia diferentes carriles en funci\u00f3n de las se\u00f1ales recibidas. \u2699\ufe0f \u00bfC\u00f3mo Funciona un Router? Un router funciona tomando una decisi\u00f3n basada en el estado del grafo o en par\u00e1metros espec\u00edficos de entrada. Define m\u00faltiples caminos posibles y selecciona uno, enviando el flujo hacia el nodo correspondiente. \ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Router de Departamentos Vamos a crear un chatbot que redirige al usuario a diferentes departamentos seg\u00fan el tipo de pregunta: Soporte T\u00e9cnico: Para resolver problemas t\u00e9cnicos. Ventas: Para consultas de productos o servicios. Consultas Generales: Para cualquier otra pregunta. El router analizar\u00e1 el mensaje del usuario y lo dirigir\u00e1 al nodo adecuado. from typing_extensions import TypedDict class State ( TypedDict ): message : str response : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) print ( state [ \"message\" ]) return state def route_request ( state : State ) -> str : message = state [ \"message\" ] . lower () if \"soporte\" in message or \"problema\" in message : return \"support_node\" elif \"comprar\" in message or \"precio\" in message : return \"sales_node\" else : return \"general_node\" def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"response\" ] = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" return state def sales_node ( state : State ): print ( \"--- Nodo de Ventas ---\" ) state [ \"response\" ] = \"Te conectamos con el equipo de ventas.\" return state def general_node ( state : State ): print ( \"--- Nodo de Consultas Generales ---\" ) state [ \"response\" ] = \"Tu consulta ser\u00e1 respondida a la brevedad.\" return state \ud83d\udd0d Explicaci\u00f3n del Ejemplo: Nodo 1 (user_input): Recibe el mensaje del usuario. Router (route_request): Eval\u00faa el mensaje y redirige al nodo correspondiente: support_node , sales_node o general_node . Nodos de Respuesta: Cada nodo proporciona una respuesta basada en el departamento al que se redirigi\u00f3 al usuario. \ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo con Router Agregamos el router y conectamos cada nodo de respuesta al flujo. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_node ( \"general_node\" , general_node ) builder . add_edge ( START , \"user_input\" ) builder . add_conditional_edges ( \"user_input\" , route_request ) builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) builder . add_edge ( \"general_node\" , END ) graph = builder . compile () \ud83d\udcc8 Visualizaci\u00f3n del Grafo Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) \ud83d\ude80 Invocando el Grafo Probamos el grafo con diferentes entradas para ver c\u00f3mo el router dirige el flujo. graph . invoke ({ \"message\" : \"\" , \"response\" : \"\" }) Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : 'Quiero comprar un producto' , 'response' : 'Te conectamos con el equipo de ventas.' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : 'Tengo un problema con mi cuenta' , 'response' : 'Te estamos transfiriendo a soporte t\u00e9cnico.' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : '\u00bfCu\u00e1l es el horario de atenci\u00f3n?' , 'response' : 'Tu consulta ser\u00e1 respondida a la brevedad.' } Dependiendo del contenido del mensaje del usuario, el flujo tomar\u00e1 caminos distintos, demostrando el poder y flexibilidad de los routers. \ud83d\udee0\ufe0f Usando \"Command\" para Modificar el Estado Durante el Enrutamiento Adem\u00e1s de redirigir el flujo del grafo, LangGraph permite modificar el estado directamente desde el router usando Command . Esto es \u00fatil cuando, adem\u00e1s de dirigir al usuario a un nodo espec\u00edfico, queremos actualizar atributos del estado sin necesidad de crear nodos adicionales. \ud83d\ude80 \u00bfQu\u00e9 es un Command en LangGraph? Un command es una instrucci\u00f3n que permite realizar dos acciones simult\u00e1neas: Enrutar el flujo del grafo hacia un nodo espec\u00edfico. Actualizar o modificar atributos del estado. \ud83e\udde9 \u00bfPor Qu\u00e9 es \u00datil? Optimizaci\u00f3n: Evita la necesidad de crear nodos adicionales solo para actualizar el estado. Simplicidad: Mantiene el flujo del grafo m\u00e1s limpio y con menos nodos intermedios. Eficiencia: Reduce el n\u00famero de pasos y permite que el grafo sea m\u00e1s din\u00e1mico y reactivo. \ud83d\udccb Ejemplo Pr\u00e1ctico con Command Modificaremos nuestro chatbot para que, adem\u00e1s de redirigir al usuario a un departamento, actualice el estado con un mensaje indicando a qu\u00e9 secci\u00f3n fue transferido. from typing_extensions import TypedDict , Literal from langgraph.types import Command class State ( TypedDict ): message : str response : str department : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) #state[\"message\"] = \"Necesito soporte t\u00e9cnico\" return state def route_request ( state : State ) -> Command [ Literal [ \"support_node\" , \"sales_node\" , \"general_node\" ]]: message = state [ \"message\" ] . lower () print ( \"--- Nodo 2: Ruta de la Solicitud ---\" ) if \"soporte\" in message : return Command ( goto = \"support_node\" , update = { \"department\" : \"Soporte T\u00e9cnico\" }) elif \"comprar\" in message : return Command ( goto = \"sales_node\" , update = { \"department\" : \"Ventas\" }) else : return Command ( goto = \"general_node\" , update = { \"department\" : \"Consultas Generales\" }) def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" return state def sales_node ( state : State ): print ( \"--- Nodo de Ventas ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Te conectamos con el equipo de ventas.\" return state def general_node ( state : State ): print ( \"--- Nodo de Consultas Generales ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Tu consulta ser\u00e1 respondida a la brevedad.\" return state \ud83d\udd0d Explicaci\u00f3n del Ejemplo Router con Command: Ahora, el router no solo dirige el flujo sino que tambi\u00e9n actualiza el estado con el nombre del departamento seleccionado. Actualizaci\u00f3n Directa del Estado: Esto nos permite guardar un registro de a qu\u00e9 nodo fue transferido el usuario, lo que puede ser \u00fatil para an\u00e1lisis o futuros pasos en el flujo. \ud83d\ude80 Invocando el Grafo Probamos el grafo para observar c\u00f3mo se actualiza el estado durante el enrutamiento. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"route_request\" , route_request ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_node ( \"general_node\" , general_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"route_request\" ) # NOTE: No hay edges entre route_request y el resto de nodos! builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) builder . add_edge ( \"general_node\" , END ) graph = builder . compile () from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) graph . invoke ({ \"message\" : \"\" , \"response\" : \"\" , \"department\" : \"\" }) Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Soporte T\u00e9cnico --- { 'message' : 'Necesito soporte t\u00e9cnico' , 'response' : 'Te estamos transfiriendo a soporte t\u00e9cnico.' , 'department' : 'Soporte T\u00e9cnico' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Ventas --- { 'message' : 'Quiero comprar un producto' , 'response' : 'Te conectamos con el equipo de ventas.' , 'department' : 'Ventas' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Consultas Generales --- { 'message' : 'Tengo una pregunta general' , 'response' : 'Tu consulta ser\u00e1 respondida a la brevedad.' , 'department' : 'Consultas Generales' } El estado reflejar\u00e1 tanto la respuesta del nodo como el departamento al que fue transferido el usuario. \ud83d\udd0e Recursos: Ver notebook en Google Colab Definici\u00f3n Command How-to-guide Command \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? Routers: Son nodos que gestionan m\u00faltiples bifurcaciones desde un solo punto. Centralizaci\u00f3n y Escalabilidad: Los routers permiten mantener un grafo limpio y organizado, facilitando la expansi\u00f3n. Flujos Din\u00e1micos: Los routers toman decisiones en tiempo real basadas en el estado o entrada del usuario. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el pr\u00f3ximo tema, hablaremos de Reducers , que permiten consolidar datos y resultados de diferentes caminos dentro del grafo. Los reducers trabajan en conjunto con los routers, formando flujos completos y optimizados.","title":"Tema 6: Routers"},{"location":"curso1/tema6_routers/#tema-6-routers-dirigiendo-el-flujo-del-grafo","text":"","title":"\ud83d\udea6 Tema 6: Routers \u2013 Dirigiendo el Flujo del Grafo"},{"location":"curso1/tema6_routers/#que-es-un-router-en-langgraph","text":"Los routers en LangGraph son nodos especiales que permiten redirigir el flujo hacia diferentes caminos en funci\u00f3n de condiciones din\u00e1micas. A diferencia de los edges condicionales , los routers centralizan y gestionan m\u00faltiples bifurcaciones desde un solo punto, haciendo que los grafos sean m\u00e1s modulares, limpios y escalables.","title":"\ud83d\ude80 \u00bfQu\u00e9 es un Router en LangGraph?"},{"location":"curso1/tema6_routers/#por-que-usar-routers-en-lugar-de-condicionales","text":"Centralizaci\u00f3n: Un solo nodo puede gestionar m\u00faltiples caminos, evitando bifurcaciones dispersas. Escalabilidad: A medida que crecen los caminos posibles, los routers permiten expandir el grafo sin a\u00f1adir complejidad. Reutilizaci\u00f3n: Un mismo router puede ser usado en diferentes partes del grafo. Legibilidad: Mantiene el grafo organizado y f\u00e1cil de seguir. \ud83d\udc49 Piensa en el router como un sem\u00e1foro \ud83d\udea6 que dirige el tr\u00e1fico hacia diferentes carriles en funci\u00f3n de las se\u00f1ales recibidas.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 usar Routers en lugar de Condicionales?"},{"location":"curso1/tema6_routers/#como-funciona-un-router","text":"Un router funciona tomando una decisi\u00f3n basada en el estado del grafo o en par\u00e1metros espec\u00edficos de entrada. Define m\u00faltiples caminos posibles y selecciona uno, enviando el flujo hacia el nodo correspondiente.","title":"\u2699\ufe0f \u00bfC\u00f3mo Funciona un Router?"},{"location":"curso1/tema6_routers/#ejemplo-practico-chatbot-con-router-de-departamentos","text":"Vamos a crear un chatbot que redirige al usuario a diferentes departamentos seg\u00fan el tipo de pregunta: Soporte T\u00e9cnico: Para resolver problemas t\u00e9cnicos. Ventas: Para consultas de productos o servicios. Consultas Generales: Para cualquier otra pregunta. El router analizar\u00e1 el mensaje del usuario y lo dirigir\u00e1 al nodo adecuado. from typing_extensions import TypedDict class State ( TypedDict ): message : str response : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) print ( state [ \"message\" ]) return state def route_request ( state : State ) -> str : message = state [ \"message\" ] . lower () if \"soporte\" in message or \"problema\" in message : return \"support_node\" elif \"comprar\" in message or \"precio\" in message : return \"sales_node\" else : return \"general_node\" def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"response\" ] = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" return state def sales_node ( state : State ): print ( \"--- Nodo de Ventas ---\" ) state [ \"response\" ] = \"Te conectamos con el equipo de ventas.\" return state def general_node ( state : State ): print ( \"--- Nodo de Consultas Generales ---\" ) state [ \"response\" ] = \"Tu consulta ser\u00e1 respondida a la brevedad.\" return state","title":"\ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Router de Departamentos"},{"location":"curso1/tema6_routers/#explicacion-del-ejemplo","text":"Nodo 1 (user_input): Recibe el mensaje del usuario. Router (route_request): Eval\u00faa el mensaje y redirige al nodo correspondiente: support_node , sales_node o general_node . Nodos de Respuesta: Cada nodo proporciona una respuesta basada en el departamento al que se redirigi\u00f3 al usuario.","title":"\ud83d\udd0d Explicaci\u00f3n del Ejemplo:"},{"location":"curso1/tema6_routers/#construccion-del-grafo-con-router","text":"Agregamos el router y conectamos cada nodo de respuesta al flujo. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_node ( \"general_node\" , general_node ) builder . add_edge ( START , \"user_input\" ) builder . add_conditional_edges ( \"user_input\" , route_request ) builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) builder . add_edge ( \"general_node\" , END ) graph = builder . compile ()","title":"\ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo con Router"},{"location":"curso1/tema6_routers/#visualizacion-del-grafo","text":"Para observar c\u00f3mo se estructura nuestro grafo, generamos una visualizaci\u00f3n: from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ()))","title":"\ud83d\udcc8 Visualizaci\u00f3n del Grafo"},{"location":"curso1/tema6_routers/#invocando-el-grafo","text":"Probamos el grafo con diferentes entradas para ver c\u00f3mo el router dirige el flujo. graph . invoke ({ \"message\" : \"\" , \"response\" : \"\" }) Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : 'Quiero comprar un producto' , 'response' : 'Te conectamos con el equipo de ventas.' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : 'Tengo un problema con mi cuenta' , 'response' : 'Te estamos transfiriendo a soporte t\u00e9cnico.' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo de Ventas --- { 'message' : '\u00bfCu\u00e1l es el horario de atenci\u00f3n?' , 'response' : 'Tu consulta ser\u00e1 respondida a la brevedad.' } Dependiendo del contenido del mensaje del usuario, el flujo tomar\u00e1 caminos distintos, demostrando el poder y flexibilidad de los routers.","title":"\ud83d\ude80 Invocando el Grafo"},{"location":"curso1/tema6_routers/#usando-command-para-modificar-el-estado-durante-el-enrutamiento","text":"Adem\u00e1s de redirigir el flujo del grafo, LangGraph permite modificar el estado directamente desde el router usando Command . Esto es \u00fatil cuando, adem\u00e1s de dirigir al usuario a un nodo espec\u00edfico, queremos actualizar atributos del estado sin necesidad de crear nodos adicionales.","title":"\ud83d\udee0\ufe0f Usando \"Command\" para Modificar el Estado Durante el Enrutamiento"},{"location":"curso1/tema6_routers/#que-es-un-command-en-langgraph","text":"Un command es una instrucci\u00f3n que permite realizar dos acciones simult\u00e1neas: Enrutar el flujo del grafo hacia un nodo espec\u00edfico. Actualizar o modificar atributos del estado.","title":"\ud83d\ude80 \u00bfQu\u00e9 es un Command en LangGraph?"},{"location":"curso1/tema6_routers/#por-que-es-util","text":"Optimizaci\u00f3n: Evita la necesidad de crear nodos adicionales solo para actualizar el estado. Simplicidad: Mantiene el flujo del grafo m\u00e1s limpio y con menos nodos intermedios. Eficiencia: Reduce el n\u00famero de pasos y permite que el grafo sea m\u00e1s din\u00e1mico y reactivo.","title":"\ud83e\udde9 \u00bfPor Qu\u00e9 es \u00datil?"},{"location":"curso1/tema6_routers/#ejemplo-practico-con-command","text":"Modificaremos nuestro chatbot para que, adem\u00e1s de redirigir al usuario a un departamento, actualice el estado con un mensaje indicando a qu\u00e9 secci\u00f3n fue transferido. from typing_extensions import TypedDict , Literal from langgraph.types import Command class State ( TypedDict ): message : str response : str department : str def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) #state[\"message\"] = \"Necesito soporte t\u00e9cnico\" return state def route_request ( state : State ) -> Command [ Literal [ \"support_node\" , \"sales_node\" , \"general_node\" ]]: message = state [ \"message\" ] . lower () print ( \"--- Nodo 2: Ruta de la Solicitud ---\" ) if \"soporte\" in message : return Command ( goto = \"support_node\" , update = { \"department\" : \"Soporte T\u00e9cnico\" }) elif \"comprar\" in message : return Command ( goto = \"sales_node\" , update = { \"department\" : \"Ventas\" }) else : return Command ( goto = \"general_node\" , update = { \"department\" : \"Consultas Generales\" }) def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" return state def sales_node ( state : State ): print ( \"--- Nodo de Ventas ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Te conectamos con el equipo de ventas.\" return state def general_node ( state : State ): print ( \"--- Nodo de Consultas Generales ---\" ) print ( state [ \"department\" ]) state [ \"response\" ] = \"Tu consulta ser\u00e1 respondida a la brevedad.\" return state","title":"\ud83d\udccb Ejemplo Pr\u00e1ctico con Command"},{"location":"curso1/tema6_routers/#explicacion-del-ejemplo_1","text":"Router con Command: Ahora, el router no solo dirige el flujo sino que tambi\u00e9n actualiza el estado con el nombre del departamento seleccionado. Actualizaci\u00f3n Directa del Estado: Esto nos permite guardar un registro de a qu\u00e9 nodo fue transferido el usuario, lo que puede ser \u00fatil para an\u00e1lisis o futuros pasos en el flujo.","title":"\ud83d\udd0d Explicaci\u00f3n del Ejemplo"},{"location":"curso1/tema6_routers/#invocando-el-grafo_1","text":"Probamos el grafo para observar c\u00f3mo se actualiza el estado durante el enrutamiento. from langgraph.graph import StateGraph , START , END builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"route_request\" , route_request ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_node ( \"general_node\" , general_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"route_request\" ) # NOTE: No hay edges entre route_request y el resto de nodos! builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) builder . add_edge ( \"general_node\" , END ) graph = builder . compile () from IPython.display import Image , display display ( Image ( graph . get_graph () . draw_mermaid_png ())) graph . invoke ({ \"message\" : \"\" , \"response\" : \"\" , \"department\" : \"\" }) Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Soporte T\u00e9cnico --- { 'message' : 'Necesito soporte t\u00e9cnico' , 'response' : 'Te estamos transfiriendo a soporte t\u00e9cnico.' , 'department' : 'Soporte T\u00e9cnico' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Ventas --- { 'message' : 'Quiero comprar un producto' , 'response' : 'Te conectamos con el equipo de ventas.' , 'department' : 'Ventas' } Resultado --- Nodo 1 : Entrada del Usuario --- --- Nodo 2 : Ruta de la Solicitud --- --- Nodo de Consultas Generales --- { 'message' : 'Tengo una pregunta general' , 'response' : 'Tu consulta ser\u00e1 respondida a la brevedad.' , 'department' : 'Consultas Generales' } El estado reflejar\u00e1 tanto la respuesta del nodo como el departamento al que fue transferido el usuario.","title":"\ud83d\ude80 Invocando el Grafo"},{"location":"curso1/tema6_routers/#recursos","text":"Ver notebook en Google Colab Definici\u00f3n Command How-to-guide Command","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema6_routers/#que-hemos-aprendido","text":"Routers: Son nodos que gestionan m\u00faltiples bifurcaciones desde un solo punto. Centralizaci\u00f3n y Escalabilidad: Los routers permiten mantener un grafo limpio y organizado, facilitando la expansi\u00f3n. Flujos Din\u00e1micos: Los routers toman decisiones en tiempo real basadas en el estado o entrada del usuario.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema6_routers/#que-es-lo-siguiente","text":"En el pr\u00f3ximo tema, hablaremos de Reducers , que permiten consolidar datos y resultados de diferentes caminos dentro del grafo. Los reducers trabajan en conjunto con los routers, formando flujos completos y optimizados.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema7_reducers/","text":"\ud83d\udd04 Tema 7: Reducers \ud83d\ude80 \u00bfQu\u00e9 es un Reducer en LangGraph? Los reducers en LangGraph permiten consolidar y procesar datos provenientes de diferentes nodos o caminos. Cuando un grafo sigue flujos paralelos o m\u00faltiples bifurcaciones , los reducers recogen, combinan o modifican los resultados, facilitando una salida coherente y organizada. \ud83d\udc49 Piensa en un reducer como un colector de datos que une los resultados de distintas partes del grafo en un solo punto. \ud83e\udde0 \u00bfPor qu\u00e9 son Importantes los Reducers? Consolidaci\u00f3n de Datos: Re\u00fane informaci\u00f3n de diferentes nodos y la almacena en el estado. Flujos Complejos: Permite manejar y combinar respuestas de m\u00faltiples caminos paralelos. Evitan Sobrescrituras No Deseadas: Sin un reducer, cada actualizaci\u00f3n sobrescribe el valor existente. \u2699\ufe0f \u00bfC\u00f3mo Funciona un Reducer? Cuando un nodo devuelve datos parciales del estado, el reducer decide c\u00f3mo aplicar esos datos : - Sin Reducer: El valor existente se sobrescribe. - Con Reducer: Los datos se combinan o acumulan siguiendo una l\u00f3gica definida. \ud83d\udc49 Ejemplo: Si tienes una lista de mensajes, un reducer puede a\u00f1adir nuevos mensajes al final, en lugar de borrar el historial anterior. \ud83d\udd0d Ejemplo A: Sin Reducer (Sobrescritura Directa) En este caso, cada vez que un nodo devuelve un valor, sobrescribe el valor anterior: from typing_extensions import TypedDict from langchain_core.messages import AnyMessage class State ( TypedDict ): messages : list [ AnyMessage ] # Sin reducer (sobrescribe) response : str department : str \ud83d\udd0e Explicaci\u00f3n: La clave messages no tiene un reducer asignado. Cada actualizaci\u00f3n de mensajes reemplaza por completo la lista anterior. El \u00faltimo mensaje ser\u00e1 el \u00fanico que quede en el estado. \ud83d\udccb Ejemplo B: Con Reducer (Acumulaci\u00f3n de Mensajes) Usamos Annotated y add_messages para acumular mensajes en lugar de sobrescribirlos: from typing import Annotated from langgraph.graph.message import add_messages class State ( TypedDict ): messages : Annotated [ list [ AnyMessage ], add_messages ] # Con reducer (acumula) response : str department : str Annotated permite a\u00f1adir metadatos a messages para definir un reducer. add_messages acumula mensajes en el historial, evitando sobrescrituras. Cada vez que un nodo a\u00f1ade un mensaje, este se agrega al final de la lista. \ud83d\udd0d El Papel del Reducer (add_messages) Cuando definimos: messages : Annotated [ list [ AnyMessage ], add_messages ] Estamos indicando que cuando un nodo devuelve una actualizaci\u00f3n parcial del estado, el reducer add_messages se encargar\u00e1 de combinar el valor nuevo con el existente. Esto implica que: Si un nodo devuelve {\"messages\": [...]} , el reducer add_messages sumar\u00e1 los mensajes nuevos a la lista actual. Si no hay un reducer definido, el nuevo valor reemplazar\u00e1 al valor anterior. \ud83d\udca1 Los reducers solo se activan cuando un nodo devuelve una actualizaci\u00f3n parcial o el estado completo. Es importante tener esto en cuenta si planeamos realizar otras modificaciones manualmente, ya que los cambios directos en el estado no pasar\u00e1n por el reducer . \ud83d\udee0\ufe0f Ejemplo Completo: Comparando con y sin Reducer Vamos a construir un grafo de chatbot que: 1. Recibe el mensaje del usuario. 2. Redirige al nodo correspondiente (soporte, ventas, general). 3. A\u00f1ade respuestas al historial de mensajes usando un reducer. Veremos c\u00f3mo cambia el resultado al usar un reducer para messages . from langchain_core.messages import HumanMessage , AIMessage from langgraph.graph import StateGraph , START , END def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) return { \"messages\" : HumanMessage ( content = \"Hola, tengo una pregunta.\" )} def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"response\" ] = \"Soporte\" return { \"messages\" : AIMessage ( content = \"Te estamos transfiriendo a soporte.\" )} def route_request ( state : State ) -> str : return \"support_node\" builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"support_node\" ) builder . add_edge ( \"support_node\" , END ) graph = builder . compile () \ud83d\ude80 Invocando el Grafo Probamos el grafo sin reducer y luego con add_messages para observar la diferencia. graph . invoke ({ \"messages\" : [], \"response\" : \"\" , \"department\" : \"\" }) # Sin reducer (sobrescribe) { 'messages' : [ AIMessage ( content = \"Te estamos transfiriendo a soporte.\" )], 'response' : 'Soporte' , 'department' : '' } # Con reducer (acumula) { 'messages' : [ HumanMessage ( content = \"Hola, tengo una pregunta.\" ), AIMessage ( content = \"Te estamos transfiriendo a soporte.\" ) ], 'response' : 'Soporte' , 'department' : '' } Sin Reducer: Solo el \u00faltimo mensaje aparece en el estado. Con Reducer: El historial acumula todos los mensajes y respuestas. \u2728 \u00bfC\u00f3mo Crear un Reducer Personalizado? Si necesitas una l\u00f3gica espec\u00edfica que add_messages no cubre, puedes crear tu propio reducer. A continuaci\u00f3n, definimos un reducer personalizado que cuenta cu\u00e1ntos mensajes se han procesado y actualiza el estado con ese total: from typing import Annotated , Union from typing_extensions import TypedDict from langchain_core.messages import AnyMessage , HumanMessage , AIMessage from langgraph.graph.message import add_messages from langgraph.graph import StateGraph , START , END # Definir un reducer personalizado que cuenta los mensajes def count_messages ( existing : int , new : Union [ list [ AnyMessage ], AnyMessage ]) -> int : # Si 'new' es una lista, sumamos su longitud. Si es un solo mensaje, sumamos 1. if isinstance ( new , list ): return existing + len ( new ) return existing + 1 # Definir el estado con historial de mensajes y contador total class StateCustomReducer ( TypedDict ): messages : Annotated [ list [ AnyMessage ], add_messages ] total_messages : Annotated [ int , count_messages ] response : str # Nodo de entrada del usuario def user_input ( state : StateCustomReducer ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) state [ \"messages\" ] . append ( HumanMessage ( content = \"Hola, tengo una consulta.\" )) return state # Nodo de respuesta de soporte def support_node ( state : StateCustomReducer ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"messages\" ] . append ( AIMessage ( content = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" )) state [ \"response\" ] = \"Soporte\" return state # Nodo de ventas def sales_node ( state : StateCustomReducer ): print ( \"--- Nodo de Ventas ---\" ) state [ \"messages\" ] . append ( AIMessage ( content = \"Te conectamos con el equipo de ventas.\" )) state [ \"response\" ] = \"Ventas\" return state # Router que decide a qu\u00e9 nodo enviar def route_request ( state : StateCustomReducer ) -> str : if \"compra\" in state [ \"messages\" ][ - 1 ] . content . lower (): return \"sales_node\" return \"support_node\" # Construcci\u00f3n del grafo builder = StateGraph ( StateCustomReducer ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_edge ( START , \"user_input\" ) builder . add_conditional_edges ( \"user_input\" , route_request ) builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) # Compilar el grafo graph_with_custom_reducer = builder . compile () from IPython.display import Image , display display ( Image ( graph_with_custom_reducer . get_graph () . draw_mermaid_png ())) Ejecutamos el grafo y verificamos c\u00f3mo el estado se actualiza con el n\u00famero total de mensajes. graph_with_custom_reducer . invoke ({ \"messages\" : [], \"total_messages\" : 0 , \"response\" : \"\" }) Resultado { 'messages' : [ HumanMessage ( content = \"Hola, tengo una pregunta.\" ), AIMessage ( content = \"Te estamos transfiriendo a soporte.\" ) ], 'total_messages' : 2 , 'response' : 'Soporte' } El estado reflejar\u00e1 tanto el historial de mensajes como el conteo total. \ud83d\udd0e Recursos: Ver notebook en Google Colab Definici\u00f3n Reducers \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? Reducers: Controlan c\u00f3mo se actualiza el estado durante el flujo del grafo. add_messages: Permite acumular mensajes, evitando sobrescrituras. Reducers Personalizados: Proporcionan flexibilidad para definir cualquier l\u00f3gica de actualizaci\u00f3n. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el pr\u00f3ximo tema, exploraremos Tools (Herramientas) , viendo c\u00f3mo integrar funciones externas y APIs dentro del grafo para ampliar sus capacidades.","title":"Tema 7: Reducers"},{"location":"curso1/tema7_reducers/#tema-7-reducers","text":"","title":"\ud83d\udd04 Tema 7: Reducers"},{"location":"curso1/tema7_reducers/#que-es-un-reducer-en-langgraph","text":"Los reducers en LangGraph permiten consolidar y procesar datos provenientes de diferentes nodos o caminos. Cuando un grafo sigue flujos paralelos o m\u00faltiples bifurcaciones , los reducers recogen, combinan o modifican los resultados, facilitando una salida coherente y organizada. \ud83d\udc49 Piensa en un reducer como un colector de datos que une los resultados de distintas partes del grafo en un solo punto.","title":"\ud83d\ude80 \u00bfQu\u00e9 es un Reducer en LangGraph?"},{"location":"curso1/tema7_reducers/#por-que-son-importantes-los-reducers","text":"Consolidaci\u00f3n de Datos: Re\u00fane informaci\u00f3n de diferentes nodos y la almacena en el estado. Flujos Complejos: Permite manejar y combinar respuestas de m\u00faltiples caminos paralelos. Evitan Sobrescrituras No Deseadas: Sin un reducer, cada actualizaci\u00f3n sobrescribe el valor existente.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 son Importantes los Reducers?"},{"location":"curso1/tema7_reducers/#como-funciona-un-reducer","text":"Cuando un nodo devuelve datos parciales del estado, el reducer decide c\u00f3mo aplicar esos datos : - Sin Reducer: El valor existente se sobrescribe. - Con Reducer: Los datos se combinan o acumulan siguiendo una l\u00f3gica definida. \ud83d\udc49 Ejemplo: Si tienes una lista de mensajes, un reducer puede a\u00f1adir nuevos mensajes al final, en lugar de borrar el historial anterior.","title":"\u2699\ufe0f \u00bfC\u00f3mo Funciona un Reducer?"},{"location":"curso1/tema7_reducers/#ejemplo-a-sin-reducer-sobrescritura-directa","text":"En este caso, cada vez que un nodo devuelve un valor, sobrescribe el valor anterior: from typing_extensions import TypedDict from langchain_core.messages import AnyMessage class State ( TypedDict ): messages : list [ AnyMessage ] # Sin reducer (sobrescribe) response : str department : str","title":"\ud83d\udd0d Ejemplo A: Sin Reducer (Sobrescritura Directa)"},{"location":"curso1/tema7_reducers/#explicacion","text":"La clave messages no tiene un reducer asignado. Cada actualizaci\u00f3n de mensajes reemplaza por completo la lista anterior. El \u00faltimo mensaje ser\u00e1 el \u00fanico que quede en el estado.","title":"\ud83d\udd0e Explicaci\u00f3n:"},{"location":"curso1/tema7_reducers/#ejemplo-b-con-reducer-acumulacion-de-mensajes","text":"Usamos Annotated y add_messages para acumular mensajes en lugar de sobrescribirlos: from typing import Annotated from langgraph.graph.message import add_messages class State ( TypedDict ): messages : Annotated [ list [ AnyMessage ], add_messages ] # Con reducer (acumula) response : str department : str Annotated permite a\u00f1adir metadatos a messages para definir un reducer. add_messages acumula mensajes en el historial, evitando sobrescrituras. Cada vez que un nodo a\u00f1ade un mensaje, este se agrega al final de la lista.","title":"\ud83d\udccb Ejemplo B: Con Reducer (Acumulaci\u00f3n de Mensajes)"},{"location":"curso1/tema7_reducers/#el-papel-del-reducer-add_messages","text":"Cuando definimos: messages : Annotated [ list [ AnyMessage ], add_messages ] Estamos indicando que cuando un nodo devuelve una actualizaci\u00f3n parcial del estado, el reducer add_messages se encargar\u00e1 de combinar el valor nuevo con el existente. Esto implica que: Si un nodo devuelve {\"messages\": [...]} , el reducer add_messages sumar\u00e1 los mensajes nuevos a la lista actual. Si no hay un reducer definido, el nuevo valor reemplazar\u00e1 al valor anterior. \ud83d\udca1 Los reducers solo se activan cuando un nodo devuelve una actualizaci\u00f3n parcial o el estado completo. Es importante tener esto en cuenta si planeamos realizar otras modificaciones manualmente, ya que los cambios directos en el estado no pasar\u00e1n por el reducer .","title":"\ud83d\udd0d El Papel del Reducer (add_messages)"},{"location":"curso1/tema7_reducers/#ejemplo-completo-comparando-con-y-sin-reducer","text":"Vamos a construir un grafo de chatbot que: 1. Recibe el mensaje del usuario. 2. Redirige al nodo correspondiente (soporte, ventas, general). 3. A\u00f1ade respuestas al historial de mensajes usando un reducer. Veremos c\u00f3mo cambia el resultado al usar un reducer para messages . from langchain_core.messages import HumanMessage , AIMessage from langgraph.graph import StateGraph , START , END def user_input ( state : State ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) return { \"messages\" : HumanMessage ( content = \"Hola, tengo una pregunta.\" )} def support_node ( state : State ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"response\" ] = \"Soporte\" return { \"messages\" : AIMessage ( content = \"Te estamos transfiriendo a soporte.\" )} def route_request ( state : State ) -> str : return \"support_node\" builder = StateGraph ( State ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_edge ( START , \"user_input\" ) builder . add_edge ( \"user_input\" , \"support_node\" ) builder . add_edge ( \"support_node\" , END ) graph = builder . compile ()","title":"\ud83d\udee0\ufe0f Ejemplo Completo: Comparando con y sin Reducer"},{"location":"curso1/tema7_reducers/#invocando-el-grafo","text":"Probamos el grafo sin reducer y luego con add_messages para observar la diferencia. graph . invoke ({ \"messages\" : [], \"response\" : \"\" , \"department\" : \"\" }) # Sin reducer (sobrescribe) { 'messages' : [ AIMessage ( content = \"Te estamos transfiriendo a soporte.\" )], 'response' : 'Soporte' , 'department' : '' } # Con reducer (acumula) { 'messages' : [ HumanMessage ( content = \"Hola, tengo una pregunta.\" ), AIMessage ( content = \"Te estamos transfiriendo a soporte.\" ) ], 'response' : 'Soporte' , 'department' : '' } Sin Reducer: Solo el \u00faltimo mensaje aparece en el estado. Con Reducer: El historial acumula todos los mensajes y respuestas.","title":"\ud83d\ude80 Invocando el Grafo"},{"location":"curso1/tema7_reducers/#como-crear-un-reducer-personalizado","text":"Si necesitas una l\u00f3gica espec\u00edfica que add_messages no cubre, puedes crear tu propio reducer. A continuaci\u00f3n, definimos un reducer personalizado que cuenta cu\u00e1ntos mensajes se han procesado y actualiza el estado con ese total: from typing import Annotated , Union from typing_extensions import TypedDict from langchain_core.messages import AnyMessage , HumanMessage , AIMessage from langgraph.graph.message import add_messages from langgraph.graph import StateGraph , START , END # Definir un reducer personalizado que cuenta los mensajes def count_messages ( existing : int , new : Union [ list [ AnyMessage ], AnyMessage ]) -> int : # Si 'new' es una lista, sumamos su longitud. Si es un solo mensaje, sumamos 1. if isinstance ( new , list ): return existing + len ( new ) return existing + 1 # Definir el estado con historial de mensajes y contador total class StateCustomReducer ( TypedDict ): messages : Annotated [ list [ AnyMessage ], add_messages ] total_messages : Annotated [ int , count_messages ] response : str # Nodo de entrada del usuario def user_input ( state : StateCustomReducer ): print ( \"--- Nodo 1: Entrada del Usuario ---\" ) state [ \"messages\" ] . append ( HumanMessage ( content = \"Hola, tengo una consulta.\" )) return state # Nodo de respuesta de soporte def support_node ( state : StateCustomReducer ): print ( \"--- Nodo de Soporte T\u00e9cnico ---\" ) state [ \"messages\" ] . append ( AIMessage ( content = \"Te estamos transfiriendo a soporte t\u00e9cnico.\" )) state [ \"response\" ] = \"Soporte\" return state # Nodo de ventas def sales_node ( state : StateCustomReducer ): print ( \"--- Nodo de Ventas ---\" ) state [ \"messages\" ] . append ( AIMessage ( content = \"Te conectamos con el equipo de ventas.\" )) state [ \"response\" ] = \"Ventas\" return state # Router que decide a qu\u00e9 nodo enviar def route_request ( state : StateCustomReducer ) -> str : if \"compra\" in state [ \"messages\" ][ - 1 ] . content . lower (): return \"sales_node\" return \"support_node\" # Construcci\u00f3n del grafo builder = StateGraph ( StateCustomReducer ) builder . add_node ( \"user_input\" , user_input ) builder . add_node ( \"support_node\" , support_node ) builder . add_node ( \"sales_node\" , sales_node ) builder . add_edge ( START , \"user_input\" ) builder . add_conditional_edges ( \"user_input\" , route_request ) builder . add_edge ( \"support_node\" , END ) builder . add_edge ( \"sales_node\" , END ) # Compilar el grafo graph_with_custom_reducer = builder . compile () from IPython.display import Image , display display ( Image ( graph_with_custom_reducer . get_graph () . draw_mermaid_png ())) Ejecutamos el grafo y verificamos c\u00f3mo el estado se actualiza con el n\u00famero total de mensajes. graph_with_custom_reducer . invoke ({ \"messages\" : [], \"total_messages\" : 0 , \"response\" : \"\" }) Resultado { 'messages' : [ HumanMessage ( content = \"Hola, tengo una pregunta.\" ), AIMessage ( content = \"Te estamos transfiriendo a soporte.\" ) ], 'total_messages' : 2 , 'response' : 'Soporte' } El estado reflejar\u00e1 tanto el historial de mensajes como el conteo total.","title":"\u2728 \u00bfC\u00f3mo Crear un Reducer Personalizado?"},{"location":"curso1/tema7_reducers/#recursos","text":"Ver notebook en Google Colab Definici\u00f3n Reducers","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema7_reducers/#que-hemos-aprendido","text":"Reducers: Controlan c\u00f3mo se actualiza el estado durante el flujo del grafo. add_messages: Permite acumular mensajes, evitando sobrescrituras. Reducers Personalizados: Proporcionan flexibilidad para definir cualquier l\u00f3gica de actualizaci\u00f3n.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema7_reducers/#que-es-lo-siguiente","text":"En el pr\u00f3ximo tema, exploraremos Tools (Herramientas) , viendo c\u00f3mo integrar funciones externas y APIs dentro del grafo para ampliar sus capacidades.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema8_tools/","text":"\ud83d\udee0\ufe0f Tema 7: Tools \u2013 Integraci\u00f3n de Herramientas Externas en el Grafo \ud83d\ude80 \u00bfQu\u00e9 son las Tools en LangGraph? Las tools (herramientas) son funciones externas que el grafo puede invocar para realizar tareas espec\u00edficas, como consultas a bases de datos, c\u00e1lculos matem\u00e1ticos o llamadas a APIs externas. Las tools permiten que el grafo extienda sus capacidades m\u00e1s all\u00e1 de los nodos internos , integrando l\u00f3gica personalizada o servicios de terceros. \ud83e\udde0 \u00bfPor qu\u00e9 son Importantes las Tools? Extensibilidad: Permiten que el grafo interact\u00fae con APIs externas y sistemas avanzados. Modularidad: Las tools se definen de forma independiente y se integran f\u00e1cilmente en el flujo del grafo. Eficiencia: Delegan tareas espec\u00edficas a funciones externas, reduciendo la complejidad dentro de los nodos. \ud83d\udc49 Piensa en las tools como plugins que a\u00f1aden nuevas capacidades al grafo sin necesidad de modificar su estructura central. \u2699\ufe0f \u00bfC\u00f3mo Funcionan las Tools? Definici\u00f3n de Tools: Creamos funciones externas que pueden recibir par\u00e1metros y devolver resultados. Vinculaci\u00f3n al Modelo de Lenguaje (LLM): Asociamos estas tools al LLM para que pueda invocarlas durante el flujo de trabajo. Ejecuci\u00f3n Condicional: Si el LLM detecta que es necesario usar una tool, el grafo redirige el flujo para ejecutarla y procesar el resultado. \ud83d\udca1 Es fundamental entender que es el LLM quien decide qu\u00e9 tool invocar en funci\u00f3n del mensaje o prompt proporcionado. El grafo facilita la integraci\u00f3n de herramientas, pero la decisi\u00f3n de cu\u00e1l utilizar se basa en la interpretaci\u00f3n que hace el modelo del contexto y las instrucciones. \ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Tools para Soporte y Ventas Vamos a construir un grafo que act\u00faa como un asistente virtual, redirigiendo solicitudes de los usuarios a diferentes herramientas seg\u00fan sus necesidades. El chatbot podr\u00e1: 1. Consultar precios de productos. 2. Verificar el estado de pedidos. 3. Abrir tickets de soporte. from langchain_openai import ChatOpenAI # Definimos las tools externas con docstrings def check_price ( product : str ) -> str : \"\"\"Consulta el precio de un producto. Args: product: Nombre del producto a consultar. Returns: El precio del producto en formato texto. \"\"\" # Simulamos una consulta a nuestra base de datos. return f \"El precio de { product } es de 100\u20ac.\" def order_status ( order_id : int ) -> str : \"\"\"Consulta el estado de un pedido. Args: order_id: ID del pedido. Returns: El estado actual del pedido. \"\"\" # Simulamos una consulta a nuestro ORM. return f \"El pedido con ID { order_id } est\u00e1 en camino.\" def open_ticket ( issue : str ) -> str : \"\"\"Abre un ticket de soporte. Args: issue: Descripci\u00f3n del problema o incidencia. Returns: Confirmaci\u00f3n de apertura del ticket. \"\"\" # Simulamos una creacion de un ticket en nuestro sistema de soporte. return f \"Se ha abierto un ticket de soporte para el problema: { issue } .\" tools = [ check_price , order_status , open_ticket ] # Vinculamos las tools al modelo de lenguaje llm = ChatOpenAI ( model = \"gpt-4o-mini\" ) llm_with_tools = llm . bind_tools ( tools , parallel_tool_calls = False ) Tools ( check_price , order_status , open_ticket ): Simulan herramientas externas que realizan distintas tareas para ventas y soporte. Nota Importante: Cuando llamamos a bind_tools , no se modifica el modelo original ( llm ) , sino que se genera una nueva instancia con las herramientas vinculadas. Por esta raz\u00f3n, es necesario asignarlo a una nueva variable ( llm_with_tools ). Esto garantiza que el modelo original permanezca sin cambios y podamos reutilizarlo o aplicar diferentes herramientas en otros contextos. Ejemplo: llm_with_tools = llm . bind_tools ( tools , parallel_tool_calls = False ) \ud83d\udc49 llm sigue siendo el modelo base, mientras que llm_with_tools es la versi\u00f3n extendida con las tools activas. \ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo Creamos los nodos y edges necesarios para integrar las tools al flujo del grafo. from langgraph.graph import MessagesState from langchain_core.messages import HumanMessage , SystemMessage from langgraph.graph import START , StateGraph from langgraph.prebuilt import tools_condition from langgraph.prebuilt import ToolNode sys_msg = SystemMessage ( content = \"Eres un asistente de ventas y soporte. Responde usando las herramientas disponibles.\" ) def assistant ( state : MessagesState ): return { \"messages\" : [ llm_with_tools . invoke ([ sys_msg ] + state [ \"messages\" ])]} builder = StateGraph ( MessagesState ) # A\u00f1adimos nodos builder . add_node ( \"assistant\" , assistant ) builder . add_node ( \"tools\" , ToolNode ( tools )) # Definimos los edges y el flujo del grafo builder . add_edge ( START , \"assistant\" ) builder . add_conditional_edges ( \"assistant\" , tools_condition ) builder . add_edge ( \"tools\" , \"assistant\" ) graph_with_tools = builder . compile () from IPython.display import Image , display display ( Image ( graph_with_tools . get_graph ( xray = True ) . draw_mermaid_png ())) Assistant Node: El nodo principal procesa el mensaje del usuario y decide si debe invocar alguna tool. Router Condicional: El flujo se redirige al nodo de tools si se detecta una llamada a alguna de ellas. \ud83d\ude80 Invocando el Grafo Probamos el grafo enviando un mensaje del usuario para ver c\u00f3mo se invocan las tools en el flujo. messages = [ HumanMessage ( content = \"Quiero saber el precio del producto 'RTX4070' y abrir un ticket de soporte.\" )] response = graph_with_tools . invoke ({ \"messages\" : messages }) for msg in response [ \"messages\" ]: msg . pretty_print () Response ================================ Human Message ================================= Quiero saber el precio del producto 'RTX4070' y abrir un ticket de soporte . ================================== Ai Message ================================== Tool Calls : check_price ( call_0Ws3GDPS0sZHn3xhK6M10pxX ) Call ID : call_0Ws3GDPS0sZHn3xhK6M10pxX Args : product : RTX4070 ================================= Tool Message ================================= Name : check_price El precio de RTX4070 es de 100 \u20ac . ================================== Ai Message ================================== El precio de la RTX4070 es de 100 \u20ac . Ahora , por favor , ind\u00edcame la descripci\u00f3n del problema o incidencia para abrir el ticket de soporte . El chatbot analiza la solicitud, invoca las tools adecuadas y devuelve una respuesta consolidada al usuario. \ud83d\udd0e Recursos: Ver notebook en Google Colab Definici\u00f3n: Tools \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? Tools: Permiten extender el grafo con funciones externas que realizan tareas espec\u00edficas. Integraci\u00f3n con LLM: Las tools se vinculan directamente al modelo de lenguaje, permitiendo respuestas m\u00e1s avanzadas. Flujo Din\u00e1mico: El grafo puede invocar tools de forma condicional, adapt\u00e1ndose a las necesidades del usuario. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? En el pr\u00f3ximo tema, exploraremos Trim y Filter Messages , t\u00e9cnicas que permiten controlar y optimizar el historial de mensajes en el grafo. Esto es clave para gestionar conversaciones largas y garantizar que el modelo reciba solo la informaci\u00f3n m\u00e1s relevante.","title":"Tema 8: Tools"},{"location":"curso1/tema8_tools/#tema-7-tools-integracion-de-herramientas-externas-en-el-grafo","text":"","title":"\ud83d\udee0\ufe0f Tema 7: Tools \u2013 Integraci\u00f3n de Herramientas Externas en el Grafo"},{"location":"curso1/tema8_tools/#que-son-las-tools-en-langgraph","text":"Las tools (herramientas) son funciones externas que el grafo puede invocar para realizar tareas espec\u00edficas, como consultas a bases de datos, c\u00e1lculos matem\u00e1ticos o llamadas a APIs externas. Las tools permiten que el grafo extienda sus capacidades m\u00e1s all\u00e1 de los nodos internos , integrando l\u00f3gica personalizada o servicios de terceros.","title":"\ud83d\ude80 \u00bfQu\u00e9 son las Tools en LangGraph?"},{"location":"curso1/tema8_tools/#por-que-son-importantes-las-tools","text":"Extensibilidad: Permiten que el grafo interact\u00fae con APIs externas y sistemas avanzados. Modularidad: Las tools se definen de forma independiente y se integran f\u00e1cilmente en el flujo del grafo. Eficiencia: Delegan tareas espec\u00edficas a funciones externas, reduciendo la complejidad dentro de los nodos. \ud83d\udc49 Piensa en las tools como plugins que a\u00f1aden nuevas capacidades al grafo sin necesidad de modificar su estructura central.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 son Importantes las Tools?"},{"location":"curso1/tema8_tools/#como-funcionan-las-tools","text":"Definici\u00f3n de Tools: Creamos funciones externas que pueden recibir par\u00e1metros y devolver resultados. Vinculaci\u00f3n al Modelo de Lenguaje (LLM): Asociamos estas tools al LLM para que pueda invocarlas durante el flujo de trabajo. Ejecuci\u00f3n Condicional: Si el LLM detecta que es necesario usar una tool, el grafo redirige el flujo para ejecutarla y procesar el resultado. \ud83d\udca1 Es fundamental entender que es el LLM quien decide qu\u00e9 tool invocar en funci\u00f3n del mensaje o prompt proporcionado. El grafo facilita la integraci\u00f3n de herramientas, pero la decisi\u00f3n de cu\u00e1l utilizar se basa en la interpretaci\u00f3n que hace el modelo del contexto y las instrucciones.","title":"\u2699\ufe0f \u00bfC\u00f3mo Funcionan las Tools?"},{"location":"curso1/tema8_tools/#ejemplo-practico-chatbot-con-tools-para-soporte-y-ventas","text":"Vamos a construir un grafo que act\u00faa como un asistente virtual, redirigiendo solicitudes de los usuarios a diferentes herramientas seg\u00fan sus necesidades. El chatbot podr\u00e1: 1. Consultar precios de productos. 2. Verificar el estado de pedidos. 3. Abrir tickets de soporte. from langchain_openai import ChatOpenAI # Definimos las tools externas con docstrings def check_price ( product : str ) -> str : \"\"\"Consulta el precio de un producto. Args: product: Nombre del producto a consultar. Returns: El precio del producto en formato texto. \"\"\" # Simulamos una consulta a nuestra base de datos. return f \"El precio de { product } es de 100\u20ac.\" def order_status ( order_id : int ) -> str : \"\"\"Consulta el estado de un pedido. Args: order_id: ID del pedido. Returns: El estado actual del pedido. \"\"\" # Simulamos una consulta a nuestro ORM. return f \"El pedido con ID { order_id } est\u00e1 en camino.\" def open_ticket ( issue : str ) -> str : \"\"\"Abre un ticket de soporte. Args: issue: Descripci\u00f3n del problema o incidencia. Returns: Confirmaci\u00f3n de apertura del ticket. \"\"\" # Simulamos una creacion de un ticket en nuestro sistema de soporte. return f \"Se ha abierto un ticket de soporte para el problema: { issue } .\" tools = [ check_price , order_status , open_ticket ] # Vinculamos las tools al modelo de lenguaje llm = ChatOpenAI ( model = \"gpt-4o-mini\" ) llm_with_tools = llm . bind_tools ( tools , parallel_tool_calls = False ) Tools ( check_price , order_status , open_ticket ): Simulan herramientas externas que realizan distintas tareas para ventas y soporte. Nota Importante: Cuando llamamos a bind_tools , no se modifica el modelo original ( llm ) , sino que se genera una nueva instancia con las herramientas vinculadas. Por esta raz\u00f3n, es necesario asignarlo a una nueva variable ( llm_with_tools ). Esto garantiza que el modelo original permanezca sin cambios y podamos reutilizarlo o aplicar diferentes herramientas en otros contextos. Ejemplo: llm_with_tools = llm . bind_tools ( tools , parallel_tool_calls = False ) \ud83d\udc49 llm sigue siendo el modelo base, mientras que llm_with_tools es la versi\u00f3n extendida con las tools activas.","title":"\ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Tools para Soporte y Ventas"},{"location":"curso1/tema8_tools/#construccion-del-grafo","text":"Creamos los nodos y edges necesarios para integrar las tools al flujo del grafo. from langgraph.graph import MessagesState from langchain_core.messages import HumanMessage , SystemMessage from langgraph.graph import START , StateGraph from langgraph.prebuilt import tools_condition from langgraph.prebuilt import ToolNode sys_msg = SystemMessage ( content = \"Eres un asistente de ventas y soporte. Responde usando las herramientas disponibles.\" ) def assistant ( state : MessagesState ): return { \"messages\" : [ llm_with_tools . invoke ([ sys_msg ] + state [ \"messages\" ])]} builder = StateGraph ( MessagesState ) # A\u00f1adimos nodos builder . add_node ( \"assistant\" , assistant ) builder . add_node ( \"tools\" , ToolNode ( tools )) # Definimos los edges y el flujo del grafo builder . add_edge ( START , \"assistant\" ) builder . add_conditional_edges ( \"assistant\" , tools_condition ) builder . add_edge ( \"tools\" , \"assistant\" ) graph_with_tools = builder . compile () from IPython.display import Image , display display ( Image ( graph_with_tools . get_graph ( xray = True ) . draw_mermaid_png ())) Assistant Node: El nodo principal procesa el mensaje del usuario y decide si debe invocar alguna tool. Router Condicional: El flujo se redirige al nodo de tools si se detecta una llamada a alguna de ellas.","title":"\ud83c\udfd7\ufe0f Construcci\u00f3n del Grafo"},{"location":"curso1/tema8_tools/#invocando-el-grafo","text":"Probamos el grafo enviando un mensaje del usuario para ver c\u00f3mo se invocan las tools en el flujo. messages = [ HumanMessage ( content = \"Quiero saber el precio del producto 'RTX4070' y abrir un ticket de soporte.\" )] response = graph_with_tools . invoke ({ \"messages\" : messages }) for msg in response [ \"messages\" ]: msg . pretty_print () Response ================================ Human Message ================================= Quiero saber el precio del producto 'RTX4070' y abrir un ticket de soporte . ================================== Ai Message ================================== Tool Calls : check_price ( call_0Ws3GDPS0sZHn3xhK6M10pxX ) Call ID : call_0Ws3GDPS0sZHn3xhK6M10pxX Args : product : RTX4070 ================================= Tool Message ================================= Name : check_price El precio de RTX4070 es de 100 \u20ac . ================================== Ai Message ================================== El precio de la RTX4070 es de 100 \u20ac . Ahora , por favor , ind\u00edcame la descripci\u00f3n del problema o incidencia para abrir el ticket de soporte . El chatbot analiza la solicitud, invoca las tools adecuadas y devuelve una respuesta consolidada al usuario.","title":"\ud83d\ude80 Invocando el Grafo"},{"location":"curso1/tema8_tools/#recursos","text":"Ver notebook en Google Colab Definici\u00f3n: Tools","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema8_tools/#que-hemos-aprendido","text":"Tools: Permiten extender el grafo con funciones externas que realizan tareas espec\u00edficas. Integraci\u00f3n con LLM: Las tools se vinculan directamente al modelo de lenguaje, permitiendo respuestas m\u00e1s avanzadas. Flujo Din\u00e1mico: El grafo puede invocar tools de forma condicional, adapt\u00e1ndose a las necesidades del usuario.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema8_tools/#que-es-lo-siguiente","text":"En el pr\u00f3ximo tema, exploraremos Trim y Filter Messages , t\u00e9cnicas que permiten controlar y optimizar el historial de mensajes en el grafo. Esto es clave para gestionar conversaciones largas y garantizar que el modelo reciba solo la informaci\u00f3n m\u00e1s relevante.","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso1/tema9_trim_filter/","text":"\u2702\ufe0f Tema 8: Trim y Filter Messages \u2013 Optimizaci\u00f3n del Historial de Mensajes \ud83d\ude80 \u00bfQu\u00e9 es el Trimming y Filtering de Mensajes? A medida que un grafo interact\u00faa con los usuarios, el historial de mensajes puede crecer considerablemente , lo que puede: - Aumentar el costo de procesamiento para los modelos LLM. - Reducir la eficiencia del grafo en conversaciones largas. - Diluir el contexto , incluyendo mensajes irrelevantes. Para solucionar esto, LangGraph ofrece herramientas que permiten gestionar y optimizar el historial de mensajes : RemoveMessages \u2013 Elimina mensajes espec\u00edficos. trim_messages \u2013 Recorta el historial manteniendo solo los mensajes m\u00e1s recientes. summarize_conversation \u2013 Resume la conversaci\u00f3n para reducir la longitud del historial, manteniendo el contexto. Nota Importante: Al eliminar mensajes del historial, es crucial asegurarse de que la estructura de los mensajes siga siendo v\u00e1lida para el modelo LLM. Algunos modelos, como los chatbots basados en LLM, requieren que el primer mensaje sea de un Humano ( HumanMessage ). \ud83d\udc49 Antes de procesar el historial, verifica que la estructura cumpla con los requisitos del modelo para evitar errores en su funcionamiento. \ud83e\udde0 \u00bfPor qu\u00e9 es Importante? Optimizaci\u00f3n del Rendimiento: Reduce la cantidad de datos enviados al LLM. Mejora de la Precisi\u00f3n: Mantiene el contexto relevante, eliminando informaci\u00f3n redundante. Ahorro de Costos: Menos tokens procesados significa menos consumo de recursos. \u2699\ufe0f \u00bfC\u00f3mo Funciona el Trimming y Filtering? LangGraph ofrece diferentes enfoques seg\u00fan el escenario: - Eliminar mensajes irrelevantes o antiguos. - Recortar autom\u00e1ticamente despu\u00e9s de alcanzar un l\u00edmite. - Resumir el historial para mantener el contexto clave. \ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Gesti\u00f3n del Historial de Mensajes Vamos a crear un chatbot que interact\u00faa con el usuario, pero gestiona el historial para mantener solo los mensajes relevantes y no saturar el flujo del grafo. \ud83d\udee0\ufe0f Opci\u00f3n 1: Eliminar Mensajes Espec\u00edficos con RemoveMessages Permite eliminar ciertos mensajes del historial, ideal para eliminar mensajes duplicados o irrelevantes. from langchain_core.messages import HumanMessage , AIMessage , RemoveMessage from IPython.display import Image , display from langgraph.graph import MessagesState from langgraph.graph import StateGraph , START , END # Nodes def filter_messages ( state : MessagesState ): # Eliminamos todo el historial menos los 2 mas recientes delete_messages = [ RemoveMessage ( id = m . id ) for m in state [ \"messages\" ][: - 2 ]] return { \"messages\" : delete_messages } def chat_model_node ( state : MessagesState ): # Simulamos una respuesta de un LLM. return { \"messages\" : [ AIMessage ( content = \"El producto B cuesta 150\u20ac y est\u00e1 disponible en color rojo y azul. \u00bfTe interesa alguna de estas opciones?\" , id = \"accce84f-3e31-4cf2-b16d-5aed5a4b890a\" ) ]} # Build graph builder = StateGraph ( MessagesState ) builder . add_node ( \"filter\" , filter_messages ) builder . add_node ( \"chat_model\" , chat_model_node ) builder . add_edge ( START , \"filter\" ) builder . add_edge ( \"filter\" , \"chat_model\" ) builder . add_edge ( \"chat_model\" , END ) graph = builder . compile () # View display ( Image ( graph . get_graph () . draw_mermaid_png ())) messages = [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] response = graph . invoke ({ 'messages' : messages }) for m in response [ 'messages' ]: m . pretty_print () Resuldato ================================== Ai Message ================================== El producto A cuesta 100 \u20ac y est\u00e1 disponible . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ? ================================== Ai Message ================================== El producto B cuesta 150 \u20ac y est\u00e1 disponible en color rojo y azul . \u00bf Te interesa alguna de estas opciones ? \ud83d\udee0\ufe0f Opci\u00f3n 2: Recorte de Mensajes con trim_messages Recorta el historial de mensajes manteniendo solo los \u00faltimos N mensajes. Esto es \u00fatil para evitar que el historial crezca sin control. from langchain_core.messages import trim_messages from langchain_core.messages import HumanMessage , AIMessage # Estado con muchos mensajes state = { \"messages\" : [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] } # Limitamos a los ultimos 3 mensajes para no sobrecargar la llamada. messages = trim_messages ( state [ 'messages' ], token_counter = len , # Contamos mensajes (simple, no tokens) max_tokens = 3 , # L\u00edmite de 3 mensajes strategy = \"last\" , #start_on=\"system\", # Empieza en un mensaje humano o sistema-humano include_system = True , allow_partial = False ) for m in messages : m . pretty_print () Resultado ================================ Human Message ================================= Perfecto . Empecemos con el producto A . ================================== Ai Message ================================== El producto A cuesta 100 \u20ac y est\u00e1 disponible . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ? \ud83d\udee0\ufe0f Opci\u00f3n 3: Resumir Conversaci\u00f3n con summarize_conversation En lugar de eliminar mensajes, genera un resumen de la conversaci\u00f3n manteniendo el contexto en menos palabras. Perfecto para mantener el contexto en conversaciones extensas. def summarize_conversation ( state : State ): # First, we get any existing summary summary = state . get ( \"summary\" , \"\" ) # Create our summarization prompt if summary : # A summary already exists summary_message = ( f \"This is summary of the conversation to date: { summary } \\n\\n \" \"Extend the summary by taking into account the new messages above:\" ) else : summary_message = \"Create a summary of the conversation above:\" # Add prompt to our history messages = state [ \"messages\" ] + [ HumanMessage ( content = summary_message )] response = model . invoke ( messages ) # Delete all but the 2 most recent messages delete_messages = [ RemoveMessage ( id = m . id ) for m in state [ \"messages\" ][: - 2 ]] return { \"summary\" : response . content , \"messages\" : delete_messages } \ud83d\udee0\ufe0f Opci\u00f3n 4: Filtrar Mensajes con filter_messages La funci\u00f3n filter_messages permite aplicar filtros personalizados al historial de mensajes en el grafo. Esto es \u00fatil para eliminar mensajes irrelevantes , mantener solo ciertos tipos de mensajes o aplicar l\u00f3gica m\u00e1s avanzada para estructurar el historial antes de enviarlo al LLM. state = { \"messages\" : [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] } # Resumir la conversaci\u00f3n messages = filter_messages ( state [ \"messages\" ], include_types = \"human\" ) for m in messages : m . pretty_print () Resultado ================================ Human Message ================================= Hola , necesito informaci\u00f3n sobre varios productos . ================================ Human Message ================================= Perfecto . Empecemos con el producto A . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ? \ud83d\udd0e Recursos: Ver notebook en Google Colab Mas ejemplos: Google Colab Definici\u00f3n: trim_messages Definici\u00f3n: RemoveMessages Definici\u00f3n: filter_messages How-to-guide: filter_messages \ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido? RemoveMessages: Elimina mensajes espec\u00edficos del historial. trim_messages: Recorta el historial a los \u00faltimos mensajes. summarize_conversation: Genera res\u00famenes que conservan el contexto sin saturar el historial. filter_messages: Aplica filtros personalizados a un historial. \ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente? \ud83c\udf89 \u00a1Has completado el Curso 1: Fundamentos de LangGraph! En este curso, aprendiste los conceptos esenciales de LangGraph, desde la definici\u00f3n de nodos y edges, hasta el uso de chains, routers, reducers y herramientas avanzadas como trim y filter messages. En el Curso 2 , llevaremos tus conocimientos al siguiente nivel: Aprender\u00e1s a integrar LangGraph en aplicaciones reales, explorar el uso de memoria avanzada, flujos paralelos, y c\u00f3mo emplear LangGraph Studio para monitorizar y optimizar tus grafos. \u00a1Prep\u00e1rate para descubrir todo lo que LangGraph puede ofrecer en escenarios complejos y din\u00e1micos!","title":"Tema 9: Trim y Filtrado de Mensajes"},{"location":"curso1/tema9_trim_filter/#tema-8-trim-y-filter-messages-optimizacion-del-historial-de-mensajes","text":"","title":"\u2702\ufe0f Tema 8: Trim y Filter Messages \u2013 Optimizaci\u00f3n del Historial de Mensajes"},{"location":"curso1/tema9_trim_filter/#que-es-el-trimming-y-filtering-de-mensajes","text":"A medida que un grafo interact\u00faa con los usuarios, el historial de mensajes puede crecer considerablemente , lo que puede: - Aumentar el costo de procesamiento para los modelos LLM. - Reducir la eficiencia del grafo en conversaciones largas. - Diluir el contexto , incluyendo mensajes irrelevantes. Para solucionar esto, LangGraph ofrece herramientas que permiten gestionar y optimizar el historial de mensajes : RemoveMessages \u2013 Elimina mensajes espec\u00edficos. trim_messages \u2013 Recorta el historial manteniendo solo los mensajes m\u00e1s recientes. summarize_conversation \u2013 Resume la conversaci\u00f3n para reducir la longitud del historial, manteniendo el contexto. Nota Importante: Al eliminar mensajes del historial, es crucial asegurarse de que la estructura de los mensajes siga siendo v\u00e1lida para el modelo LLM. Algunos modelos, como los chatbots basados en LLM, requieren que el primer mensaje sea de un Humano ( HumanMessage ). \ud83d\udc49 Antes de procesar el historial, verifica que la estructura cumpla con los requisitos del modelo para evitar errores en su funcionamiento.","title":"\ud83d\ude80 \u00bfQu\u00e9 es el Trimming y Filtering de Mensajes?"},{"location":"curso1/tema9_trim_filter/#por-que-es-importante","text":"Optimizaci\u00f3n del Rendimiento: Reduce la cantidad de datos enviados al LLM. Mejora de la Precisi\u00f3n: Mantiene el contexto relevante, eliminando informaci\u00f3n redundante. Ahorro de Costos: Menos tokens procesados significa menos consumo de recursos.","title":"\ud83e\udde0 \u00bfPor qu\u00e9 es Importante?"},{"location":"curso1/tema9_trim_filter/#como-funciona-el-trimming-y-filtering","text":"LangGraph ofrece diferentes enfoques seg\u00fan el escenario: - Eliminar mensajes irrelevantes o antiguos. - Recortar autom\u00e1ticamente despu\u00e9s de alcanzar un l\u00edmite. - Resumir el historial para mantener el contexto clave.","title":"\u2699\ufe0f \u00bfC\u00f3mo Funciona el Trimming y Filtering?"},{"location":"curso1/tema9_trim_filter/#ejemplo-practico-chatbot-con-gestion-del-historial-de-mensajes","text":"Vamos a crear un chatbot que interact\u00faa con el usuario, pero gestiona el historial para mantener solo los mensajes relevantes y no saturar el flujo del grafo.","title":"\ud83d\udccb Ejemplo Pr\u00e1ctico: Chatbot con Gesti\u00f3n del Historial de Mensajes"},{"location":"curso1/tema9_trim_filter/#opcion-1-eliminar-mensajes-especificos-con-removemessages","text":"Permite eliminar ciertos mensajes del historial, ideal para eliminar mensajes duplicados o irrelevantes. from langchain_core.messages import HumanMessage , AIMessage , RemoveMessage from IPython.display import Image , display from langgraph.graph import MessagesState from langgraph.graph import StateGraph , START , END # Nodes def filter_messages ( state : MessagesState ): # Eliminamos todo el historial menos los 2 mas recientes delete_messages = [ RemoveMessage ( id = m . id ) for m in state [ \"messages\" ][: - 2 ]] return { \"messages\" : delete_messages } def chat_model_node ( state : MessagesState ): # Simulamos una respuesta de un LLM. return { \"messages\" : [ AIMessage ( content = \"El producto B cuesta 150\u20ac y est\u00e1 disponible en color rojo y azul. \u00bfTe interesa alguna de estas opciones?\" , id = \"accce84f-3e31-4cf2-b16d-5aed5a4b890a\" ) ]} # Build graph builder = StateGraph ( MessagesState ) builder . add_node ( \"filter\" , filter_messages ) builder . add_node ( \"chat_model\" , chat_model_node ) builder . add_edge ( START , \"filter\" ) builder . add_edge ( \"filter\" , \"chat_model\" ) builder . add_edge ( \"chat_model\" , END ) graph = builder . compile () # View display ( Image ( graph . get_graph () . draw_mermaid_png ())) messages = [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] response = graph . invoke ({ 'messages' : messages }) for m in response [ 'messages' ]: m . pretty_print () Resuldato ================================== Ai Message ================================== El producto A cuesta 100 \u20ac y est\u00e1 disponible . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ? ================================== Ai Message ================================== El producto B cuesta 150 \u20ac y est\u00e1 disponible en color rojo y azul . \u00bf Te interesa alguna de estas opciones ?","title":"\ud83d\udee0\ufe0f Opci\u00f3n 1: Eliminar Mensajes Espec\u00edficos con RemoveMessages"},{"location":"curso1/tema9_trim_filter/#opcion-2-recorte-de-mensajes-con-trim_messages","text":"Recorta el historial de mensajes manteniendo solo los \u00faltimos N mensajes. Esto es \u00fatil para evitar que el historial crezca sin control. from langchain_core.messages import trim_messages from langchain_core.messages import HumanMessage , AIMessage # Estado con muchos mensajes state = { \"messages\" : [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] } # Limitamos a los ultimos 3 mensajes para no sobrecargar la llamada. messages = trim_messages ( state [ 'messages' ], token_counter = len , # Contamos mensajes (simple, no tokens) max_tokens = 3 , # L\u00edmite de 3 mensajes strategy = \"last\" , #start_on=\"system\", # Empieza en un mensaje humano o sistema-humano include_system = True , allow_partial = False ) for m in messages : m . pretty_print () Resultado ================================ Human Message ================================= Perfecto . Empecemos con el producto A . ================================== Ai Message ================================== El producto A cuesta 100 \u20ac y est\u00e1 disponible . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ?","title":"\ud83d\udee0\ufe0f Opci\u00f3n 2: Recorte de Mensajes con trim_messages"},{"location":"curso1/tema9_trim_filter/#opcion-3-resumir-conversacion-con-summarize_conversation","text":"En lugar de eliminar mensajes, genera un resumen de la conversaci\u00f3n manteniendo el contexto en menos palabras. Perfecto para mantener el contexto en conversaciones extensas. def summarize_conversation ( state : State ): # First, we get any existing summary summary = state . get ( \"summary\" , \"\" ) # Create our summarization prompt if summary : # A summary already exists summary_message = ( f \"This is summary of the conversation to date: { summary } \\n\\n \" \"Extend the summary by taking into account the new messages above:\" ) else : summary_message = \"Create a summary of the conversation above:\" # Add prompt to our history messages = state [ \"messages\" ] + [ HumanMessage ( content = summary_message )] response = model . invoke ( messages ) # Delete all but the 2 most recent messages delete_messages = [ RemoveMessage ( id = m . id ) for m in state [ \"messages\" ][: - 2 ]] return { \"summary\" : response . content , \"messages\" : delete_messages }","title":"\ud83d\udee0\ufe0f Opci\u00f3n 3: Resumir Conversaci\u00f3n con summarize_conversation"},{"location":"curso1/tema9_trim_filter/#opcion-4-filtrar-mensajes-con-filter_messages","text":"La funci\u00f3n filter_messages permite aplicar filtros personalizados al historial de mensajes en el grafo. Esto es \u00fatil para eliminar mensajes irrelevantes , mantener solo ciertos tipos de mensajes o aplicar l\u00f3gica m\u00e1s avanzada para estructurar el historial antes de enviarlo al LLM. state = { \"messages\" : [ HumanMessage ( content = 'Hola, necesito informaci\u00f3n sobre varios productos.' , additional_kwargs = {}, response_metadata = {}, id = '66a48850-bcf9-4500-9a0b-6a18ecad0d4a' ), AIMessage ( content = 'Claro, puedo ayudarte con eso.' , additional_kwargs = {}, response_metadata = {}, id = '46bc8fa9-452b-4f16-b5d9-65f527812b8e' ), HumanMessage ( content = 'Perfecto. Empecemos con el producto A.' , additional_kwargs = {}, response_metadata = {}, id = 'ef3742dd-87ac-443a-bbff-72282fb4c1ca' ), AIMessage ( content = 'El producto A cuesta 100\u20ac y est\u00e1 disponible.' , additional_kwargs = {}, response_metadata = {}, id = '038bff18-4498-4ca5-afa8-448c9118b1bc' ), HumanMessage ( content = '\u00bfY qu\u00e9 pasa con el producto B?' , additional_kwargs = {}, response_metadata = {}, id = '1d315b43-906e-48f0-a801-b2807e8abf0a' ) ] } # Resumir la conversaci\u00f3n messages = filter_messages ( state [ \"messages\" ], include_types = \"human\" ) for m in messages : m . pretty_print () Resultado ================================ Human Message ================================= Hola , necesito informaci\u00f3n sobre varios productos . ================================ Human Message ================================= Perfecto . Empecemos con el producto A . ================================ Human Message ================================= \u00bf Y qu\u00e9 pasa con el producto B ?","title":"\ud83d\udee0\ufe0f Opci\u00f3n 4: Filtrar Mensajes con filter_messages"},{"location":"curso1/tema9_trim_filter/#recursos","text":"Ver notebook en Google Colab Mas ejemplos: Google Colab Definici\u00f3n: trim_messages Definici\u00f3n: RemoveMessages Definici\u00f3n: filter_messages How-to-guide: filter_messages","title":"\ud83d\udd0e Recursos:"},{"location":"curso1/tema9_trim_filter/#que-hemos-aprendido","text":"RemoveMessages: Elimina mensajes espec\u00edficos del historial. trim_messages: Recorta el historial a los \u00faltimos mensajes. summarize_conversation: Genera res\u00famenes que conservan el contexto sin saturar el historial. filter_messages: Aplica filtros personalizados a un historial.","title":"\ud83e\uddd1\u200d\ud83c\udfeb \u00bfQu\u00e9 Hemos Aprendido?"},{"location":"curso1/tema9_trim_filter/#que-es-lo-siguiente","text":"\ud83c\udf89 \u00a1Has completado el Curso 1: Fundamentos de LangGraph! En este curso, aprendiste los conceptos esenciales de LangGraph, desde la definici\u00f3n de nodos y edges, hasta el uso de chains, routers, reducers y herramientas avanzadas como trim y filter messages. En el Curso 2 , llevaremos tus conocimientos al siguiente nivel: Aprender\u00e1s a integrar LangGraph en aplicaciones reales, explorar el uso de memoria avanzada, flujos paralelos, y c\u00f3mo emplear LangGraph Studio para monitorizar y optimizar tus grafos. \u00a1Prep\u00e1rate para descubrir todo lo que LangGraph puede ofrecer en escenarios complejos y din\u00e1micos!","title":"\ud83c\udf10 \u00bfQu\u00e9 es lo Siguiente?"},{"location":"curso2/","text":"\u2699\ufe0f Curso 2: Aplicaciones Avanzadas \ud83d\udc4b Bienvenida al Curso 2 Bienvenido al segundo curso de nuestra serie sobre LangGraph. \ud83c\udf10 En este m\u00f3dulo, llevaremos tus habilidades al siguiente nivel al explorar aplicaciones avanzadas como chatbots, paralelismo, subgraf\u00edas y mucho m\u00e1s. Este curso se centra en maximizar la eficiencia y escalabilidad de tus flujos de trabajo. \ud83c\udfaf \u00bfQu\u00e9 Aprenderemos? Desarrollar chatbots con capacidad de resumen y generaci\u00f3n de respuestas. Implementar Human in the Loop para correcciones manuales. Integrar streaming y puntos de interrupci\u00f3n din\u00e1micos. Crear flujos paralelos y subgraf\u00edas interconectadas. Usar LangGraph Studio y LangSmith para monitoreo y pruebas. \ud83c\udfc6 Objetivo del Curso El objetivo es ense\u00f1arte c\u00f3mo crear soluciones complejas con flujos paralelos, implementar intervenci\u00f3n humana en tiempo real y desarrollar chatbots de alto rendimiento integrando t\u00e9cnicas avanzadas. \ud83d\udccb Temario Tema 1: Chatbot Summarizing Tema 2: Human in the Loop Tema 3: Streaming y Breakpoints Tema 4: Paralelismo Tema 5: Subgraf\u00edas (Sub-graphs) Tema 6: Mapas Tema 7: RAG (Retrieval-Augmented Generation) Tema 8: LangGraph Studio Tema 9: LangSmith \ud83c\udfc1 Resultado Final del Curso Crear\u00e1s chatbots avanzados y flujos con intervenci\u00f3n humana. Ser\u00e1s capaz de implementar flujos de trabajo en paralelo y sistemas din\u00e1micos. Aprender\u00e1s a manejar herramientas gr\u00e1ficas para monitorizar tus flujos de LangGraph. \u2699\ufe0f Tecnolog\u00edas Utilizadas LangGraph 0.3.x Python 3.10+ LangGraph Studio LangSmith FastAPI y websockets para streaming","title":"\u2699\ufe0f Curso 2: Aplicaciones Avanzadas"},{"location":"curso2/#curso-2-aplicaciones-avanzadas","text":"","title":"\u2699\ufe0f Curso 2: Aplicaciones Avanzadas"},{"location":"curso2/#bienvenida-al-curso-2","text":"Bienvenido al segundo curso de nuestra serie sobre LangGraph. \ud83c\udf10 En este m\u00f3dulo, llevaremos tus habilidades al siguiente nivel al explorar aplicaciones avanzadas como chatbots, paralelismo, subgraf\u00edas y mucho m\u00e1s. Este curso se centra en maximizar la eficiencia y escalabilidad de tus flujos de trabajo.","title":"\ud83d\udc4b Bienvenida al Curso 2"},{"location":"curso2/#que-aprenderemos","text":"Desarrollar chatbots con capacidad de resumen y generaci\u00f3n de respuestas. Implementar Human in the Loop para correcciones manuales. Integrar streaming y puntos de interrupci\u00f3n din\u00e1micos. Crear flujos paralelos y subgraf\u00edas interconectadas. Usar LangGraph Studio y LangSmith para monitoreo y pruebas.","title":"\ud83c\udfaf \u00bfQu\u00e9 Aprenderemos?"},{"location":"curso2/#objetivo-del-curso","text":"El objetivo es ense\u00f1arte c\u00f3mo crear soluciones complejas con flujos paralelos, implementar intervenci\u00f3n humana en tiempo real y desarrollar chatbots de alto rendimiento integrando t\u00e9cnicas avanzadas.","title":"\ud83c\udfc6 Objetivo del Curso"},{"location":"curso2/#temario","text":"Tema 1: Chatbot Summarizing Tema 2: Human in the Loop Tema 3: Streaming y Breakpoints Tema 4: Paralelismo Tema 5: Subgraf\u00edas (Sub-graphs) Tema 6: Mapas Tema 7: RAG (Retrieval-Augmented Generation) Tema 8: LangGraph Studio Tema 9: LangSmith","title":"\ud83d\udccb Temario"},{"location":"curso2/#resultado-final-del-curso","text":"Crear\u00e1s chatbots avanzados y flujos con intervenci\u00f3n humana. Ser\u00e1s capaz de implementar flujos de trabajo en paralelo y sistemas din\u00e1micos. Aprender\u00e1s a manejar herramientas gr\u00e1ficas para monitorizar tus flujos de LangGraph.","title":"\ud83c\udfc1 Resultado Final del Curso"},{"location":"curso2/#tecnologias-utilizadas","text":"LangGraph 0.3.x Python 3.10+ LangGraph Studio LangSmith FastAPI y websockets para streaming","title":"\u2699\ufe0f Tecnolog\u00edas Utilizadas"},{"location":"curso2/tema1_chatbot/","text":"","title":"Tema 1: Chatbot Summarizing"},{"location":"curso2/tema2_human_loop/","text":"","title":"Tema 2: Human in the Loop"},{"location":"curso2/tema3_streaming/","text":"","title":"Tema 3: Streaming y Breakpoints"},{"location":"curso2/tema4_parallelism/","text":"","title":"Tema 4: Paralelismo"},{"location":"curso2/tema5_sub_graphs/","text":"","title":"Tema 5: Subgraf\u00edas (Sub-graphs)"},{"location":"curso2/tema6_maps/","text":"","title":"Tema 6: Mapas"},{"location":"curso2/tema7_rag/","text":"","title":"Tema 7: RAG (Retrieval-Augmented Generation)"},{"location":"curso2/tema8_langgraph_studio/","text":"","title":"Tema 8: LangGraph Studio"},{"location":"curso2/tema9_langsmith/","text":"","title":"Tema 9: LangSmith"},{"location":"curso3/","text":"\ud83d\ude80 Curso 3: Despliegue y Proyecto Final \ud83d\udc4b Bienvenida al Curso 3 \u00a1Ya est\u00e1s en la recta final! \ud83c\udfd7\ufe0f En este curso, nos enfocaremos en llevar tus flujos de trabajo a producci\u00f3n. Aprender\u00e1s c\u00f3mo desplegar aplicaciones LangGraph, crear memorias extensas y desarrollar APIs REST para interactuar con tus flujos de manera externa. \ud83c\udfaf \u00bfQu\u00e9 Aprenderemos? Implementar flujos de memoria a largo plazo . Desplegar LangGraph en servidores locales y en la nube . Crear APIs REST para conectar tus flujos con otras aplicaciones. Usar la CLI de LangGraph para facilitar despliegues y pruebas. \ud83c\udfc6 Objetivo del Curso El objetivo es que logres desarrollar y desplegar flujos completos listos para producci\u00f3n. Aprender\u00e1s a trabajar con herramientas que facilitan la puesta en marcha y el mantenimiento de tus aplicaciones de LangGraph. \ud83d\udccb Temario Tema 1: Long Memory Tema 2: LangGraph Store Tema 3: Memory Schema Tema 4: Despliegue de LangGraph Tema 5: LangGraph CLI Tema 6: LangGraph Server Tema 7: API REST/GraphQL \ud83c\udfc1 Resultado Final del Curso Desplegar\u00e1s flujos completos de LangGraph. Crear\u00e1s APIs REST que interact\u00faan con tus flujos. Podr\u00e1s implementar sistemas completos y listos para producci\u00f3n. \u2699\ufe0f Tecnolog\u00edas Utilizadas LangGraph 0.3.x Docker Python FastAPI GraphQL PostgreSQL","title":"\ud83d\ude80 Curso 3: Despliegue y Proyecto Final"},{"location":"curso3/#curso-3-despliegue-y-proyecto-final","text":"","title":"\ud83d\ude80 Curso 3: Despliegue y Proyecto Final"},{"location":"curso3/#bienvenida-al-curso-3","text":"\u00a1Ya est\u00e1s en la recta final! \ud83c\udfd7\ufe0f En este curso, nos enfocaremos en llevar tus flujos de trabajo a producci\u00f3n. Aprender\u00e1s c\u00f3mo desplegar aplicaciones LangGraph, crear memorias extensas y desarrollar APIs REST para interactuar con tus flujos de manera externa.","title":"\ud83d\udc4b Bienvenida al Curso 3"},{"location":"curso3/#que-aprenderemos","text":"Implementar flujos de memoria a largo plazo . Desplegar LangGraph en servidores locales y en la nube . Crear APIs REST para conectar tus flujos con otras aplicaciones. Usar la CLI de LangGraph para facilitar despliegues y pruebas.","title":"\ud83c\udfaf \u00bfQu\u00e9 Aprenderemos?"},{"location":"curso3/#objetivo-del-curso","text":"El objetivo es que logres desarrollar y desplegar flujos completos listos para producci\u00f3n. Aprender\u00e1s a trabajar con herramientas que facilitan la puesta en marcha y el mantenimiento de tus aplicaciones de LangGraph.","title":"\ud83c\udfc6 Objetivo del Curso"},{"location":"curso3/#temario","text":"Tema 1: Long Memory Tema 2: LangGraph Store Tema 3: Memory Schema Tema 4: Despliegue de LangGraph Tema 5: LangGraph CLI Tema 6: LangGraph Server Tema 7: API REST/GraphQL","title":"\ud83d\udccb Temario"},{"location":"curso3/#resultado-final-del-curso","text":"Desplegar\u00e1s flujos completos de LangGraph. Crear\u00e1s APIs REST que interact\u00faan con tus flujos. Podr\u00e1s implementar sistemas completos y listos para producci\u00f3n.","title":"\ud83c\udfc1 Resultado Final del Curso"},{"location":"curso3/#tecnologias-utilizadas","text":"LangGraph 0.3.x Docker Python FastAPI GraphQL PostgreSQL","title":"\u2699\ufe0f Tecnolog\u00edas Utilizadas"},{"location":"curso3/tema1_long_memory/","text":"","title":"Tema 1: Long Memory"},{"location":"curso3/tema2_langgraph_store/","text":"","title":"Tema 2: LangGraph Store"},{"location":"curso3/tema3_memory_schema/","text":"Short-term memory, or thread-scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short-term memory as a part of your agent's state. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step. Long-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores (reference doc) to let you save and recall long-term memories. https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory https://langchain-ai.github.io/langgraph/how-tos/persistence/","title":"Tema 3: Memory Schema"},{"location":"curso3/tema4_deployments/","text":"","title":"Tema 4: Despliegue de LangGraph"},{"location":"curso3/tema5_langgraph_cli/","text":"","title":"Tema 5: LangGraph CLI"},{"location":"curso3/tema6_langgraph_server/","text":"","title":"Tema 6: LangGraph Server"},{"location":"curso3/tema7_api_rest/","text":"","title":"Tema 7: API REST/GraphQL"},{"location":"curso4/","text":"","title":"Introducci\u00f3n"}]}