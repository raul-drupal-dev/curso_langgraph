# ğŸ§  CÃ¡psula 4: LangMem SDK â€” Memoria a Largo Plazo para Agentes

## ğŸ¯ Â¿QuÃ© es LangMem?

**LangMem** es un SDK que ayuda a tus agentes a aprender y adaptarse con el tiempo mediante **memoria a largo plazo**. Proporciona herramientas para:

- ğŸ§© Extraer informaciÃ³n importante de las conversaciones.
- âœï¸ Actualizar el comportamiento del agente mediante mejoras del prompt (memoria procedimental).
- ğŸ—‚ï¸ Mantener recuerdos persistentes (hechos, preferencias, eventos) entre sesiones.

Funciona con cualquier sistema de almacenamiento y se integra de forma nativa con la **capa de memoria de LangGraph (BaseStore)**. Esto permite que tus agentes sean mÃ¡s personales, consistentes y â€œaprendanâ€ de sus interacciones.

!!! info "Lecturas clave" 
    - Blog de lanzamiento del SDK: <https://blog.langchain.dev/langmem-sdk-launch/>{target="\_blank"} 
    - DocumentaciÃ³n (Key features + Quickstarts): <https://langchain-ai.github.io/langmem/>{target="\_blank"}
    - API de herramientas de memoria: <https://langchain-ai.github.io/langmem/reference/tools/>{target="\_blank"}

### ğŸ§­ RelaciÃ³n con los tipos de memoria del curso

En el curso ya vimos la diferencia entre:

- ğŸŸ¡ **Memoria a corto plazo** (checkpointing dentro del hilo)
- ğŸ”µ **Memoria a largo plazo** (persistente entre sesiones)

AdemÃ¡s, distinguimos 3 â€œsaboresâ€ de memoria a largo plazo:

- ğŸ§  **SemÃ¡ntica (facts)**: datos y preferencias del usuario, conocimiento atemporal.
- ğŸ§ª **EpisÃ³dica (experiencias)**: ejemplos o resÃºmenes de interacciones pasadas.
- âš™ï¸ **Procedimental (comportamiento)**: reglas y pautas del agente que evolucionan.

LangMem ofrece herramientas listas para implementar estas memorias sobre la capa de almacenamiento de LangGraph, y se complementa con la memoria de corto plazo del grafo.

![Memoria a largo plazo en LangGraph](../assets/img/curso3/tema1/image.png)

> Como vimos en â€œLong-Term Memoryâ€, LangMem encaja como la capa que persiste recuerdos entre sesiones, mientras que `MemorySaver` mantiene el historial dentro de un hilo activo.

---

## ğŸ§  Â¿Para quÃ© podemos usarlo? (Casos de uso)

- ğŸ‘¤ PersonalizaciÃ³n: recordar preferencias del usuario (p. ej., â€œprefiero modo oscuroâ€).
- ğŸ—ƒï¸ Perfiles y contexto: construir y mantener fichas de usuario o equipo.
- ğŸ§­ RecuperaciÃ³n contextual: buscar recuerdos relevantes para responder mejor.
- ğŸ” Mejora continua: ajustar instrucciones del agente segÃºn su rendimiento.
- ğŸ¤ ColaboraciÃ³n: compartir memorias entre agentes o por equipos (namespaces).

---

## ğŸ“¦ InstalaciÃ³n

```bash
pip install -U langmem
```

Configura la clave del proveedor de LLM (ejemplo con Anthropic):

```bash
export ANTHROPIC_API_KEY="sk-..."
```

!!! tip "Almacenamiento" 
    - Desarrollo: `InMemoryStore` (en memoria, se pierde al reiniciar). 
    - ProducciÃ³n: almacenes persistentes como `AsyncPostgresStore` u otros compatibles con `BaseStore`.

---

## ğŸ•¹ï¸ Â¿CÃ³mo se usa? (Paso a paso)

A continuaciÃ³n verÃ¡s cÃ³mo aÃ±adir memoria persistente a un agente de LangGraph usando las herramientas de LangMem. La idea clave es que el agente pueda:

1. crear/actualizar/borrar recuerdos cuando haga falta, y
2. buscar recuerdos relevantes durante el chat.

### 1) Preparar el Store y Namespaces

Los recuerdos se guardan en un `BaseStore` y se organizan por `namespace`. Es habitual incluir un identificador de usuario para evitar mezcla de memorias.

```python
from langgraph.store.memory import InMemoryStore

store = InMemoryStore(
    index={
        "dims": 1536,
        "embed": "openai:text-embedding-3-small",
    }
)

# El namespace final puede formarse con valores configurables a runtime.
# Ej.: ("memories", "<user-id>")
```

!!! note "Namespaces dinÃ¡micos"
    Puedes usar placeholders como `{langgraph_user_id}` y rellenarlos con `config={"configurable": {"langgraph_user_id": "user-123"}}`.

### 2) Herramientas de memoria (LangMem)

LangMem provee dos herramientas principales:

- ğŸ› ï¸ `create_manage_memory_tool(...)`: crea/actualiza/borra recuerdos.
- ğŸ” `create_search_memory_tool(...)`: busca recuerdos por similitud o filtros.

```python
from langmem import create_manage_memory_tool, create_search_memory_tool

manage_memory = create_manage_memory_tool(
    namespace=("memories", "{langgraph_user_id}"),
)

search_memory = create_search_memory_tool(
    namespace=("memories", "{langgraph_user_id}"),
)
```

!!! info "Contrato de `manage_memory`"
    - `content: str | None` â€” contenido del recuerdo (crear/actualizar) 
    - `id: str | None` â€” id de un recuerdo existente (actualizar/borrar) 
    - `action: Literal["create","update","delete"]` â€” acciÃ³n a realizar

### 3) Crear un agente con memoria

Puedes incorporar estas herramientas en un agente preconstruido de LangGraph (p. ej. ReAct) y pasarle el `store`:

```python
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(
    model="anthropic:claude-3-5-sonnet-latest",
    tools=[manage_memory, search_memory],
    store=store,
)
```

### 4) Guardar y recuperar recuerdos en el â€œhot pathâ€

El propio LLM decide cuÃ¡ndo llamar a las herramientas (no necesitas comandos especiales). Si el usuario dice algo relevante, el agente puede invocar `manage_memory` para guardarlo; y si necesita contexto pasado, `search_memory` para encontrarlo.

```python
# El agente decide guardar una preferencia
agent.invoke({
    "messages": [{"role": "user", "content": "RecuÃ©rdame en el futuro que prefiero el modo oscuro."}]
}, config={"configurable": {"langgraph_user_id": "user-123"}})

# MÃ¡s tarde, el agente puede recuperar ese dato
resp = agent.invoke({
    "messages": [{"role": "user", "content": "Â¿CuÃ¡les son mis preferencias de iluminaciÃ³n?"}]
}, config={"configurable": {"langgraph_user_id": "user-123"}})
print(resp["messages"][-1].content)
# â†’ "Me comentaste que prefieres el modo oscuro."
```

!!! tip "Memoria procedimental"
    LangMem tambiÃ©n incluye utilidades para **optimizar prompts** (p. ej., `metaprompt`, `gradient`). Sirven para ajustar reglas del agente a partir de conversaciones exitosas o fallidas.

### 5) Background memory manager (opcional)

AdemÃ¡s del uso â€œen calienteâ€, puedes correr un **gestor en background** que procese conversaciones, consolide recuerdos y mantenga consistencia sin bloquear la interacciÃ³n.

- GuÃ­a â€œBackground Quickstartâ€: <https://langchain-ai.github.io/langmem/background_quickstart/>{target="\_blank"}

---

## âœ… Ventajas

- ğŸ§© API simple y portable; funciona con cualquier `BaseStore`.
- ğŸ”Œ IntegraciÃ³n nativa con la memoria persistente de LangGraph.
- ğŸ¤– Agentes mÃ¡s **personalizados** y **consistentes** entre sesiones.
- ğŸ” BÃºsqueda semÃ¡ntica de recuerdos para mejores respuestas.
- â™»ï¸ Mejora continua del comportamiento mediante optimizaciÃ³n del prompt.

---

## ğŸ§ª Lo aprendido

- QuÃ© es LangMem y cÃ³mo se relaciona con los tipos de memoria del curso.
- CÃ³mo instalarlo y configurarlo con un `BaseStore` y namespaces.
- CÃ³mo usar sus herramientas (`manage_memory` y `search_memory`) en el â€œhot pathâ€.
- QuÃ© opciones hay para mantenimiento en background y optimizaciÃ³n del prompt.

---

## ğŸ” Recursos

- ğŸ“° Blog (lanzamiento): <https://blog.langchain.dev/langmem-sdk-launch/>{target="\_blank"}
- ğŸ“˜ Docs (inicio): <https://langchain-ai.github.io/langmem/>{target="\_blank"}
- ğŸ§° Memory Tools API: <https://langchain-ai.github.io/langmem/reference/tools/>{target="\_blank"}
- âš¡ Hot Path Quickstart: <https://langchain-ai.github.io/langmem/hot_path_quickstart/>{target="\_blank"}
- ğŸ§  Background Quickstart: <https://langchain-ai.github.io/langmem/background_quickstart/>{target="\_blank"}
- ğŸ—ï¸ BaseStore (LangGraph): <https://langchain-ai.github.io/langgraph/reference/store/>{target="\_blank"}
- ğŸ“š Conceptos de Memoria (LangGraph): <https://langchain-ai.github.io/langgraph/concepts/memory/>{target="\_blank"}
