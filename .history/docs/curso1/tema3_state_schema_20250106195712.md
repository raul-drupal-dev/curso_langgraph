# ğŸ§© Tema 3: State Schema y Memoria  

## ğŸš€ Â¿QuÃ© es el State Schema y la Memoria en LangGraph?  

El **State Schema** es el corazÃ³n de LangGraph, ya que define y gestiona el estado del grafo durante su ejecuciÃ³n.  
El **estado** es la informaciÃ³n que **se transfiere, modifica y actualiza** a medida que el flujo avanza por diferentes nodos.  

Piensa en el estado como una mochila ğŸ§³ que lleva datos entre los nodos. En cada nodo, puedes:  
- **AÃ±adir** nuevos datos.  
- **Modificar** valores existentes.  
- **Eliminar** informaciÃ³n que ya no necesitas.  

### ğŸ§  Â¿Y la Memoria?  
La memoria es la capacidad que tiene el grafo para **recordar informaciÃ³n** a lo largo de mÃºltiples invocaciones. Es especialmente Ãºtil cuando creamos chatbots o flujos conversacionales donde el contexto es crucial.  

- **Sin memoria:** Cada vez que invocamos el grafo, comienza desde cero.  
- **Con memoria:** El grafo guarda un historial de mensajes o datos, permitiendo respuestas basadas en todo el contexto anterior.  

**Â¿Por quÃ© es importante?**  
- **Persistencia de datos.**  
- **Toma de decisiones basadas en el contexto actual.**  
- **Mayor precisiÃ³n en interacciones prolongadas.**  

---

## âš™ï¸ Â¿CÃ³mo Funciona el State?  

Para entender cÃ³mo se define el estado en LangGraph, crearemos un `State` personalizado.  
Este enfoque facilita la comprensiÃ³n antes de utilizar estructuras predefinidas como `MessagesState`.  

### ğŸ“‹ CreaciÃ³n de un State Propio  
```python hl_lines="3 4"
from typing_extensions import TypedDict

class CustomState(MessagesState):
    messages: list[AIMessage | HumanMessage | SystemMessage] = []
```

- **ExplicaciÃ³n:**  
  - `TypedDict` nos permite definir un diccionario con tipos estrictos, lo que asegura que el estado tenga una estructura clara y esperada.  
  - El `graph_state` es un campo donde almacenaremos mensajes o datos que pasarÃ¡n de un nodo a otro.  

Si prefieres simplificar, puedes utilizar el estado predefinido `MessagesState` de LangGraph, diseÃ±ado especÃ­ficamente para flujos conversacionales.  
ğŸ‘‰ [DocumentaciÃ³n de MessagesState](https://python.langchain.com/docs/modules/langgraph#messagesstate)  

---

## ğŸ§© Nodos que Utilizan el Estado  

A continuaciÃ³n, crearemos dos nodos que utilizan el estado:  
1. **Nodo de entrada del usuario:** Agrega el mensaje del usuario al estado.  
2. **Nodo de respuesta de IA:** El modelo de OpenAI (`gpt-4o-mini`) genera una respuesta basada en el historial.  

```python  
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

llm = ChatOpenAI(model="gpt-4o-mini")

def user_input_node(state: CustomState):
    print("--- Usuario dice ---")
    return {"messages": state['messages']}

def ai_response_node(state: CustomState):
    print("--- IA responde ---")
    response = llm.invoke(state['messages'])
    return {"messages": state['messages'] + [AIMessage(content=response.content)]}
```

- **`user_input_node:`** Toma el mensaje del usuario y lo guarda en el estado.  
- **`ai_response_node:`** Usa el estado actual (historial) para generar una respuesta de IA.  

---

## ğŸ§  Memoria: Â¿CÃ³mo Funciona?  

LangGraph ofrece varios tipos de memoria:  

1. **Memoria de Estado (State Memory):**  
    - El estado se transfiere de nodo a nodo, reteniendo informaciÃ³n solo durante una invocaciÃ³n.  
   
2. **Memoria de Corto Alcance (MemorySaver):**  
    - Guarda datos durante mÃºltiples invocaciones, pero **no persiste despuÃ©s de cerrar el programa.**  
    - Almacena la informaciÃ³n en memoria volÃ¡til (RAM).  
    - Ideal para flujos temporales que necesitan recordar el contexto durante la sesiÃ³n actual.  
   ğŸ‘‰ [DocumentaciÃ³n de MemorySaver](https://python.langchain.com/docs/modules/langgraph#memorysaver)  

3. **Memoria Persistente (Postgres u otros):**  
    - Permite almacenar el historial en bases de datos externas (ej: PostgreSQL).  
    - **Se verÃ¡ en temas mÃ¡s avanzados.**  

4. **Memoria Transversal (Cross-Session Memory):**  
    - Conserva datos a lo largo de mÃºltiples sesiones y usuarios.  
    - **Se estudiarÃ¡ en profundidad en futuros mÃ³dulos.**  

---

## ğŸ—ï¸ AÃ±adiendo Memoria al Grafo  

Ahora implementaremos el `MemorySaver` para agregar memoria de corto alcance a nuestro grafo.  

### ğŸ“‹ Grafo sin Memoria  

En el siguiente ejemplo, vamos a ver un grafo bÃ¡sico, como ya hemos visto hasta ahora, solamente para poder ver la diferencia para cuando le apliquemos nuestra memoria.

```python  
from langgraph.graph import StateGraph, START, END

builder = StateGraph(State)
builder.add_node("user_input", user_input_node)
builder.add_node("ai_response", ai_response_node)

builder.add_edge(START, "user_input")
builder.add_edge("user_input", "ai_response")
builder.add_edge("ai_response", END)

graph_no_memory = builder.compile()
```

### ğŸ“‹ Grafo con Memoria  

Ahora, agregaremos una memoria temporal

```python   hl_lines="4 14"
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

builder_mem = StateGraph(State)
builder_mem.add_node("user_input", user_input_node)
builder_mem.add_node("ai_response", ai_response_node)

builder_mem.add_edge(START, "user_input")
builder_mem.add_edge("user_input", "ai_response")
builder_mem.add_edge("ai_response", END)

graph_memory = builder_mem.compile(checkpointer=memory)
```

---

## ğŸ“ˆ VisualizaciÃ³n del Grafo  

Para observar cÃ³mo se estructura nuestro grafo, generamos una visualizaciÃ³n:  
```python  
from IPython.display import Image, display
display(Image(graph_no_memory.get_graph().draw_mermaid_png()))
display(Image(graph_memory.get_graph().draw_mermaid_png()))
```  

---

## ğŸš€ Invocando el Grafo y Comparando Resultados  

### ğŸ“‹ Sin Memoria  
```python  
graph_no_memory.invoke({"messages": [HumanMessage(content="Hola, me llamo Raul.")]})
graph_no_memory.invoke({"messages": [HumanMessage(content="Â¿CÃ³mo me llamo?")]})

```

```python 
--- Usuario dice ---
Hola, me llamo Raul.
--- IA responde ---
Hola Raul, Â¿en quÃ© puedo ayudarte?
--- Usuario dice ---
Â¿CÃ³mo me llamo?
--- IA responde ---
No tengo esa informaciÃ³n.
```

---

### ğŸ“‹ Con Memoria  
```python  
graph_memory.invoke({"messages": [HumanMessage(content="Hola, me llamo Raul.")]})
graph_memory.invoke({"messages": [HumanMessage(content="Â¿CÃ³mo me llamo?")]})
```

```python  
--- Usuario dice ---
Hola, me llamo Raul.
--- IA responde ---
Hola Raul, Â¿en quÃ© puedo ayudarte?
--- Usuario dice ---
Â¿CÃ³mo me llamo?
--- IA responde ---
Te llamas Raul.
```

---

## ğŸ§‘â€ğŸ« Â¿QuÃ© Hemos Aprendido?  

- **State Schema:** Es la estructura que define quÃ© datos se transportan y modifican durante el flujo del grafo.  
- **Memoria de Estado (State):** Solo persiste durante la ejecuciÃ³n de una invocaciÃ³n.  
- **MemorySaver:** Proporciona memoria de corto alcance para retener datos durante mÃºltiples invocaciones.  
- **Diferencias Clave:** Sin memoria, cada invocaciÃ³n es independiente. Con memoria, el grafo recuerda datos anteriores.  

---

## ğŸŒ Â¿QuÃ© es lo Siguiente?  

En el siguiente tema exploraremos **Chains y Flujos de Trabajo**, donde aprenderemos a encadenar nodos y construir pipelines complejos.  
TambiÃ©n abordaremos el tema de **Tools (Herramientas)**, pero lo veremos **despuÃ©s de Chains**, ya que comprender primero el flujo de trabajo harÃ¡ que la integraciÃ³n de herramientas sea mÃ¡s sencilla y prÃ¡ctica.  
