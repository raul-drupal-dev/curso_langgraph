# âœ‚ï¸ Tema 8: Trim y Filter Messages â€“ OptimizaciÃ³n del Historial de Mensajes  

## ğŸš€ Â¿QuÃ© es el Trimming y Filtering de Mensajes?  

A medida que un grafo interactÃºa con los usuarios, el historial de mensajes puede **crecer considerablemente**, lo que puede:  
- **Aumentar el costo de procesamiento** para los modelos LLM.  
- **Reducir la eficiencia** del grafo en conversaciones largas.  
- **Diluir el contexto**, incluyendo mensajes irrelevantes.  

Para solucionar esto, LangGraph ofrece herramientas que permiten **gestionar y optimizar el historial de mensajes**:  

1. **`RemoveMessages`** â€“ Elimina mensajes especÃ­ficos.  
2. **`trim_messages`** â€“ Recorta el historial manteniendo solo los mensajes mÃ¡s recientes.  
3. **`summarize_conversation`** â€“ Resume la conversaciÃ³n para reducir la longitud del historial, manteniendo el contexto.  

---

## ğŸ§  Â¿Por quÃ© es Importante?  

- **OptimizaciÃ³n del Rendimiento:** Reduce la cantidad de datos enviados al LLM.  
- **Mejora de la PrecisiÃ³n:** Mantiene el contexto relevante, eliminando informaciÃ³n redundante.  
- **Ahorro de Costos:** Menos tokens procesados significa **menos consumo de recursos.**  

---

## âš™ï¸ Â¿CÃ³mo Funciona el Trimming y Filtering?  

LangGraph ofrece diferentes enfoques segÃºn el escenario:  
- **Eliminar mensajes irrelevantes o antiguos.**  
- **Recortar automÃ¡ticamente despuÃ©s de alcanzar un lÃ­mite.**  
- **Resumir el historial para mantener el contexto clave.**  

---

## ğŸ“‹ Ejemplo PrÃ¡ctico: Chatbot con GestiÃ³n del Historial de Mensajes  

Vamos a crear un chatbot que interactÃºa con el usuario, pero **gestiona el historial** para mantener solo los mensajes relevantes y no saturar el flujo del grafo.  

---

### ğŸ› ï¸ OpciÃ³n 1: Eliminar Mensajes EspecÃ­ficos con `RemoveMessages`  

Permite eliminar ciertos mensajes del historial, ideal para **eliminar mensajes duplicados o irrelevantes.**  

[codigo1]  
```python
from langgraph.graph.message import RemoveMessages
from langchain_core.messages import AIMessage, HumanMessage

# Estado con mensajes acumulados
state = {
    "messages": [
        HumanMessage(content="Hola, Â¿puedes ayudarme?"),
        AIMessage(content="Claro, Â¿en quÃ© puedo ayudarte?"),
        HumanMessage(content="Olvida lo anterior."),
        HumanMessage(content="Necesito hacer un pedido.")
    ]
}

# Eliminar el segundo mensaje
state = RemoveMessages([1]).invoke(state)

print(state)
```

---

### ğŸ› ï¸ OpciÃ³n 2: Recorte de Mensajes con `trim_messages`  

Recorta el historial de mensajes **manteniendo solo los Ãºltimos N mensajes.**  
Esto es Ãºtil para **evitar que el historial crezca sin control.**  

[codigo2]  
```python
from langgraph.graph.message import trim_messages

# Estado con muchos mensajes
state = {
    "messages": [
        HumanMessage(content="Hola"),
        AIMessage(content="Hola, Â¿cÃ³mo estÃ¡s?"),
        HumanMessage(content="Quiero informaciÃ³n."),
        AIMessage(content="Claro, dime quÃ© necesitas."),
        HumanMessage(content="Dime el precio del producto A."),
        AIMessage(content="El precio es de 100â‚¬."),
    ]
}

# Mantener solo los Ãºltimos 3 mensajes
state = trim_messages(state, n=3)

print(state)
```

---

### ğŸ› ï¸ OpciÃ³n 3: Resumir ConversaciÃ³n con `summarize_conversation`  

En lugar de eliminar mensajes, **genera un resumen de la conversaciÃ³n** manteniendo el contexto en menos palabras.  
Perfecto para **mantener el contexto en conversaciones extensas.**  

[codigo3]  
```python
from langgraph.graph.message import summarize_conversation

# Estado con mensajes acumulados
state = {
    "messages": [
        HumanMessage(content="Hola, necesito informaciÃ³n sobre varios productos."),
        AIMessage(content="Claro, puedo ayudarte con eso."),
        HumanMessage(content="Perfecto. Empecemos con el producto A."),
        AIMessage(content="El producto A cuesta 100â‚¬ y estÃ¡ disponible."),
        HumanMessage(content="Â¿Y quÃ© pasa con el producto B?")
    ]
}

# Resumir la conversaciÃ³n
state = summarize_conversation(state)

print(state)
```

---

## ğŸ—ï¸ ConstrucciÃ³n del Grafo con Trim y Filter Messages  

Integramos estas herramientas en el flujo de trabajo del chatbot para optimizar el historial de mensajes en diferentes etapas.  
[codigo4]  
```python
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import RemoveMessages, trim_messages

def assistant(state: MessagesState):
    # Simula la respuesta de un asistente
    state["messages"].append(AIMessage(content="Tu pedido ha sido procesado."))
    return state

def filter_messages(state: MessagesState):
    # Elimina mensajes irrelevantes
    state = RemoveMessages([0]).invoke(state)
    state = trim_messages(state, n=5)
    return state

# ConstrucciÃ³n del grafo
builder = StateGraph(MessagesState)
builder.add_node("assistant", assistant)
builder.add_node("filter", filter_messages)

builder.add_edge(START, "assistant")
builder.add_edge("assistant", "filter")
builder.add_edge("filter", END)

graph = builder.compile()


```

---

## ğŸš€ Invocando el Grafo y Resultados  

Probamos el grafo con mensajes largos y observamos cÃ³mo se filtran, recortan o resumen automÃ¡ticamente.  
[codigo5]  
```python
# Invocamos el grafo
result = graph.invoke({"messages": [HumanMessage(content="Hola, tengo una duda.")]} )
print(result)
```

[resultado1]  
```python
{'messages': [
    AIMessage(content="Tu pedido ha sido procesado.")
]}
```

---

## ğŸ§‘â€ğŸ« Â¿QuÃ© Hemos Aprendido?  

- **RemoveMessages:** Elimina mensajes especÃ­ficos del historial.  
- **trim_messages:** Recorta el historial a los Ãºltimos mensajes.  
- **summarize_conversation:** Genera resÃºmenes que conservan el contexto sin saturar el historial.  

---

## ğŸŒ Â¿QuÃ© es lo Siguiente?  

Con esto finalizamos el **Curso 1: Fundamentos de LangGraph.**  
En el siguiente curso, exploraremos temas mÃ¡s avanzados como **Memoria a Largo Plazo, SubgrafÃ­as y Despliegues.**  
