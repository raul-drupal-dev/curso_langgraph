# üß† Tema 1: Long-Term Memory ‚Äì Memoria a Largo Plazo en LangGraph  

## üåü ¬øQu√© es la Memoria a Largo Plazo en LangGraph?  

En el **Curso 1**, exploramos c√≥mo LangGraph maneja la **memoria de estado**, que nos permite almacenar informaci√≥n dentro del estado del grafo mientras se ejecuta una sesi√≥n. Sin embargo, esta memoria es **temporal** y se pierde una vez que el flujo del grafo finaliza.  

Tambi√©n aprendimos sobre la **memoria de corto alcance (Short-Term Memory)**, que nos permit√≠a **guardar el historial de un chat dentro de una misma sesi√≥n**, proporcionando mayor contexto y fluidez a la conversaci√≥n sin necesidad de almacenamiento externo.  

Ahora, en el **Curso 3**, introducimos un concepto a√∫n m√°s avanzado: **Long-Term Memory**, una memoria **persistente** que permite **mantener datos entre m√∫ltiples ejecuciones**, haciendo posible que el sistema recuerde informaci√≥n pasada y la reutilice en futuras interacciones.  


üîπ **¬øQu√© nos permite hacer la memoria a largo plazo?**  
‚úÖ **Almacenar contexto de conversaciones previas** para mantener continuidad en interacciones futuras.  
‚úÖ **Persistir informaci√≥n relevante en bases de datos** o sistemas externos.  
‚úÖ **Optimizar respuestas en chatbots** al recordar detalles importantes a lo largo del tiempo.  

Con esta memoria, nuestros grafos pueden aprender de interacciones pasadas y mejorar su desempe√±o con el tiempo. üöÄ  

---

## üîÑ Comparaci√≥n: Memoria B√°sica vs. Memoria a Corto y Largo Plazo  

| **Caracter√≠stica**          | **Memoria B√°sica** üü¢ | **Memoria a Corto Plazo** üü° | **Memoria a Largo Plazo** üîµ |
|-----------------------------|-----------------------|------------------------------|------------------------------|
| **Alcance**                | Solo durante la ejecuci√≥n del grafo | Se mantiene dentro de una sesi√≥n activa | Se mantiene entre sesiones |
| **Persistencia**           | Se borra al finalizar el flujo | Se almacena temporalmente en la memoria del grafo | Se guarda en almacenamiento externo |
| **Ejemplo de Uso**         | Referencias dentro de una conversaci√≥n en curso | Mantener el historial de mensajes en una sesi√≥n de chat | Recordar interacciones a lo largo del tiempo |
| **Implementaci√≥n**         | Se gestiona dentro del estado (`State`) | Se almacena en memoria (`MemorySaver`) dentro de la sesi√≥n | Usa almacenamiento externo como bases de datos (`InMemoryStore`) |
| **Casos de Uso**           | Flujos de conversaci√≥n dentro de un solo request | Chats que necesitan contexto en una misma sesi√≥n | Sistemas con memoria continua (chatbots avanzados, asistentes virtuales, etc.) |

???+ Note "Nota"

    - La **memoria b√°sica** es √∫til para tareas donde no necesitamos persistencia entre sesiones.  
    - La **memoria a corto plazo** nos permite recordar datos dentro de una misma sesi√≥n, pero se pierde al cerrarla.  
    - la **memoria a largo plazo** es ideal cuando queremos que el sistema recuerde informaci√≥n incluso despu√©s de varias sesiones, permitiendo experiencias m√°s personalizadas y contextuales.  


---

## üõ†Ô∏è ¬øC√≥mo Funciona la Memoria a Largo Plazo?  

LangGraph nos permite almacenar memoria de manera persistente utilizando diferentes opciones:  

‚úÖ **Bases de datos externas** como PostgreSQL o MongoDB.  
‚úÖ **Sistemas de almacenamiento en la nube** como Redis o vectores sem√°nticos.  
‚úÖ **Archivos locales** donde guardamos registros de conversaci√≥n.  

En esta implementaci√≥n, LangGraph guarda los datos en un sistema de almacenamiento que podemos recuperar en futuras ejecuciones del grafo.  

üìå **Ejemplo Pr√°ctico:** Implementaci√≥n de Memoria a Largo Plazo en LangGraph  

```python
from IPython.display import Image, display

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.store.base import BaseStore

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables.config import RunnableConfig

# Instrucci√≥n del chatbot
MODEL_SYSTEM_MESSAGE = """Eres un asistente √∫til con memoria que proporciona informaci√≥n personalizada sobre el usuario. 
Si tienes memoria para este usuario, util√≠zala para personalizar tus respuestas.
Aqu√≠ est√° la memoria (puede estar vac√≠a): {memory}"""

# Crear nueva memoria a partir del historial de chat y cualquier memoria existente
CREATE_MEMORY_INSTRUCTION = """Est√°s recopilando informaci√≥n sobre el usuario para personalizar tus respuestas.

INFORMACI√ìN ACTUAL DEL USUARIO:
{memory}

INSTRUCCIONES:
1. Revisa cuidadosamente el historial de chat a continuaci√≥n.
2. Identifica nueva informaci√≥n sobre el usuario, como:
   - Datos personales (nombre, ubicaci√≥n).
   - Preferencias (gustos, aversiones).
   - Intereses y aficiones.
   - Experiencias pasadas.
   - Objetivos o planes futuros.
3. Fusiona cualquier nueva informaci√≥n con la memoria existente.
4. Formatea la memoria como una lista clara con vi√±etas.
5. Si la nueva informaci√≥n contradice la memoria existente, conserva la versi√≥n m√°s reciente.

Recuerda: Solo incluye informaci√≥n real directamente mencionada por el usuario. No hagas suposiciones ni inferencias.

Basado en el historial de chat a continuaci√≥n, actualiza la informaci√≥n del usuario:"""

def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):

    """Carga la memoria desde el almacenamiento y la usa para personalizar la respuesta del chatbot."""
    
    # Obtiene el ID del usuario desde la configuraci√≥n
    user_id = config["configurable"]["user_id"]

    # Recupera la memoria desde el almacenamiento
    namespace = ("memory", user_id)
    key = "user_memory"
    existing_memory = store.get(namespace, key)

    # Extrae el contenido de la memoria si existe y agrega un prefijo
    if existing_memory:
        # El valor es un diccionario con la clave "memory"
        existing_memory_content = existing_memory.value.get('memory')
    else:
        existing_memory_content = "No se encontr√≥ memoria previa."

    # Formatea la memoria en el mensaje del sistema
    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)
    
    # Responde utilizando la memoria junto con el historial de chat
    response = model.invoke([SystemMessage(content=system_msg)] + state["messages"])

    return {"messages": response}

def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):

    """Reflexiona sobre el historial de chat y guarda la memoria en el almacenamiento."""
    
    # Obtiene el ID del usuario desde la configuraci√≥n
    user_id = config["configurable"]["user_id"]

    # Recupera la memoria existente desde el almacenamiento
    namespace = ("memory", user_id)
    existing_memory = store.get(namespace, "user_memory")
        
    # Extrae el contenido de la memoria
    if existing_memory:
        existing_memory_content = existing_memory.value.get('memory')
    else:
        existing_memory_content = "No se encontr√≥ memoria previa."

    # Formatea la memoria en el mensaje del sistema
    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)
    new_memory = model.invoke([SystemMessage(content=system_msg)] + state['messages'])

    # Sobrescribe la memoria existente en el almacenamiento 
    key = "user_memory"

    # Guarda el valor como un diccionario con la clave "memory"
    store.put(namespace, key, {"memory": new_memory.content})

# Definir el grafo
builder = StateGraph(MessagesState)
builder.add_node("call_model", call_model)
builder.add_node("write_memory", write_memory)
builder.add_edge(START, "call_model")
builder.add_edge("call_model", "write_memory")
builder.add_edge("write_memory", END)

# Almacenamiento para la memoria a largo plazo (entre sesiones)
across_thread_memory = InMemoryStore()

# Checkpointer para la memoria a corto plazo (dentro de una sesi√≥n)
within_thread_memory = MemorySaver()

# Compilar el grafo con memoria a corto y largo plazo
graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)

# Visualizar el grafo
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

![long-term-memory](../assets/img/curso3/tema1/image.png)

Este c√≥digo implementa un sistema de **memoria a largo plazo y memoria a corto plazo** en un grafo de LangGraph.  

- **üü° Memoria a corto plazo (`MemorySaver`)**:  
  Permite recordar informaci√≥n dentro de una √∫nica sesi√≥n o hilo de conversaci√≥n.  

- **üîµ Memoria a largo plazo (`InMemoryStore`)**:  
  Guarda informaci√≥n del usuario entre m√∫ltiples sesiones para personalizar respuestas futuras.  

- **üìå Estructura del Grafo:**  
    - **`call_model`**: Recupera la memoria almacenada y la usa para personalizar las respuestas del chatbot.  
    - **`write_memory`**: Extrae informaci√≥n del historial de mensajes y la almacena para su uso posterior.  

- **üí° Personalizaci√≥n del Chatbot:**  
  El chatbot puede recordar **detalles personales del usuario**, como su **nombre o intereses**, y utilizarlos en futuras conversaciones.    

---

## üöÄ Probando la Memoria a Largo Plazo  

### üìù Iniciamos un chat  

Ejecutamos un chat donde el usuario proporciona su nombre y un gusto personal:  

```python
# Proporcionamos un ID de hilo para la memoria a corto plazo (dentro de la sesi√≥n)
# Proporcionamos un ID de usuario para la memoria a largo plazo (entre sesiones)
config = {"configurable": {"thread_id": "1", "user_id": "1"}}

# Entrada del usuario 
input_messages = [HumanMessage(content="Hola, me llamo Ra√∫l y me gusta salir en bici.")]

# Ejecutamos el grafo y mostramos la respuesta del chatbot
for chunk in graph.stream({"messages": input_messages}, config, stream_mode="values"):
    chunk["messages"][-1].pretty_print()
```

```python title="Resultado"
================================ Human Message =================================

Hola, me llamo Ra√∫l y me gusta salir en bici.
================================== Ai Message ==================================

¬°Hola, Ra√∫l! Es genial que te guste salir en bici. ¬øSueles hacer rutas largas o prefieres paseos m√°s cortos?
```

Podemos ver c√≥mo esta informaci√≥n se almacena en la memoria a corto plazo, permitiendo que el chatbot siga record√°ndola en la conversaci√≥n actual.  

Para verificarlo, podemos inspeccionar el estado del grafo: 

```python
thread = {"configurable": {"thread_id": "1"}}
state = graph.get_state(thread).values
for m in state["messages"]: 
    m.pretty_print()
```

```python title="Resultado"
================================ Human Message =================================

Hola, me llamo Ra√∫l y me gusta salir en bici.
================================== Ai Message ==================================

¬°Hola, Ra√∫l! Es genial que te guste salir en bici. ¬øSueles hacer rutas largas o prefieres paseos m√°s cortos?
```

Adem√°s, tambi√©n podemos revisar la memoria a largo plazo para comprobar qu√© informaci√≥n se ha almacenado:  

```python
user_id = "1"
namespace = ("memory", user_id)
existing_memory = across_thread_memory.get(namespace, "user_memory")
existing_memory.dict()
```

```json title="Resultado" hl_lines="3"
{'namespace': ['memory', '1'],
 'key': 'user_memory',
 'value': {'memory': 'Actualizaci√≥n de la memoria del usuario:\n\n- Nombre: Ra√∫l\n- Gustos: Salir en bici.'},
 'created_at': '2025-02-05T11:39:01.252749+00:00',
 'updated_at': '2025-02-05T11:39:01.252753+00:00'}
```

???+ Note "Nota"

    Como podemos vemos ver, nuestro grafo ha creado ya un peque√±o perfil de nuestro usuario, almazenando tanto su nombre, como sus gustos.

---

### üîÑ Iniciamos un nuevo chat  

Ahora, simularemos una **nueva conversaci√≥n**, donde el usuario no proporciona contexto previo, pero el chatbot deber√≠a recordar informaci√≥n de la memoria a largo plazo:  

```python hl_lines="6"
# Proporcionamos un ID de un nuvo hilo para la memoria a corto plazo (dentro de la sesi√≥n), esto simulara un nuevo chat.
# Proporcionamos un ID de usuario para la memoria a largo plazo (entre sesiones)
config = {"configurable": {"thread_id": "2", "user_id": "1"}}

# Entrada del usuario 
input_messages = [HumanMessage(content="¬øMe puedes recomendar algo que hacer hoy?")]

# Ejecutamos el grafo y mostramos la respuesta del chatbot
for chunk in graph.stream({"messages": input_messages}, config, stream_mode="values"):
    chunk["messages"][-1].pretty_print()
```

```python title="Resultado"
================================ Human Message =================================

¬øMe puedes recomendar algo que hacer hoy?
================================== Ai Message ==================================

¬°Claro, Ra√∫l! Dado que te gusta salir en bici, podr√≠as aprovechar el d√≠a para hacer una ruta en bicicleta. Busca alg√∫n sendero o parque cercano donde puedas disfrutar del paisaje. Si el clima es agradable, tambi√©n podr√≠as considerar llevar algo de comida y hacer un picnic en el camino. ¬øTe gustar√≠a que te ayudara a encontrar lugares espec√≠ficos para montar en bici?
```

???+ Note "Nota"

    A pesar de que el usuario no ha mencionado su nombre ni sus intereses en este nuevo chat, el chatbot **recuerda que se llama Ra√∫l y que le gusta salir en bici**, gracias a la memoria almacenada en sesiones anteriores.  

---

## üîé ¬øCu√°ndo Usar Memoria a Largo Plazo?  

La memoria persistente es clave en aplicaciones como:  

- **Chatbots que deben recordar a los usuarios** y personalizar respuestas seg√∫n interacciones previas.  
- **Asistentes virtuales** que requieren seguimiento de tareas o preferencias del usuario.  
- **Sistemas de soporte t√©cnico** que deben recordar consultas anteriores para brindar un mejor servicio.  

Si nuestro sistema necesita **contexto entre m√∫ltiples sesiones**, entonces la memoria a largo plazo es la mejor opci√≥n.  

---

## ‚ú® Conclusi√≥n  

La memoria a largo plazo en LangGraph nos permite alamacenar informacion relevante de nuestro usuario, podriamos incluso generar un peque√±o perfil personalizado para usarlo en posteriores sesiones.

Uno de los puntos que hace esta tecnica tan interesante, es que podemos jugar con el tipo de informacion que almacenamos de nuestro usuario, haciendo que el resultado de las respuesta sea mas espectacular.

‚úÖ Nos ayuda a **recordar informaci√≥n m√°s all√° de una sesi√≥n**, mejorando la experiencia del usuario.  
‚úÖ Permite **almacenar datos en bases de datos externas**, brindando mayor flexibilidad.  
‚úÖ Es ideal para **chatbots, asistentes y sistemas de soporte t√©cnico** que requieren memoria a largo plazo.  

üöÄ Con esta funcionalidad, nuestros grafos pueden evolucionar y mejorar con el tiempo.  

---

## üîé Recursos:

- :simple-googlecolab: Ver notebook en [Google Colab](https://colab.research.google.com/drive/16ReKOrfytiTZi9-FAV55vugWrseZuthm?usp=sharing)
- :books: Definici√≥n: [Memory](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory)
- :books: Definici√≥n: [Memory-store](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store)
- :material-code-tags: Class: [BaseStore](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)
- :material-wikipedia: Wikipedia: [Semantic-memory](https://es.wikipedia.org/wiki/Memoria_sem%C3%A1ntica)

---

## üßë‚Äçüè´ ¬øQu√© Hemos Aprendido?  

- **Diferencias entre la memoria b√°sica y la memoria a largo plazo.**  
- **C√≥mo funciona la persistencia de datos en LangGraph.**  
- **Cu√°ndo es √∫til utilizar memoria persistente en nuestros grafos.**  

---

## üåê ¬øQu√© es lo Siguiente?  

En el pr√≥ximo tema, exploraremos **memory schema**, almacenando memoria con una estructura personalizada.  
