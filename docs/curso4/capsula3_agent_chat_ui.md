# ğŸ’¬ CÃ¡psula: Agent Chat UI

## ğŸ¯ Â¿QuÃ© es Agent Chat UI?

**Agent Chat UI** es una aplicaciÃ³n web construida con **Next.js** que te permite chatear con cualquier agente de **LangGraph** (tanto en Python como en TypeScript) a travÃ©s de una interfaz de chat moderna y lista para usar.

En pocas palabras, es el â€œfrontendâ€ de chat para tus agentes: conectas tu servidor de LangGraph y empiezas a interactuar con tu grafo/assistant sin tener que construir una UI desde cero. Soporta streaming, renderizado de artefactos en un panel lateral y opciones de producciÃ³n con autenticaciÃ³n.


## ğŸ§  Â¿Para quÃ© podemos usarlo? (Casos de uso)

- ğŸ§ª Prototipado rÃ¡pido de agentes: prueba tus grafos sin desarrollar interfaz propia.
- ğŸ§° Demos y presentaciones: muestra tus agentes a usuarios o stakeholders de forma simple.
- ğŸ›Ÿ Soporte interno: interfaz para equipos que necesitan hablar con agentes internos.
- ğŸ”¬ Experimentos y evaluaciÃ³n: valida prompts, flujos y memoria sobre una UI estable.
- ğŸš€ ProducciÃ³n con autenticaciÃ³n: publica una UI de chat conectada a tu despliegue de LangGraph.


## ğŸ“¦ Â¿CÃ³mo se instala?

!!! info "Requisitos previos"
    - Node.js 18+ (recomendado LTS)
    - pnpm instalado globalmente (o usa npm/yarn)

Tienes dos caminos principales:

### "OpciÃ³n 1: Crear proyecto nuevo (recomendado)"

```bash
npx create-agent-chat-app
cd agent-chat-ui
pnpm install
pnpm dev
```

### "OpciÃ³n 2: Clonar el repositorio oficial"

```bash
git clone https://github.com/langchain-ai/agent-chat-ui.git
cd agent-chat-ui
pnpm install
pnpm dev
```
La app quedarÃ¡ disponible en [http://localhost:3000](http://localhost:3000)

!!! tip "Sin instalaciÃ³n local"
    Puedes usar la demo desplegada: [https://agentchat.vercel.app/](https://agentchat.vercel.app/)


## ğŸ•¹ï¸ Â¿CÃ³mo se usa?

Al abrir la app por primera vez (local o demo), verÃ¡s un formulario de conexiÃ³n donde debes indicar:

1. ğŸ”— Deployment URL: URL de tu servidor LangGraph (local o producciÃ³n).
2. ğŸ§­ Assistant/Graph ID: nombre del grafo o ID del assistant al que quieres chatear.
3. ğŸ” LangSmith API Key: solo si te conectas a un LangGraph desplegado que requiera autenticaciÃ³n con LangSmith.

DespuÃ©s, pulsa Â«ContinueÂ» y entrarÃ¡s al chat. A partir de ahÃ­ podrÃ¡s enviar mensajes, ver respuestas en streaming, visualizar artefactos y controlar la sesiÃ³n.

### ğŸš« Saltar el formulario (variables de entorno)

Si lo prefieres, puedes precargar la configuraciÃ³n creando un archivo `.env` (copia `.env.example`) y definiendo por ejemplo:

```bash
NEXT_PUBLIC_API_URL=http://localhost:2024
NEXT_PUBLIC_ASSISTANT_ID=agent
```

Al iniciar, la UI usarÃ¡ estos valores y no mostrarÃ¡ el formulario.


## ğŸ§© Funciones clave Ãºtiles

### 1) ğŸ” Ocultar mensajes en el chat

- Ocultar el streaming (render en vivo): aÃ±ade la etiqueta `langsmith:nostream` a tu modelo de chat.
- Ocultar un mensaje por completo (ni en vivo ni al final): aÃ±ade la etiqueta `langsmith:do-not-render` y guarda el mensaje con un `id` que empiece por `do-not-render-`.

#### "Python"

```python
# Evitar streaming en la UI
model = ChatAnthropic().with_config(config={"tags": ["langsmith:nostream"]})

# Ocultar por completo un mensaje
result = model.invoke([messages])
result.id = f"do-not-render-{result.id}"
return {"messages": [result]}
```

#### "TypeScript"

```ts
// Evitar streaming en la UI
const model = new ChatAnthropic().withConfig({ tags: ["langsmith:nostream"] });

// Ocultar por completo un mensaje
const result = await model.invoke([messages]);
result.id = `do-not-render-${result.id}`;
return { messages: [result] };
```

!!! note "Importante"
    Aunque ocultes el streaming, si el mensaje se guarda en el estado sin modificaciones, aparecerÃ¡ al final salvo que uses el patrÃ³n `do-not-render-`.

### 2) ğŸ§± Renderizado de artefactos

La UI permite mostrar â€œartefactosâ€ (contenido adicional) en un panel lateral. Desde tu grafo puedes establecer contexto en `thread.meta.artifact` y, en la UI, recuperar ese contexto con el hook `useArtifact` para renderizar componentes propios.


## ğŸ­ Â¿CÃ³mo llevarlo a producciÃ³n?

Tienes dos enfoques principales:

### "Quickstart: API Passthrough (proxy)"

Usa el paquete de passthrough para proxy inverso y autenticaciÃ³n sencilla. Configura estas variables en `.env`:

```bash
# URL de tu despliegue de LangGraph (producciÃ³n)
LANGGRAPH_API_URL="https://mi-agente.default.us.langgraph.app"
# URL pÃºblica de tu web + "/api" (el proxy)
NEXT_PUBLIC_API_URL="https://mi-sitio.com/api"
# ID del assistant/grafo a usar
NEXT_PUBLIC_ASSISTANT_ID="agent"
# API Key de LangSmith (solo en servidor, sin NEXT_PUBLIC_)
LANGSMITH_API_KEY="lsv2_..."
```

Con esto, el cliente habla con tu `/api`, y el servidor inyecta la clave de LangSmith al llamar a LangGraph.

### "Avanzado: AutenticaciÃ³n personalizada"

Implementa autenticaciÃ³n en tu servidor de LangGraph y pasa un token propio desde el cliente. Pasos tÃ­picos:

  1. ExpÃ³n un endpoint en tu despliegue de LangGraph que devuelva un token de acceso para el usuario.
  2. En la UI, ajusta el hook de streaming para enviar el token en headers, por ejemplo:

```ts
const streamValue = useTypedStream({
  apiUrl: process.env.NEXT_PUBLIC_API_URL,
  assistantId: process.env.NEXT_PUBLIC_ASSISTANT_ID,
  defaultHeaders: {
    Authentication: `Bearer ${yourAuthToken}`,
  },
});
```


## âœ… Ventajas

- â±ï¸ Ahorro de tiempo: UI de chat lista para conectar a tus grafos.
- ğŸ§© IntegraciÃ³n directa con LangGraph (Python y TS) vÃ­a clave `messages`.
- ğŸ“¡ Streaming en vivo y control fino de visibilidad de mensajes.
- ğŸ–¼ï¸ Panel de artefactos para contenido enriquecido.
- ğŸ Lista para producciÃ³n con opciones de autenticaciÃ³n y proxy.
- ğŸ§ª Ideal para demos, pruebas, evaluaciÃ³n y uso interno.
- ğŸ†“ Open Source (MIT), fÃ¡cil de extender y personalizar.


## ğŸ” Recursos

- [ğŸ¥ Video guÃ­a](https://www.youtube.com/watch?v=lInrwVnZ83o)
- [ğŸ’» Repositorio oficial](https://github.com/langchain-ai/agent-chat-ui)
- [ğŸ§ª Demo en vivo](https://agentchat.vercel.app/)
- ğŸ“˜ Docs LangGraph (autenticaciÃ³n):
    - [Python](https://langchain-ai.github.io/langgraph/tutorials/auth/getting_started/)
    - [TypeScript](https://langchain-ai.github.io/langgraphjs/how-tos/auth/custom_auth/)


## ğŸ§© Â¿QuÃ© hemos aprendido?

- QuÃ© es Agent Chat UI y cuÃ¡ndo usarlo.
- CÃ³mo instalarlo localmente o usar la demo.
- CÃ³mo conectarlo a tu servidor de LangGraph.
- CÃ³mo ocultar mensajes, renderizar artefactos y preparar un despliegue de producciÃ³n.