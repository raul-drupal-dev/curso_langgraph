# ✂️ Tema 8: Trim y Filter Messages – Optimización del Historial de Mensajes  

## 🚀 ¿Qué es el Trimming y Filtering de Mensajes?  

A medida que un grafo interactúa con los usuarios, el historial de mensajes puede **crecer considerablemente**, lo que puede:  
- **Aumentar el costo de procesamiento** para los modelos LLM.  
- **Reducir la eficiencia** del grafo en conversaciones largas.  
- **Diluir el contexto**, incluyendo mensajes irrelevantes.  

Para solucionar esto, LangGraph ofrece herramientas que permiten **gestionar y optimizar el historial de mensajes**:  

1. **`RemoveMessages`** – Elimina mensajes específicos.  
2. **`trim_messages`** – Recorta el historial manteniendo solo los mensajes más recientes.  
3. **`summarize_conversation`** – Resume la conversación para reducir la longitud del historial, manteniendo el contexto.  

---

## 🧠 ¿Por qué es Importante?  

- **Optimización del Rendimiento:** Reduce la cantidad de datos enviados al LLM.  
- **Mejora de la Precisión:** Mantiene el contexto relevante, eliminando información redundante.  
- **Ahorro de Costos:** Menos tokens procesados significa **menos consumo de recursos.**  

---

## ⚙️ ¿Cómo Funciona el Trimming y Filtering?  

LangGraph ofrece diferentes enfoques según el escenario:  
- **Eliminar mensajes irrelevantes o antiguos.**  
- **Recortar automáticamente después de alcanzar un límite.**  
- **Resumir el historial para mantener el contexto clave.**  

---

## 📋 Ejemplo Práctico: Chatbot con Gestión del Historial de Mensajes  

Vamos a crear un chatbot que interactúa con el usuario, pero **gestiona el historial** para mantener solo los mensajes relevantes y no saturar el flujo del grafo.  

---

### 🛠️ Opción 1: Eliminar Mensajes Específicos con `RemoveMessages`  

Permite eliminar ciertos mensajes del historial, ideal para **eliminar mensajes duplicados o irrelevantes.**  

[codigo1]  
```python
from langgraph.graph.message import RemoveMessages
from langchain_core.messages import AIMessage, HumanMessage

# Estado con mensajes acumulados
state = {
    "messages": [
        HumanMessage(content="Hola, ¿puedes ayudarme?"),
        AIMessage(content="Claro, ¿en qué puedo ayudarte?"),
        HumanMessage(content="Olvida lo anterior."),
        HumanMessage(content="Necesito hacer un pedido.")
    ]
}

# Eliminar el segundo mensaje
state = RemoveMessages([1]).invoke(state)

print(state)
```

---

### 🛠️ Opción 2: Recorte de Mensajes con `trim_messages`  

Recorta el historial de mensajes **manteniendo solo los últimos N mensajes.**  
Esto es útil para **evitar que el historial crezca sin control.**  

[codigo2]  
```python
from langgraph.graph.message import trim_messages

# Estado con muchos mensajes
state = {
    "messages": [
        HumanMessage(content="Hola"),
        AIMessage(content="Hola, ¿cómo estás?"),
        HumanMessage(content="Quiero información."),
        AIMessage(content="Claro, dime qué necesitas."),
        HumanMessage(content="Dime el precio del producto A."),
        AIMessage(content="El precio es de 100€."),
    ]
}

# Mantener solo los últimos 3 mensajes
state = trim_messages(state, n=3)

print(state)
```

---

### 🛠️ Opción 3: Resumir Conversación con `summarize_conversation`  

En lugar de eliminar mensajes, **genera un resumen de la conversación** manteniendo el contexto en menos palabras.  
Perfecto para **mantener el contexto en conversaciones extensas.**  

[codigo3]  
```python
from langgraph.graph.message import summarize_conversation

# Estado con mensajes acumulados
state = {
    "messages": [
        HumanMessage(content="Hola, necesito información sobre varios productos."),
        AIMessage(content="Claro, puedo ayudarte con eso."),
        HumanMessage(content="Perfecto. Empecemos con el producto A."),
        AIMessage(content="El producto A cuesta 100€ y está disponible."),
        HumanMessage(content="¿Y qué pasa con el producto B?")
    ]
}

# Resumir la conversación
state = summarize_conversation(state)

print(state)
```

---

## 🏗️ Construcción del Grafo con Trim y Filter Messages  

Integramos estas herramientas en el flujo de trabajo del chatbot para optimizar el historial de mensajes en diferentes etapas.  
[codigo4]  
```python
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import RemoveMessages, trim_messages

def assistant(state: MessagesState):
    # Simula la respuesta de un asistente
    state["messages"].append(AIMessage(content="Tu pedido ha sido procesado."))
    return state

def filter_messages(state: MessagesState):
    # Elimina mensajes irrelevantes
    state = RemoveMessages([0]).invoke(state)
    state = trim_messages(state, n=5)
    return state

# Construcción del grafo
builder = StateGraph(MessagesState)
builder.add_node("assistant", assistant)
builder.add_node("filter", filter_messages)

builder.add_edge(START, "assistant")
builder.add_edge("assistant", "filter")
builder.add_edge("filter", END)

graph = builder.compile()


```

---

## 🚀 Invocando el Grafo y Resultados  

Probamos el grafo con mensajes largos y observamos cómo se filtran, recortan o resumen automáticamente.  
[codigo5]  
```python
# Invocamos el grafo
result = graph.invoke({"messages": [HumanMessage(content="Hola, tengo una duda.")]} )
print(result)
```

[resultado1]  
```python
{'messages': [
    AIMessage(content="Tu pedido ha sido procesado.")
]}
```

---

## 🧑‍🏫 ¿Qué Hemos Aprendido?  

- **RemoveMessages:** Elimina mensajes específicos del historial.  
- **trim_messages:** Recorta el historial a los últimos mensajes.  
- **summarize_conversation:** Genera resúmenes que conservan el contexto sin saturar el historial.  

---

## 🌐 ¿Qué es lo Siguiente?  

Con esto finalizamos el **Curso 1: Fundamentos de LangGraph.**  
En el siguiente curso, exploraremos temas más avanzados como **Memoria a Largo Plazo, Subgrafías y Despliegues.**  
